<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Customer Review Analysis and Neural Network Modelling - Part 2 - Modelling and Reflections | Chaoran (Ryan) Que </title> <meta name="author" content="Chaoran (Ryan) Que"> <meta name="description" content="Amazon Review Classification"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/weblogo.png?cf4a6f33b4cf731d009704119027958e"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ryanque.github.io/blog/2022/NLP6850_2/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Customer Review Analysis and Neural Network Modelling - Part 2 - Modelling and Reflections",
            "description": "Amazon Review Classification",
            "published": "March 05, 2022",
            "authors": [
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Chaoran</span> (Ryan) Que </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Customer Review Analysis and Neural Network Modelling - Part 2 - Modelling and Reflections</h1> <p>Amazon Review Classification</p> </d-title> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#benchmark-models">Benchmark Models</a> </div> <div> <a href="#embedding-bilstm-cnn-ordinal-regression">Embedding-BiLSTM-CNN-ordinal regression</a> </div> <div> <a href="#final-structure">Final structure</a> </div> <div> <a href="#limitation-reflections">Limitation / Reflections</a> </div> </nav> </d-contents> <h2 id="benchmark-models">Benchmark Models</h2> <p>This is a multi-classification problem and there are <strong>orders between each category</strong> - simply consider the prediction as a <strong>multi-classification</strong> model will result in bad performance as the order information is lost.</p> <p>One instinctive way to solve this:</p> <p>Consider the problem as a regression problem without specific restriction on the output. The the float numbers will be categorized to certain rating levels. Threshold here adopts the method of conforming to the previous level’s distribution. In other words, the proportion of each level in the training set is calculated and mapped these ‘percentiles’ into predicted results, to divide them into 5 classes.</p> <p>It shows that there are 1700 counts for rating 1, 1500 for rating 2, 1200 for rating 3, 2400 for rating 4 and 2200 for rating 5. Using these counts to calculate the proportion, then sort the predicted results from small to large, and split the predictions into classification results. In this way, all numbers are converted into ratings and have a reasonable distribution. Finally, predictions are restored to the original order.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">StratifiedKFold</span>

<span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span><span class="p">,</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">allX</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">concattoken</span><span class="sh">'</span><span class="p">]</span><span class="c1"># ,'reviewCapitalPer','summaryCapitalPer'
</span><span class="n">ally</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">rating</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># split into train and test set
</span><span class="n">X_tr_va</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_tr_va</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">allX</span><span class="p">,</span> <span class="n">ally</span><span class="p">,</span>
                                                    <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">6</span><span class="p">,</span>
                                                    <span class="n">random_state</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span> 
                                                    <span class="n">stratify</span> <span class="o">=</span> <span class="n">ally</span><span class="p">)</span>

<span class="c1"># Define the pipeline components
</span><span class="n">SKF</span> <span class="o">=</span> <span class="nc">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span> <span class="n">shuffle</span>  <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">TFVec</span> <span class="o">=</span> <span class="nc">TfidfVectorizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">,</span>
                        <span class="n">lowercase</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
                        <span class="n">max_df</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">,</span>
                        <span class="n">min_df</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
                        <span class="n">max_features</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
                        <span class="n">ngram_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">my_pipeline</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([(</span><span class="sh">'</span><span class="s">vectorizer</span><span class="sh">'</span><span class="p">,</span> <span class="n">TFVec</span><span class="p">),</span>
                        <span class="p">(</span><span class="sh">'</span><span class="s">GBR</span><span class="sh">'</span><span class="p">,</span> <span class="nc">GradientBoostingRegressor</span><span class="p">())</span>
                       <span class="p">])</span>

<span class="c1"># GridsearchCV for optimising the hyperparameters
</span><span class="n">searching_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">GBR__learning_rate</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">GBR__n_estimators</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">GBR__max_depth</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">GBR__subsample</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="n">my_pipeline</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">searching_params</span><span class="p">,</span>
                           <span class="n">cv</span><span class="o">=</span><span class="n">SKF</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">neg_mean_squared_error</span><span class="sh">'</span><span class="p">)</span>
<span class="n">grid_search</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_tr_va</span><span class="p">,</span> <span class="n">y_tr_va</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">grid_search</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>

<span class="c1"># percentage of each categories
</span><span class="n">pred_y</span> <span class="o">=</span> <span class="n">grid_search</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">pred_y</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">pred_y</span><span class="p">)</span>
<span class="n">pred_y</span><span class="p">.</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y</span><span class="sh">'</span><span class="p">]</span>
<span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">rating</span><span class="sh">'</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">()</span>
<span class="n">w1</span> <span class="o">=</span> <span class="mi">1700</span><span class="o">/</span><span class="mi">9000</span>
<span class="n">w2</span> <span class="o">=</span> <span class="mi">1500</span><span class="o">/</span><span class="mi">9000</span>
<span class="n">w3</span> <span class="o">=</span> <span class="mi">1200</span><span class="o">/</span><span class="mi">9000</span>
<span class="n">w4</span> <span class="o">=</span> <span class="mi">2400</span><span class="o">/</span><span class="mi">9000</span>
<span class="n">w5</span> <span class="o">=</span> <span class="mi">2200</span><span class="o">/</span><span class="mi">9000</span>

<span class="c1"># calculate the percentile as threshold
</span><span class="n">threshold1</span> <span class="o">=</span> <span class="n">w1</span>
<span class="n">threshold2</span> <span class="o">=</span> <span class="n">w1</span><span class="o">+</span><span class="n">w2</span>
<span class="n">threshold3</span> <span class="o">=</span> <span class="n">w1</span><span class="o">+</span><span class="n">w2</span><span class="o">+</span><span class="n">w3</span>
<span class="n">threshold4</span> <span class="o">=</span> <span class="n">w1</span><span class="o">+</span><span class="n">w2</span><span class="o">+</span><span class="n">w3</span><span class="o">+</span><span class="n">w4</span>
<span class="nf">print</span><span class="p">(</span><span class="n">threshold1</span><span class="p">,</span><span class="n">threshold2</span><span class="p">,</span><span class="n">threshold3</span><span class="p">,</span><span class="n">threshold4</span><span class="p">)</span>

<span class="n">pred_y_sort</span> <span class="o">=</span> <span class="n">pred_y</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">pred_y</span><span class="sh">'</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">pred_y_sort</span><span class="p">,</span><span class="n">threshold1</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">pred_y_sort</span><span class="p">,</span><span class="n">threshold2</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="n">t3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">pred_y_sort</span><span class="p">,</span><span class="n">threshold3</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="n">t4</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">pred_y_sort</span><span class="p">,</span><span class="n">threshold4</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">,</span><span class="n">t3</span><span class="p">,</span><span class="n">t4</span><span class="p">)</span>

<span class="c1"># The function for categorizing the final outcome
</span><span class="k">def</span> <span class="nf">cate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">t1</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">t1</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">t2</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">2</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">t2</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">t3</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">3</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">t3</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">t4</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">4</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">t4</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">5</span> 

<span class="n">pred_y</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y_cate</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred_y</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">cate</span><span class="p">)</span>

<span class="n">y_test</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">test_y</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">test_y</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">test_y</span><span class="sh">'</span><span class="p">]</span>

<span class="n">est_reg</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">pred_y</span><span class="p">,</span><span class="n">test_y</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">est_reg</span>
</code></pre></div></div> </details> <h3 id="classification-method">classification method</h3> <p>As discussed in the previous section, this problem can also be considered as a pure multi-classification problem - ignoring the order information. The code below is implementing this idea.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>

<span class="n">my_pipeline_cla</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([(</span><span class="sh">'</span><span class="s">vectorizer</span><span class="sh">'</span><span class="p">,</span> <span class="n">TFVec</span><span class="p">),</span>
                            <span class="p">(</span><span class="sh">'</span><span class="s">GBC</span><span class="sh">'</span><span class="p">,</span> <span class="nc">GradientBoostingClassifier</span><span class="p">())</span>
                           <span class="p">])</span>

<span class="n">searching_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">GBC__learning_rate</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">GBC__n_estimators</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">400</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">GBC__max_depth</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">GBC__subsample</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">grid_search_cla</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="n">my_pipeline_cla</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">searching_params</span><span class="p">,</span>
                               <span class="n">cv</span><span class="o">=</span><span class="n">SKF</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">f1_weighted</span><span class="sh">'</span><span class="p">)</span>
<span class="n">grid_search_cla</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_tr_va</span><span class="p">,</span> <span class="n">y_tr_va</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">grid_search</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>

<span class="n">pred_y</span><span class="o">=</span> <span class="n">grid_search_cla</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">pred_y</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">pred_y</span><span class="p">)</span>
<span class="n">pred_y</span><span class="p">.</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y</span><span class="sh">'</span><span class="p">]</span>
<span class="n">est_cla</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">pred_y</span><span class="p">,</span><span class="n">test_y</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">est_cla</span>
</code></pre></div></div> </details> <h3 id="model-evaluation-and-comparison">Model Evaluation and comparison</h3> <p>As is said in the task description, F1 score is used as the criteria for evaluating the model outcome.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span><span class="n">f1_score</span>

<span class="n">columns</span><span class="o">=</span><span class="p">[</span> <span class="sh">'</span><span class="s">Accuracy</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">F1 socre</span><span class="sh">'</span><span class="p">]</span>
<span class="n">rows</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Regression</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Classification</span><span class="sh">'</span><span class="p">]</span>
<span class="n">results</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">rows</span><span class="p">)</span>

<span class="n">results</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">est_reg</span><span class="p">[</span><span class="sh">'</span><span class="s">test_y</span><span class="sh">'</span><span class="p">],</span> <span class="n">est_reg</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y_cate</span><span class="sh">'</span><span class="p">])</span>
<span class="n">results</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nf">f1_score</span><span class="p">(</span><span class="n">est_reg</span><span class="p">[</span><span class="sh">'</span><span class="s">test_y</span><span class="sh">'</span><span class="p">],</span> <span class="n">est_reg</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y_cate</span><span class="sh">'</span><span class="p">],</span> <span class="n">average</span> <span class="o">=</span> <span class="sh">'</span><span class="s">macro</span><span class="sh">'</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">est_cla</span><span class="p">[</span><span class="sh">'</span><span class="s">test_y</span><span class="sh">'</span><span class="p">],</span> <span class="n">est_cla</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y</span><span class="sh">'</span><span class="p">])</span>
<span class="n">results</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nf">f1_score</span><span class="p">(</span><span class="n">est_cla</span><span class="p">[</span><span class="sh">'</span><span class="s">test_y</span><span class="sh">'</span><span class="p">],</span> <span class="n">est_cla</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y</span><span class="sh">'</span><span class="p">],</span> <span class="n">average</span> <span class="o">=</span> <span class="sh">'</span><span class="s">macro</span><span class="sh">'</span><span class="p">)</span>

<span class="n">results</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div></div> <table> <thead> <tr> <th style="text-align: left"> </th> <th style="text-align: left">Accuracy</th> <th>F1 socre</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Regression</td> <td style="text-align: left">0.4267</td> <td>0.4266</td> </tr> <tr> <td style="text-align: left">Classification</td> <td style="text-align: left">0.4680</td> <td>0.4603</td> </tr> </tbody> </table> <p>The result shows that Classification method performs better than regression model, The reason could be - <strong>The evaluation metrics penalize the misclassification equally</strong>, <strong>but the regression model don’t treat the misclassification equally</strong>.</p> <h2 id="embedding-bilstm-cnn-ordinal-regression">Embedding-BiLSTM-CNN-ordinal regression</h2> <h3 id="embeddings">Embeddings</h3> <p>More advanced and modern way to represent text data is embedding.</p> <p>Considering the TF-IDF method of feature engineering creates too many dimensions and discards important information about the meaning of words in the context as it breaks the order of the words in the document.</p> <p>Global Vectors for Word Representation (GloVe) embedding is used to be the vectorized representation for the words in each document. The advantage of using GloVe is that it is able to capture the relationship between different words.</p> <p><strong>EXAMPLE</strong>: <code class="language-plaintext highlighter-rouge">excellent </code> and <code class="language-plaintext highlighter-rouge">brilliant </code> should be considered similar in terms of meaning and sentiment.</p> <p>Moreover, GloVe trains the weights based on the entire corpus which deals with the problem of some words’ rare occurrences. With pre-trained weights, GloVe reduces the bias caused by small datasets as there are only 9000 examples provided.</p> <blockquote> <p>more about embedding techniques: <a href="https://www.kaggle.com/code/redwankarimsony/nlp-101-understanding-word-embedding/notebook" rel="external nofollow noopener" target="_blank">NLP-101: Understanding Word Embedding Kaggle</a></p> </blockquote> <p>There are also other kinds of embedding techniques, such as word2vec (derivatives like sent2vec, doc2vec for longer texts), elmo, Fasttext, etc.</p> <blockquote> <p><a href="https://medium.com/@kashyapkathrani/all-about-embeddings-829c8ff0bf5b" rel="external nofollow noopener" target="_blank">All about Embeddings - Word2Vec, Glove, FastText, ELMo, InferSent and Sentence-BERT Medium</a></p> </blockquote> <p>Actually, Glove embedding is also a bit out-of-date and the transformer representation is the current best performing solution for NLP in this field and it is still evolving with a large amount of data feeded in the pretrained model.</p> <blockquote> <p><a href="https://arxiv.org/abs/1810.04805" rel="external nofollow noopener" target="_blank">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (arxiv.org)</a></p> <p><a href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" rel="external nofollow noopener" target="_blank">Attention is All you Need (neurips.cc)</a></p> </blockquote> <p>In this project, only Glove is used as time is limited and Glove shows quite good speed.</p> <h3 id="bi-lstm">Bi-LSTM</h3> <p>Bidirectional long short-term memory(Bi-LSTM) networks are used to extract information in the <code class="language-plaintext highlighter-rouge">reviewText</code> column as this column contains much longer text data (up to 1200 words at maximum after cleaning). Bi-LSTM is expected to learn information about the information in the context of each node.</p> <p>A typical structure of single forward LSTM is shown below.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/NLP6850/BiLSTM-480.webp 480w,/assets/img/posts/NLP6850/BiLSTM-800.webp 800w,/assets/img/posts/NLP6850/BiLSTM-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/posts/NLP6850/BiLSTM.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <p>An input node represents a GloVe transformed vector and is sent into the LSTM cell. By updating the hidden state of the cell, some information is preserved and some useless information is forgotten. A bidirectional LSTM combines two layers of LSTM which have opposite calculation directions. Works have proven that using the Bi-LSTM structure could enhance the performance of language models.</p> <h3 id="cnn">CNN</h3> <p>In 2014, Yoon Kim proposed a structure of the convolutional neural network that outperforms many other models. TextCNN structure consists of 2 main phases:</p> <ol> <li>Convolution phase. As the input is a series of word vectors that are converted by the embedding layer, kernels of the same dimension(width) but with different lengths are used to perform element-wise multiplication to the input matrix.</li> <li>After the activation function, the computed vectors are going through the max-pooling layer to keep the maximum value and then concatenate as the input of the final full connect to network. By interpreting the structure in tuition, the CNN can be used to extract information and learn useful patterns by combining adjacent words - phrases or small expressions.</li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/NLP6850/textCNN-480.webp 480w,/assets/img/posts/NLP6850/textCNN-800.webp 800w,/assets/img/posts/NLP6850/textCNN-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/posts/NLP6850/textCNN.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 80%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="ordinal-regression">Ordinal Regression</h3> <p>As is aIready discussed, in this task, sentiments are not only positive and negative that can be treated as a traditional binary classification problem. The targets are <strong>ordered and have multiple classes</strong>. If this task is treated as a multi-class classification problem, information about the order is lost and surely will cause performance loss. If this task is treated as a regression problem, class 5 should have 5 times the sentiment of 1. And bias also occurs when thresholds are applied to the output.</p> <p>Therefore, the method to get the output should be <strong>consistent, ordered and unbiased</strong>. We are using the method used in age estimation in the image recognition field. The multiple outputs of the neural network represent the probability that the prediction is greater than a certain value of rank. This method has proven to be rank consistent and has better performance than existing classification and regression methods.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/NLP6850/ordinalReg-480.webp 480w,/assets/img/posts/NLP6850/ordinalReg-800.webp 800w,/assets/img/posts/NLP6850/ordinalReg-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/posts/NLP6850/ordinalReg.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 80%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">An ariticle proposing a NN with the last layer using ordinal regression</figcaption> </figure> <h2 id="final-structure">Final structure</h2> <p>Considering <code class="language-plaintext highlighter-rouge">reviewText</code> data has long texts, the Bi-LSTM block is used after the embedding layer to learn context information around each word vector. Each step’s output of LSTM is used as the output to be learnt at the TextCNN block, in order to extract important information in specific areas. <code class="language-plaintext highlighter-rouge">summary</code> has much shorter words and can be directly learnt through TextCNN.</p> <p>In the forward propagation view, these two columns are separately learnt because we consider summary as a more important indicator of sentiments and reviewText serves as a fine-tune factor of the result. These two inputs should not share the same weights in the TextCNN block and are expected to be learnt in the network to have different importance.</p> <p>The whole structure visualization of Bi-LSTM-TextCNN-Ordinal regression is shown below.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/NLP6850/finalStructure-480.webp 480w,/assets/img/posts/NLP6850/finalStructure-800.webp 800w,/assets/img/posts/NLP6850/finalStructure-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/posts/NLP6850/finalStructure.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 80%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li>Up-left: the structure of the whole network;</li> <li>Up-right: the encoding methods for ordinal regression</li> <li>Downside: The output layer design</li> </ul> <p>Initially, we came up with 2 solutions to this issue. Firstly, we can simply regard the task as a regression task as in Task A, which proves to be less accurate than classification. We also tried to encode the target to a list of new targets which can represent the ordinal information. But this solution has a potential problem that sometimes we can not decode results. For example, if we get a result like [1,0,1,1,1], we can not easily define which group it belongs to.</p> <p>The final solution is using ordinal regression as is proposed. We tried to make the output layer have multiple outputs. Given that there are 5 categories, the target is one hot encoded, as shown in the structure, interpreted as the probability of the predicted value greater than 1 to 4. The loss function is designed as cross-entropy loss. For rank prediction, there will be 4 continuous outputs and the output channels will be marked as 1 if their value is greater than 0.5, and 0 if their value is less than 0.5. It is mathematically proved that the output will be rank consistent. The ultimate rank prediction uses the same decoding as one-hot.</p> <p>The result is that this model will have a much more stable performance than without such a technique - the standard deviation of the validation F1 score is much lower(which is observed in different epochs). However, the maximum value of the validation f1 score is not as large as the network without using this method.</p> <p>We also conducted several hyperparameter tuning but failed to find the optimized one that can outperform the gradient boosting classification model.</p> <table> <thead> <tr> <th>parameter</th> <th>base</th> <th>test1</th> <th>test2</th> <th>test3</th> <th>test4</th> <th>test5</th> <th>test6</th> <th>test7</th> <th>test8</th> <th>test9</th> <th>test10</th> <th>test11</th> <th>test12</th> </tr> </thead> <tbody> <tr> <td>batch_size</td> <td>128</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>epoch</td> <td>12</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>hidden_size</td> <td>100</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>200</td> <td>50</td> </tr> <tr> <td>dropout</td> <td>0.1</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>0.2</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>lstm_layers</td> <td>1</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>2</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>optimizerlearning rate</td> <td>0.001</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>0.0005</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>weight_decay</td> <td>0.001</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>0.005</td> <td>0.0005</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>kernel_num</td> <td>32</td> <td>-</td> <td>-</td> <td>16</td> <td>64</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>kernel_size</td> <td>2,3,4</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>2,4,6</td> <td>-</td> <td>-</td> </tr> <tr> <td>upper count</td> <td>false</td> <td>true</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>ordinal regression</td> <td>True</td> <td>-</td> <td>False</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>result (F1)</td> <td>0.402</td> <td>0.426</td> <td>0.443</td> <td>0.438</td> <td>0.440</td> <td>0.372</td> <td>0.442</td> <td>0.431</td> <td>0.409</td> <td>0.426</td> <td>0.423</td> <td>0.431</td> <td>0.426</td> </tr> </tbody> </table> <p>It is considered that the model is too complicated while the dataset is too small so that the model is not able to learn enough samples to have a decent prediction ability. Moreover, it is proposed that TextCNN can be used after embedding to learn short expressions at first and then feed into the Bi-LSTM block to learn contextual information. Due to the limitation of computation power and time, experiments are far from enough to draw a convincing conclusion.</p> <p>The code is too long to be included here, <a href="https://github.com/RyanQue/backupRepo/blob/43cd3f76ce6272f44021584ecd3737a0fca0f6ee/githubPage/NLP6850/TASK_B_Glove_Bi-LSTM_CNN_OrdinalReg.ipynb" rel="external nofollow noopener" target="_blank">check this link</a>.</p> <h2 id="limitation--reflections">Limitation / Reflections</h2> <p>Due to the limited time and computational power, we considered several limitations of this study:</p> <ol> <li>There is no comparison between the different structures of neural networks in task B, which may improve the model performance. And more hyperparameters can be tuned.</li> <li>Concerning Task A, LightGBM could be a better solution as an advanced gradient boosting method - It has a faster computation speed and better generalization in practice. The ordinal regression method may also work as long as the gradient boosting model can have multiple outputs.</li> <li>We should have dug deeper into the cutting edge techniques of transformer models, there is no comparison using a similar structure to compare the transformer with the embeddings, because the BERT transformation block has already consumed lots of computation power and we have to directly link it to a full connect output layer.</li> <li>As for preprocessing, the data that is learnt by neural networks may not be deep cleaned because the neural network may learn from the propositions or specially named entities. Moreover, the proportion of uppercase in the text should also be considered in the model as they imply a stronger expression of feelings.</li> </ol> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/"></d-bibliography> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Chaoran (Ryan) Que. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: March 24, 2024. </div> </footer> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>