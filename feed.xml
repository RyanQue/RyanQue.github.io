<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ryanque.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ryanque.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-23T08:08:30+00:00</updated><id>https://ryanque.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">A Typical ML Project Workflow</title><link href="https://ryanque.github.io/blog/2022/airbnb6810/" rel="alternate" type="text/html" title="A Typical ML Project Workflow"/><published>2022-10-22T00:00:00+00:00</published><updated>2022-10-22T00:00:00+00:00</updated><id>https://ryanque.github.io/blog/2022/airbnb6810</id><content type="html" xml:base="https://ryanque.github.io/blog/2022/airbnb6810/"><![CDATA[<h2 id="introduction">Introduction</h2> <p><em>This blog post was initially written in 2022 as a summary of a in-class ML project, which won the first place in terms of model performance. <a href="https://www.kaggle.com/c/qbus6810-2021-sem2-regression">check this link.</a> I led a team of 5 and took the responsibility of most EDA, data transformation and feature engineering parts. XGB and LightGBM were tuned and trained by me.</em></p> <p><em>I put a lot of efforts into the project and still took this project as a basic framework for ML projects. Mistakes and shortcomings made in the project constantly inspire me sebsequently.</em></p> <p>The post covers the common practices in a regression ML problem with a real-life dataset given by Airbnb. This is written in a fairly detailed manner, while deeper explanantion of certain techniques are not included.</p> <h3 id="problem-statement">Problem Statement</h3> <p>Airbnb is a global platform that runs an online marketplace for short term travel rentals.</p> <p>Targeting the Airbnb market, the task is developing an advice service for hosts, property managers, and real estate investors.</p> <p>To achieve the project’s goals, we are provided with a dataset containing detailed information on a number of existing Airbnb listings in Sydney. The team has two tasks:</p> <ol> <li> <p>To develop a predictive model for the daily prices of Airbnb rentals based on state-of-the-art techniques from statistical learning. This model will and allow the company to advise hosts on pricing and to help owners and investors to predict the potential revenue of Airbnb rental (which also depends on the occupancy rate).</p> </li> <li> <p>To obtain at least three insights that can help hosts to make better decisions. What are the best hosts doing?</p> </li> </ol> <h3 id="the-procedures-in-a-nutshell">The Procedures in a Nutshell</h3> <div class="row mt-3"> <div class="col-sm-7 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/CRISP_DM_Diag-480.webp 480w,/assets/img/CRISP_DM_Diag-800.webp 800w,/assets/img/CRISP_DM_Diag-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/CRISP_DM_Diag.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> CRISP-DM Process Diagram </div> <p>As shown in the image, the workflow of such machine learning project is highly <strong>iterative</strong>.</p> <p>Although this article is presented as the order of the jupyter notebook, the final version is a result of several iterations of the whole process. EDA, feature engineering and modelling benefit from each other.</p> <h2 id="preparation">Preparation</h2> <h3 id="i-loading-libraries">I. Loading Libraries</h3> <details><summary>Click here for codes</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">missingno</span> <span class="k">as</span> <span class="n">msn</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="n">warnings</span>
<span class="kn">import</span> <span class="n">scipy</span> <span class="k">as</span> <span class="n">sp</span>
<span class="kn">from</span> <span class="n">dataprep.eda</span> <span class="kn">import</span> <span class="n">plot</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="n">xgboost</span> <span class="kn">import</span> <span class="n">XGBRegressor</span><span class="p">,</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_log_error</span><span class="p">,</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span> <span class="n">lightgbm</span> <span class="k">as</span> <span class="n">lgb</span>
<span class="kn">import</span> <span class="n">re</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">import</span> <span class="n">optuna</span>
<span class="kn">from</span> <span class="n">optuna.samplers</span> <span class="kn">import</span> <span class="n">TPESampler</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">from</span> <span class="n">mlxtend.regressor</span> <span class="kn">import</span> <span class="n">StackingCVRegressor</span></code></pre></figure> </details> <p>Some configuration for better output display:</p> <details><summary>Click here for codes</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># filter warnings
</span><span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="nf">set_option</span><span class="p">(</span><span class="sh">'</span><span class="s">display.max_columns</span><span class="sh">'</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>

<span class="c1"># set plot display mode
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="c1"># or
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">notebook</span></code></pre></figure> </details> <h3 id="ii-reproducibility">II. Reproducibility</h3> <p>The random seed determines whether the results would be the same when others want to re-run the code. Reproducibility is particularly <strong>important for sharing</strong> the work.</p> <p>There are several sources about this problem:</p> <blockquote> <p><a href="https://scikit-learn.org/stable/common_pitfalls.html#randomness">10. Common pitfalls and recommended practices — scikit-learn 1.0.2 documentation</a></p> </blockquote> <blockquote> <p><a href="https://stackoverflow.com/questions/52746279/how-to-get-absolutely-reproducible-results-with-scikit-learn">python - How to get absolutely reproducible results with Scikit Learn? - Stack Overflow</a></p> </blockquote> <p>At least the two random seed mentioned below should be determined, because different models/splitting techniques uses different random seeding system.</p> <p>In some models, <code class="language-plaintext highlighter-rouge">random_state</code> should be defined inside the model initializing code, instead of in this global setting.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span></code></pre></figure> <h3 id="iii-read-data">III. Read Data</h3> <details><summary>Click here for codes</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">traindf</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">train.csv</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">traindf</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>

<span class="c1"># data shape, data type, and non-null counts
</span><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">the number of columns: </span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">the number of observations: </span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">*</span><span class="sh">'</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">info</span><span class="p">()</span>

<span class="c1"># random 5 observations for general understanding:
</span><span class="n">df</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="c1">#.head or .tail work fine as well, esp. in time series data</span></code></pre></figure> </details> <h2 id="data-understanding--cleaning">Data Understanding &amp; Cleaning</h2> <p>Understanding data, cleaning and transforming data, and exploratory data analysis often go together and are done in an <strong>iterative</strong> manner.</p> <p>We are doing these steps based on grouping the features by their meaning and the logic would be more coherent.</p> <p><strong>There are 2 principles throughout the whole process :</strong></p> <p><strong>1. As the goal is predicting the price, it is better to think from the perspective of the hosts and users. Considering the situation when we want to book an accommodation on Airbnb and what affects our decision, or when we want to post an accommodation on Airbnb and what factors influence our pricing - these factors are usually considered the key features (which still need statistical evidences).</strong></p> <p><strong>2. When dealing with unstructured data, the process of converting them into structured data should reduce the information loss to the minimum.</strong></p> <h3 id="iv-missing-values">IV. Missing Values</h3> <p>The library <code class="language-plaintext highlighter-rouge">missingno</code> provides several useful plots for understanding the missing value:</p> <blockquote> <p><a href="https://coderzcolumn.com/tutorials/data-science/missingno-visualize-missing-data-in-python">missingno - Visualize Missing Data in Python (coderzcolumn.com)</a></p> </blockquote> <blockquote> <ol> <li>their distribution - <code class="language-plaintext highlighter-rouge">matrix</code></li> <li>proportion/amount - <code class="language-plaintext highlighter-rouge">bar</code></li> <li>relationship - <code class="language-plaintext highlighter-rouge">heatmap</code> and <code class="language-plaintext highlighter-rouge">dendrogram</code></li> </ol> </blockquote> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># drop the columns without missing values for plotting
</span><span class="n">missingvalue_query</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span>
<span class="n">missingvalue_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="n">missingvalue_query</span><span class="p">]]</span>

<span class="c1"># bar chart for missing values
</span><span class="n">msn</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">missingvalue_df</span><span class="p">,</span>
        <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span>
        <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">lightsteelblue</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <blockquote> <p>imageplacehold</p> </blockquote> <p><strong>Insights:</strong></p> <ul> <li><code class="language-plaintext highlighter-rouge">description</code>, <code class="language-plaintext highlighter-rouge">host_location</code>, <code class="language-plaintext highlighter-rouge">bathrooms_text</code>, <code class="language-plaintext highlighter-rouge">bedrooms</code>, <code class="language-plaintext highlighter-rouge">beds</code> are features with a small portion of missing values.</li> <li><code class="language-plaintext highlighter-rouge">response_time</code> and <code class="language-plaintext highlighter-rouge">response_rate</code> are features with over a half missing values.</li> </ul> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># missing value heatmap
</span><span class="n">msn</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">missingvalue_df</span><span class="p">,</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">24</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span></code></pre></figure> <blockquote> <p>imageplacehold</p> </blockquote> <p><strong>Insights:</strong> High correlated columns have 3 groups:</p> <ul> <li>columns about reviews.</li> <li><code class="language-plaintext highlighter-rouge">neighbourbood</code> and <code class="language-plaintext highlighter-rouge">neighborhood_overview</code>.</li> <li><code class="language-plaintext highlighter-rouge">host_response_rate</code>, <code class="language-plaintext highlighter-rouge">host_response_time</code> <code class="language-plaintext highlighter-rouge">host_acceptance_rate</code></li> </ul> <p>The correlation could obviously explained by the fact that each group belongs to a certain category of information.</p> <h3 id="target-variable---price">Target Variable - ‘price’</h3> <p><code class="language-plaintext highlighter-rouge">price</code> column has the format <code class="language-plaintext highlighter-rouge">$XXX.XX</code>, which is in the <code class="language-plaintext highlighter-rouge">string</code> data type. We have to change it into <code class="language-plaintext highlighter-rouge">float</code> type.</p> <p><code class="language-plaintext highlighter-rouge">pandas</code> has a built-in function to do this. Use the <code class="language-plaintext highlighter-rouge">regex</code> parameter to be <code class="language-plaintext highlighter-rouge">True</code></p> <p><em>The module <code class="language-plaintext highlighter-rouge">re</code> can also handle this.</em></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># converting the price column's data type to float
</span><span class="n">df</span><span class="p">.</span><span class="n">price</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">price</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">[\$</span><span class="sh">'</span><span class="s">,]</span><span class="sh">"</span><span class="p">,</span><span class="sh">''</span><span class="p">,</span><span class="n">regex</span><span class="o">=</span> <span class="bp">True</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">dataprep.eda</code> provides a convenient tool for understanding the basic description of data</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># in step1, we have this line:
# from dataprep.eda import plot
</span><span class="nf">plot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>The output has quantile statistics, descriptive statistics, and several plots(histogram, KDE plot, normal Q-Q plot and Boxplot) for understanding the distribution. ()</p> <p>One thing is obvious about the <code class="language-plaintext highlighter-rouge">price</code> is that it is right skewed.</p> <p><em><strong>TIP:</strong> Some algorithms require a normal distributed target, which accords with the statistical model assumption for a better regression and prediction result. However, this is optional, linear models may benefit but tree-based algorithm may make no big difference. Also, if the skewed data is transformed into a normal distributed one, there will be <strong>transformation bias</strong>, which should be considered when the model is used for prediction.</em></p> <blockquote> <p>This problem will be elaborated on <strong>another blog.</strong></p> </blockquote> <p>Here, a log transform is used.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">log_price</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">price</span><span class="p">)</span>
</code></pre></div></div> <hr/> <p>The next steps will elaborate on pre-processing the predictors. There are more than 60 predictors and I decided to group them by its meaning.</p> <hr/> <h3 id="step6-predictors---basic-information">Step6: Predictors - Basic Information</h3> <p>including <code class="language-plaintext highlighter-rouge">['name','description]</code></p> <p>These two columns are entered by the host that can be subjective, no one will post any bad words about their accommodation. There are some missing values in the description - it reflects how much effort the host put into advertising it.</p> <p><strong>A new dummy variable created</strong> by:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">description_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">description</span><span class="p">.</span><span class="nf">isna</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</code></pre></div></div> <p><em>There will be similar missing value handling techniques later which will not be elaborated on.</em></p> <p>Then, a t-test is used to seek the difference in price between observations with or without description, the result is significant - there is a difference.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># a t-test for whether there are actually difference in price
</span><span class="n">a</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">description_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="bp">True</span><span class="p">]</span> 
<span class="n">b</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">description_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="bp">False</span><span class="p">]</span> 
<span class="n">sp</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">alternative</span> <span class="o">=</span> <span class="sh">'</span><span class="s">less</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># the output
# Ttest_indResult(statistic=-1.7525150053443874, pvalue=0.039850154641626216)
</span></code></pre></div></div> <p><em><strong>TIP</strong>: Actually, using NLP technique in the description to catch more precise information may be a better way.</em></p> <hr/> <h3 id="step7-predictors---host-related">Step7: Predictors - Host Related</h3> <p>including :</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="sh">'</span><span class="s">host_name</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">host_location</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">host_about</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">,</span>
 <span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">host_is_superhost</span><span class="sh">'</span><span class="p">,</span>
 <span class="sh">'</span><span class="s">host_listings_count</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">host_total_listings_count</span><span class="sh">'</span><span class="p">,</span>
 <span class="sh">'</span><span class="s">host_verifications</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">host_identity_verified</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <ol> <li><code class="language-plaintext highlighter-rouge">host_name</code></li> </ol> <p>check if every host has unique host name</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">host_name</span> <span class="o">==</span> <span class="sh">'</span><span class="s">David</span><span class="sh">'</span><span class="p">].</span><span class="n">host_listings_count</span><span class="p">.</span><span class="nf">unique</span><span class="p">()</span>

<span class="c1">#output
</span><span class="nf">array</span><span class="p">([</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span> <span class="mf">23.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span> <span class="mf">27.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">])</span>
</code></pre></div></div> <p>Apparently, different host can have same <code class="language-plaintext highlighter-rouge">host_name</code>, so this predictor is useless. <strong>dropped</strong></p> <ol> <li><code class="language-plaintext highlighter-rouge">host_since</code></li> </ol> <p>This column has the <code class="language-plaintext highlighter-rouge">object</code> datatype, and should be converted into how many days to the day it is collected. <em>(however this is also not available, just for approximation, the day for subtraction is the day of Kaggle competition is launched, which is Sep 23rd 2021).</em></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># first, convert object to datetime
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># second, datetime substraction
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:(</span><span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="sh">'</span><span class="s">2021-09-23</span><span class="sh">'</span><span class="p">)</span><span class="o">-</span><span class="n">x</span><span class="p">).</span><span class="n">days</span><span class="p">)</span>
</code></pre></div></div> <p><em><code class="language-plaintext highlighter-rouge">datetime</code> datatype can be calculated directly with <code class="language-plaintext highlighter-rouge">+</code> and <code class="language-plaintext highlighter-rouge">-</code>. And also can be transformed.</em></p> <blockquote> <p><a href="https://docs.python.org/3/library/datetime.html#datetime.datetime">datetime — Basic date and time types — Python 3.10.2 documentation</a></p> <p><a href="https://blog.csdn.net/DataCastle/article/details/84323603">python时间处理（三）pandas.to_datetime_DataCastle-CSDN博客_python to_datetime</a></p> </blockquote> <ol> <li><code class="language-plaintext highlighter-rouge">host_location</code></li> </ol> <p>This column is where the host lives instead of where the accommodation is, which is relatively useless. However, if the host_location is the same as the location of the accommodation, the host may provide more satisfying services. Here we just simply <strong>drop</strong> the column.</p> <ol> <li><code class="language-plaintext highlighter-rouge">host_about</code></li> </ol> <p>This column is for hosts introducing themselves, due to its large portion of missing values and textual subjective content, it is also considered to be useless.</p> <p>However, this column might give information of whether the host are putting efforts on operating the account and advertising themselves.</p> <p>Here, I built a missing value indicator and <strong>dropped</strong> this predictor.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_about_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_about</span><span class="p">.</span><span class="nf">isna</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">host_about</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <ol> <li><code class="language-plaintext highlighter-rouge">host_response_rate</code> , <code class="language-plaintext highlighter-rouge">host_response_time</code> , <code class="language-plaintext highlighter-rouge">host_acceptance_rate</code></li> </ol> <p>It is mentioned in the missing value overview that these three columns has strong correlation in terms of missing values.</p> <p>These 3 columns are indicators of whether the host and the listing are active.</p> <blockquote> <p><a href="https://www.airbnb.com/resources/hosting-homes/a/understanding-response-rate-and-acceptance-rate-86">Understanding response rate and acceptance rate - Resource Center - Airbnb</a></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># output
within an hour        4727
within a day          1470
within a few hours    1452
a few days or more     736
Name: host_response_time, dtype: int64
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">response_time</code> : It is a low-cardinality categorical variable and we <strong>fill the</strong> <code class="language-plaintext highlighter-rouge">na </code><strong>value with</strong> <code class="language-plaintext highlighter-rouge">no response</code> <strong>as a new category</strong>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># host_response_time is categorical data:
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">no response</span><span class="sh">'</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">host_response_time</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">violin</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><img src="D:/program%20files/typora/imgbed/responsetime.png" alt="responsetime"/></p> <p>From the plot above, the distribution of price are different between different response time. However, such difference are relatively minor.</p> <p><code class="language-plaintext highlighter-rouge">host_response_rate</code> and <code class="language-plaintext highlighter-rouge">host_acceptance_rate</code> should be continuous variable, convert them, and built 2 missing value indicator variables.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()</span><span class="o">==</span><span class="bp">False</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()</span><span class="o">==</span><span class="bp">False</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># a binary variable to indicate the missing value
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>  <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># fill the missing value with 0
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()]</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div></div> <ol> <li><code class="language-plaintext highlighter-rouge">host_is_superhost</code></li> </ol> <p>About the ‘superhost’ , I found the explanation in Airbnb website:</p> <blockquote> <p><a href="https://www.airbnb.com/d/superhost">Airbnb Superhost program details</a></p> </blockquote> <p>Superhost can be considered as an important factor of measuring the quality of service provided by the host, which will influence the price of the listing. - <em>This is just an assumption and will be statistically tested later</em></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># first, convert the t/f column into 0/1 binary variable.
</span><span class="n">df</span><span class="p">.</span><span class="n">host_is_superhost</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_is_superhost</span><span class="p">.</span><span class="nf">map</span><span class="p">({</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_is_superhost</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_is_superhost</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">sp</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">alternative</span> <span class="o">=</span> <span class="sh">'</span><span class="s">greater</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># the output:
# Ttest_indResult(statistic=-0.19814543743616678, pvalue=0.5785333753025225)
</span></code></pre></div></div> <p>Statistical test does not support the assumption. - host_is_superhost has no strong correlation with price.</p> <ol> <li><code class="language-plaintext highlighter-rouge">host_listing_count</code>, <code class="language-plaintext highlighter-rouge">host_total_listing_count</code></li> </ol> <p>These two columns are about the accommodations owned by the host.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">host_listings_count</span> <span class="o">==</span> <span class="n">df</span><span class="p">.</span><span class="n">host_total_listings_count</span><span class="p">).</span><span class="nf">unique</span><span class="p">()</span>

<span class="c1"># output:
# array([ True])
</span></code></pre></div></div> <p>These two columns are identical.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">host_total_listings_count</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="n">host_listings_count</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">().</span><span class="nf">sort_index</span><span class="p">()</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_listings_count</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_listings_count</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">sp</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">alternative</span> <span class="o">=</span> <span class="sh">'</span><span class="s">less</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># output:
# Ttest_indResult(statistic=-7.6451367678834385, pvalue=1.0896805499204671e-14)
</span></code></pre></div></div> <p>Statistically tested, the accommodation’s host having more than 1 listings, relates to a higher price. It can be explained that the host who has more than 1 listings are much more wealthy than the one with only one or less, whose accommodation might be more luxury, which leads to higher price.</p> <p>However, the explanation above indicates that there might be correlation between the accommodation’s condition with the <code class="language-plaintext highlighter-rouge">host_listings_count</code>, which will cause multicollinearity in linear model.(correlation is analysed later.)</p> <p><em>Clustering by the count of listings can be used here for more precise result. Here I just keep the continuous variable.</em></p> <ol> <li><code class="language-plaintext highlighter-rouge">host_verifications</code>,<code class="language-plaintext highlighter-rouge">host_identity_verified</code></li> </ol> <p>These two columns are measuring whether the host’s identity is verified and to what extent they are verified. Verified ones with more verification methods are considered as more reliable host.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert the list-like string to list data type
</span><span class="n">df</span><span class="p">.</span><span class="n">host_verifications</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_verifications</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">strip</span><span class="p">(</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"'"</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">))</span>

<span class="c1"># convert the t/f to 1/0
</span><span class="n">df</span><span class="p">.</span><span class="n">host_identity_verified</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_identity_verified</span><span class="p">.</span><span class="nf">map</span><span class="p">({</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="c1"># counting the number of verification - how host varifies seems not a relevant indicator
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">num_host_verification</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_verifications</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">'</span><span class="s">num_host_verification</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">hue</span> <span class="o">=</span> <span class="sh">'</span><span class="s">host_identity_verified</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">boxen</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><img src="D:/program%20files/typora/imgbed/verification.png" alt="verification"/></p> <p>It is observed that accommodation with identity-verified host will have slightly higher price. With number of verification increasing, there is no obvious increment in price.</p> <h3 id="step8-predictors---location-related">Step8: Predictors - Location Related</h3> <ul> <li>four text predictors relate to the location of the accommodation: <ol> <li><code class="language-plaintext highlighter-rouge">neighbourhood_cleansed</code> is the cleansed version of <code class="language-plaintext highlighter-rouge">neighbourhood</code> (no missing value and categorical compared with the original one.)</li> <li><code class="language-plaintext highlighter-rouge">neighborhood_overview</code> contains more precise information about the location, but it is recorded with human language which needs related models to extract useful information.</li> <li><code class="language-plaintext highlighter-rouge">host_neighbourhood</code> is the neighbourhood of the host, instead of the accommodation, which is relatively useless.</li> </ol> </li> <li>two continuous variables describe the exact location of the accommodation, which are the most precise location information.</li> </ul> <ol> <li>drop useless predictors - <code class="language-plaintext highlighter-rouge">host_neighbourhood</code> and <code class="language-plaintext highlighter-rouge">neighbourhood</code></li> <li>Plotting the <code class="language-plaintext highlighter-rouge">longitude</code> and <code class="language-plaintext highlighter-rouge">latitude</code> with log_price - geometric distribution</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">latitude</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">longitude</span><span class="p">,</span>
           <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">4</span><span class="p">,</span>
           <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span>
           <span class="n">s</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
           <span class="n">c</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">log_price</span><span class="p">,</span>
           <span class="n">cmap</span> <span class="o">=</span> <span class="sh">"</span><span class="s">coolwarm</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">latitude</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">longitude</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Price geometric distribution</span><span class="sh">"</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">()</span>
<span class="n">a</span><span class="p">.</span><span class="nf">set_label</span><span class="p">(</span><span class="sh">'</span><span class="s">log_price</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p><img src="D:/program%20files/typora/imgbed/geometric%20distribution.png" alt="geometric distribution"/></p> <p><em><strong>TIP</strong>: This figure can be improved by using more advanced visualization technique. For example, 1) combining with the real map, 2) use some kind of heatmap instead of this scatter graph with alpha adjusted.</em></p> <p>It is observed from the plot that geometric location of the accommodation has some complex relationship with price.</p> <p>And these two variables are more complete, authentic and precise compared with <code class="language-plaintext highlighter-rouge">neighborhood_overview</code>. Therefore, <strong>we only keep <code class="language-plaintext highlighter-rouge">longitude</code> and <code class="language-plaintext highlighter-rouge">latitude</code>.</strong> <em>However, NLP can be used to extract useful information in the predictor<code class="language-plaintext highlighter-rouge">neighborhood_overview</code>.</em></p> <p><em><strong>TIP</strong>: This step can be improved to optimise the performance of the predicting model. - the place of the accommodation affect the price greatly in common sense.</em> - Think when we want to book an accommodation on Airbnb and make a decision.</p> <h3 id="step9-predictors---accommodation-related">Step9: Predictors - Accommodation Related</h3> <p>The quality and facilities of the accommodation are the key factors in determining the price of it, due to life experience.</p> <ol> <li><code class="language-plaintext highlighter-rouge">Property_type</code></li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">property_type</span><span class="p">.</span><span class="nf">unique</span><span class="p">()</span>
</code></pre></div></div> <p>From the output, This predictors can be taken as categorical with high cardinality, but also can be taken as human language and can be reduced by NLP techniques.</p> <p><em>This part will be elaborated in the Feature Engineering part.</em></p> <ol> <li><code class="language-plaintext highlighter-rouge">room_type</code></li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">room_type</span><span class="p">.</span><span class="nf">unique</span><span class="p">()</span>
<span class="c1"># There are only 4 categories in this predictor
</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="sh">"</span><span class="s">room_type</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">y</span> <span class="o">=</span> <span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span>
            <span class="n">kind</span> <span class="o">=</span> <span class="sh">"</span><span class="s">violin</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><img src="D:/program%20files/typora/imgbed/room%20type.png" alt="room type"/></p> <p>The plot shows that private room and shared room are relatively low in price while entire home/apt and hotel room are relatively high in price.</p> <ol> <li><code class="language-plaintext highlighter-rouge">accommodates</code></li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">accommodates</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">boxen</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><img src="D:/program%20files/typora/imgbed/accommodates.png" alt="accommodates"/></p> <p>From the boxplot, it is observed that when accommodates are less than 10, the price has approximately positive linear relationship with accommodates. Accommodations with more than 10 accommodates has no obvious relationship with price.</p> <p><em>clustering can be used here - construct a indicator variable with the threshold of <code class="language-plaintext highlighter-rouge">accommodates == 10</code></em></p> <ol> <li><code class="language-plaintext highlighter-rouge">bathrooms_text</code></li> </ol> <p>use <code class="language-plaintext highlighter-rouge">.unique()</code> and we see that the predictor can be separated into a number and an adjective. This part will also be elaborated on the feature engineering part.</p> <ol> <li><code class="language-plaintext highlighter-rouge">bedrooms</code></li> </ol> <p>use <code class="language-plaintext highlighter-rouge">value_counts()</code> - the amount of bedrooms vary from 1 to 16, and there are missing values.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># na means no bedroom
</span><span class="n">df</span><span class="p">.</span><span class="n">bedrooms</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">bedrooms</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">bedrooms</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span> 
               <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">boxen</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><img src="D:/program%20files/typora/imgbed/bedrooms.png" alt="bedrooms"/></p> <p>the correlation is obvious positive but not linear.</p> <p><em>A new predictor with the value of <code class="language-plaintext highlighter-rouge">bedrooms**2</code> or more power can be constructed (I did not do it here)</em></p> <p>And I do the similar procedure with <code class="language-plaintext highlighter-rouge">beds</code> and find similar pattern.</p> <ol> <li><code class="language-plaintext highlighter-rouge">amenities</code></li> </ol> <p>This predictor can taken as a nested list and entered in the <code class="language-plaintext highlighter-rouge">string</code> format.</p> <p>The following steps did these things:</p> <ul> <li>convert the string into a list of lists</li> <li>count unrepeated items appeared in the deepest list.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert the amenities column from string to list.
</span><span class="n">df</span><span class="p">.</span><span class="n">amenities</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">strip</span><span class="p">(</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"'"</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">))</span>

<span class="c1"># try to get all the unique items in the amenities list.
</span><span class="k">def</span> <span class="nf">GetAme</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    This function takes one parameter which should be a 2-times-nested list(list of lists)
    Return with a list with all the non-repeated items in the deepest list
    </span><span class="sh">"""</span>
    <span class="n">AmeList</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">AnObservation</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">AnObservation</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">'"'</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">AmeList</span><span class="p">:</span>
                <span class="n">AmeList</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">'"'</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">AmeList</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="nc">GetAme</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">amenities</span><span class="p">)))</span> <span class="c1"># output 623
</span></code></pre></div></div> <p><em>This may not be the best way to analyse the predictor, because some of the amenities have the brand and repeatedly counted – some advanced NLP techniques can be used here to furthermore reduce the cardinality.</em></p> <h3 id="step10-predictors---availability-related">Step10: Predictors - Availability Related</h3> <ol> <li>night stay related</li> </ol> <p>including:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="sh">'</span><span class="s">minimum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">maximum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">minimum_minimum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">maximum_minimum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">minimum_maximum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">maximum_maximum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">minimum_nights_avg_ntm</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">maximum_nights_avg_ntm</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <p>Related Airbnb minimum night stay explanation:</p> <blockquote> <table> <tbody> <tr> <td>[What’s the Best Minimum Night Stay Policy on Airbnb?</td> <td>AirDNA](https://www.airdna.co/blog/whats-the-best-minimum-night-stay-policy-on-airbnb)</td> </tr> </tbody> </table> </blockquote> <p>Host can set minimum nights and maximum nights a customer can book for the accommodation. And such setting can vary in different period of time during the year, indicating a high/low season or the availability of the host.</p> <p>Longer minimum nights sometimes means lower price as the host will not have to bother in introducing and settling the accommodation.</p> <p>Based on life experience, in the high season, if there are strategy in changing the settings of the minimum nights and maximum nights, minimum nights and maximum nights will be shorter, and the opposite in the low season.</p> <p><code class="language-plaintext highlighter-rouge">minimum_nights_avg_ntm</code> and <code class="language-plaintext highlighter-rouge">maximum_nights_avg_ntm</code> might be good predictors as it is the weighted average of the number of nights setting.</p> <p>The following codes categorize the minimum and maximum night stays, then plotted against the target <code class="language-plaintext highlighter-rouge">log_price</code>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ClassifyNights</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">7</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">within a week</span><span class="sh">'</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">30</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">within a month</span><span class="sh">'</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">365</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">within a year</span><span class="sh">'</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">more than a year</span><span class="sh">'</span>

<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">cate_min_nights</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">minimum_nights_avg_ntm</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">ClassifyNights</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">cate_min_nights</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span> 
               <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">violin</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><img src="D:/program%20files/typora/imgbed/min%20night.png" alt="min night"/></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">cate_max_nights</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">maximum_nights_avg_ntm</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">ClassifyNights</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">cate_max_nights</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span> 
               <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">violin</span><span class="sh">"</span>
</code></pre></div></div> <p><img src="D:/program%20files/typora/imgbed/max%20night.png" alt="max night"/></p> <p>It seems that there is no big difference in price with different settings of minimum nights and maximum nights.</p> <ol> <li>availability related</li> </ol> <p>including:</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>['has_availability','availability_30','availability_60',
 'availability_90','availability_365','instant_bookable']
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># converting t/f to 1/0
</span><span class="n">df</span><span class="p">.</span><span class="n">has_availability</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">has_availability</span><span class="p">.</span><span class="nf">map</span><span class="p">({</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
<span class="n">df</span><span class="p">.</span><span class="n">instant_bookable</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">instant_bookable</span><span class="p">.</span><span class="nf">map</span><span class="p">({</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="c1">#plotting the has_availability against log_price
</span><span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">has_availability</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
               <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">violin</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p><img src="D:/program%20files/typora/imgbed/has%20availability.png" alt="has availability"/></p> <p>The same is did to <code class="language-plaintext highlighter-rouge">instant_bookable</code> and the plot shows no difference.</p> <p>The availability in different time scale are indicators of whether the accommodation is popular or not. Less availability days are considered as more popular based on common sense.</p> <p><code class="language-plaintext highlighter-rouge">availability_365</code> is considered as a robust indicator, <code class="language-plaintext highlighter-rouge">availability_30</code> can be used to compare with <code class="language-plaintext highlighter-rouge">availability_365</code> (in terms of ratio)to infer whether it is high/low season of the year.</p> <p>However, plots do not support the assumption mentioned above. Some difference (not obvious) in price is observed whether ratio of availability are high/low in the recent month.</p> <h3 id="step11-predictors---review-related">Step11: Predictors - Review related</h3> <p>With all the predictor plotted against <code class="language-plaintext highlighter-rouge">log_price</code>, only one thing can be sure:</p> <p>Accommodations with high price rarely have bad rating.</p> <h3 id="step12-predictors---listing-related">Step12: Predictors - Listing Related</h3> <p>No obvious relationship is found.</p> <hr/> <h3 id="step13-test-set">Step13: Test set</h3> <p>All the data cleaning procedure should be both done in the training set and testing set.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># examine whether columns are correct.
</span><span class="n">trainList</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">trainList</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">)</span>
<span class="n">trainList</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="sh">'</span><span class="s">log_price</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">trainList</span> <span class="o">==</span> <span class="nf">list</span><span class="p">(</span><span class="n">test</span><span class="p">.</span><span class="n">columns</span><span class="p">))</span>

<span class="c1"># the output shoud be:
# True
</span></code></pre></div></div> <hr/> <h2 id="3-feature-engineering">3. Feature Engineering</h2> <h3 id="step14-handling-natural-language">Step14: Handling natural language</h3> <ol> <li><code class="language-plaintext highlighter-rouge">property_type</code></li> </ol> <p>This feature descibes the type of the property. However, types are expressed with human language. The description can be devided by its word class:</p> <ul> <li> <p>adjective: ‘shared’,’private’,’entire’,etc. ;</p> </li> <li> <p>noun: ‘apartment’,’hotel’,’loft’,etc. .</p> </li> </ul> <p>Therefore, with clear pattern, it is processed by code below.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">property_word_totallist</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">AnObs</span> <span class="ow">in</span> <span class="n">train</span><span class="p">.</span><span class="n">property_type</span><span class="p">:</span>
    <span class="n">AnObs_low</span> <span class="o">=</span> <span class="n">AnObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">AnObs_low</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">aword</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">aword</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">property_word_totallist</span><span class="p">:</span>
            <span class="n">property_word_totallist</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">aword</span><span class="p">)</span>
            
<span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type_wdlist</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">property_type</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">))</span>
<span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type_wdlist</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">property_type</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">testword</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">property_word_totallist</span><span class="p">):</span>
    <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">property_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">testword</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type_wdlist</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">testword</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">property_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">testword</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type_wdlist</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">testword</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">property_word_totallist</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">property_</span><span class="sh">'</span><span class="o">+</span> <span class="n">testword</span>
    
<span class="c1"># create a list for selected features
</span><span class="n">SelectedFeature</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># include the constructed columns
</span><span class="k">for</span> <span class="n">afeature</span> <span class="ow">in</span> <span class="n">property_word_totallist</span><span class="p">:</span>
    <span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">afeature</span><span class="p">)</span>
</code></pre></div></div> <ol> <li><code class="language-plaintext highlighter-rouge">bathroom_text</code></li> </ol> <p>3 predictors are constructed:</p> <ul> <li>the number of bath</li> <li>whether the bath is private - 1 for private and 0 for not private</li> <li>whether the bath is shared - 1 for shared and 0 for not shared</li> </ul> <p><em>some of the description did not mention whether it is private and shared.</em></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bath_word_totallist</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">AnObs</span> <span class="ow">in</span> <span class="n">train</span><span class="p">.</span><span class="n">bathrooms_text</span><span class="p">:</span>
    <span class="n">AnObs_low</span> <span class="o">=</span> <span class="n">AnObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">AnObs_low</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">aword</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">aword</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">bath_word_totallist</span><span class="p">:</span>
            <span class="n">bath_word_totallist</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">aword</span><span class="p">)</span>

<span class="c1"># the number of baths
</span><span class="k">def</span> <span class="nf">bathnum</span><span class="p">(</span><span class="n">AnObs</span><span class="p">):</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">AnObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">half</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">0.5</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">awd</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">anum</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">awd</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">anum</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">continue</span>

<span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">number_of_baths</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathnum</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">number_of_baths</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathnum</span><span class="p">)</span>

<span class="c1"># whether the bath is private
</span><span class="k">def</span> <span class="nf">bathprivate</span><span class="p">(</span><span class="n">AnObs</span><span class="p">):</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">AnObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">half</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">0.5</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">private</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>

<span class="n">train</span><span class="p">[</span><span class="sh">"</span><span class="s">bath_private</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathprivate</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="sh">"</span><span class="s">bath_private</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathprivate</span><span class="p">)</span>

<span class="c1"># whether the bath is shared 
</span><span class="k">def</span> <span class="nf">bathshared</span><span class="p">(</span><span class="n">AnObs</span><span class="p">):</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">AnObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">half</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">0.5</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">shared</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    
<span class="n">train</span><span class="p">[</span><span class="sh">"</span><span class="s">bath_shared</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathshared</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="sh">"</span><span class="s">bath_shared</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathshared</span><span class="p">)</span>

<span class="c1"># add the 3 constructed predictors
</span><span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">number_of_baths</span><span class="sh">'</span><span class="p">)</span>
<span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">bath_private</span><span class="sh">'</span><span class="p">)</span>
<span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">bath_shared</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <ol> <li><code class="language-plaintext highlighter-rouge">amenities</code></li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># turn the string dtype into list
</span><span class="n">train</span><span class="p">.</span><span class="n">amenities</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"'"</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'"'</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">strip</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,  </span><span class="sh">"</span><span class="p">))</span>
<span class="n">test</span><span class="p">.</span><span class="n">amenities</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"'"</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'"'</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">strip</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,  </span><span class="sh">"</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">GetAme</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    This function takes one parameter which should be a 2-times-nested list(list of lists)
    Return with a list with all the non-repeated items in the deepest list
    </span><span class="sh">"""</span>
    <span class="n">AmeList</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">AnObservation</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">AnObservation</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">AmeList</span><span class="p">:</span>
                <span class="n">AmeList</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">AmeList</span>

<span class="n">Amenity_list</span> <span class="o">=</span> <span class="nc">GetAme</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">amenities</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">Amenity_list</span><span class="p">))</span> <span class="c1"># output 598
</span></code></pre></div></div> <p>Too many unique items in this list - a new column for each unique item is not a good idea.</p> <p>Instead, I choose the items that occurred 30 times.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">item_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">Amenity_list</span><span class="p">:</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">AnObs</span> <span class="ow">in</span> <span class="n">train</span><span class="p">.</span><span class="n">amenities</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">AnObs</span><span class="p">:</span>
            <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">item_dict</span><span class="p">[</span><span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">()]</span> <span class="o">=</span> <span class="n">counter</span>
    
<span class="n">freq_ame_list</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">akey</span> <span class="ow">in</span> <span class="n">item_dict</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">item_dict</span><span class="p">[</span><span class="n">akey</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">30</span><span class="p">:</span> <span class="c1"># 30 can be modified, the larger, the generalisation would be better.
</span>        <span class="n">freq_ame_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">akey</span><span class="p">)</span>
        
<span class="nf">len</span><span class="p">(</span><span class="n">freq_ame_list</span><span class="p">)</span> <span class="c1">#output 120, which is acceptable
</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">aitem</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">freq_ame_list</span><span class="p">):</span>
    <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">Amenity_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">aitem</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nf">int</span><span class="p">(</span><span class="n">aitem</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">Amenity_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">aitem</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nf">int</span><span class="p">(</span><span class="n">aitem</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">freq_ame_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Amenity_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">aitem</span>


<span class="k">for</span> <span class="n">afeature</span> <span class="ow">in</span> <span class="n">freq_ame_list</span><span class="p">:</span>
    <span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">afeature</span><span class="p">)</span>
</code></pre></div></div> <hr/> <h3 id="step15-encoding-the-categorical-data">Step15: Encoding the categorical data</h3> <p>including : <code class="language-plaintext highlighter-rouge">host_response_time, neighbourhood_cleansed, room_type</code></p> <p>Encoding is automatically done by the <code class="language-plaintext highlighter-rouge">OneHotEncoder</code> in the <code class="language-plaintext highlighter-rouge">sklearn</code> package.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cate_col</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">neighbourhood_cleansed</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">room_type</span><span class="sh">'</span><span class="p">]</span>
<span class="n">OHEnc</span> <span class="o">=</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="n">OHcols</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">OHEnc</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">cate_col</span><span class="p">]),</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">OHEnc</span><span class="p">.</span><span class="nf">get_feature_names</span><span class="p">())</span>
<span class="n">OHcols_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">OHEnc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">cate_col</span><span class="p">]),</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">OHEnc</span><span class="p">.</span><span class="nf">get_feature_names</span><span class="p">())</span>

<span class="n">othercols</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">cate_col</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">othercols_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">cate_col</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">OHcols</span><span class="p">,</span><span class="n">othercols</span><span class="p">],</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">OHcols_test</span><span class="p">,</span><span class="n">othercols_test</span><span class="p">],</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <hr/> <h3 id="step16-collecting-all-the-useful-predictors">Step16: Collecting all the useful predictors</h3> <p>In this example, I separate all the predictors by its meaning and then did the cleaning and feature engineering. From my perspective, this is useful when there are many predictors that may affect the target. And a list can be constructed to store the filtered predictors’ name for further modelling usage.</p> <hr/> <h2 id="4-modelling">4. Modelling</h2> <h3 id="step17-preparation">Step17: Preparation</h3> <p>There are several procedures need to be done:</p> <ul> <li>Train-valid-test split</li> </ul> <p>In this example, test set is already given to evaluate the generalization.</p> <p>A second split (as train and validation set) is done for hyperparameter optimisation. In most algorithms, I use cross-validation - the dataset is not large and computationally capable.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictors</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">SelectedFeature</span><span class="p">]</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">log_price</span><span class="sh">'</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">SelectedFeature</span><span class="p">]</span> <span class="c1"># the final y_test is in log_price scale, remember to convert back.
</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>Define the RMSLE metric and scorer - The final result is evaluated by RMSLE (root mean squared log error)</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rmsle</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">mean_squared_log_error</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">y_valid</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="p">))</span>

<span class="c1"># log transformed target scorer
</span><span class="n">rmsle_scorer</span> <span class="o">=</span> <span class="nf">make_scorer</span><span class="p">(</span><span class="n">rmsle</span><span class="p">,</span> <span class="n">greater_is_better</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>rename the column names - <code class="language-plaintext highlighter-rouge">XGboost</code> and <code class="language-plaintext highlighter-rouge">LightGBM</code> have some issues regarding the column names</li> </ul> <blockquote> <p>XGboost: <a href="https://stackoverflow.com/questions/42338972/valueerror-feature-names-mismatch-in-xgboost-in-the-predict-function">python - ValueError: feature_names mismatch: in xgboost in the predict() function - Stack Overflow</a></p> <p>LightGBM: <a href="https://stackoverflow.com/questions/60698860/how-to-deal-with-do-not-support-non-ascii-characters-in-feature-name-error-whe">python - How to deal with “Do not support non-ASCII characters in feature name” error when I use lightGBM? - Stack Overflow</a></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">'</span><span class="s">[^A-Za-z0-9_]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="n">X_valid</span> <span class="o">=</span> <span class="n">X_valid</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">'</span><span class="s">[^A-Za-z0-9_]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">'</span><span class="s">[^A-Za-z0-9_]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
</code></pre></div></div> <ul> <li>A function that generate output files</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">nameofmodel</span><span class="p">):</span>
    <span class="c1"># back transformation bias is considered.
</span>    <span class="sh">'''</span><span class="s"> this function takes two parameter,
    model - the already fitted model which has .predict() method
    nameofmodel - a string, the name of the model
    </span><span class="sh">'''</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">predictors</span><span class="p">)</span>
    <span class="n">residuals</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">y_hat</span>
    <span class="n">adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
    <span class="n">final_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj</span>
    <span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">final_predict</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">submission</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">{} model prediction.csv</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">nameofmodel</span><span class="p">),</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>
</code></pre></div></div> <p>The Transformation bias:</p> <blockquote> <p>When the target is transformed using non-linear techniques, back transformation in prediction may generate transformation bias, which can be eliminated.</p> </blockquote> <hr/> <h3 id="step18-benchmark---simple-linear-regression">Step18: Benchmark - Simple linear regression</h3> <p>Linear regression has a very strong assumption on the relationship between the predictors and target. - The model has good computation speed and interpretation but bad performance on prediction. - I use this as a benchmark model, and any model has a worse result will be considered useless.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">LR</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>

<span class="c1"># kfold is used for cross-validation - splitting the dataset into k segments
</span><span class="n">kfold</span> <span class="o">=</span> <span class="nc">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span> <span class="mi">5</span> <span class="p">,</span><span class="n">shuffle</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span> <span class="mi">42</span> <span class="p">)</span>

<span class="n">LR_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">LR</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span> <span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE Benchmark with linear regression(cross-validation): {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">LR_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span>
<span class="c1"># result(in RMSLE): 0.423998
</span>
<span class="n">LR</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">LR</span><span class="p">,</span> <span class="sh">'</span><span class="s">linearRegression</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <hr/> <h3 id="step19-regularised-linear">Step19: Regularised Linear</h3> <p>Ridge and lasso are regularised linear regression algorithms, they use different penalty mechanism on the coefficient, avoiding it to be too large. These two methods increase the robustness of the prediction model.</p> <ul> <li><code class="language-plaintext highlighter-rouge">Ridge</code></li> </ul> <p>I use <code class="language-plaintext highlighter-rouge">gridsearchcv</code> to search for the best parameter, this is a simple hyperparameter tuning method that simply loop over all the parameters that needs calculation with cross validation.</p> <blockquote> <p><a href="https://scikit-learn.org/stable/modules/grid_search.html">3.2. Tuning the hyper-parameters of an estimator — scikit-learn 1.0.2 documentation</a></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RDparameters</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">]}</span>
<span class="n">RDopt</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="nc">Ridge</span><span class="p">(),</span><span class="n">RDparameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="n">RDopt</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span><span class="n">target</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">RDopt</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span> <span class="c1">#0.6
</span>
<span class="n">RD</span> <span class="o">=</span> <span class="nc">Ridge</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">RDopt</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">])</span>
<span class="n">RD_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">RD</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span> <span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Cross-Validation data with tuned Ridge: {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">RD_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span>
<span class="c1"># 0.423853
</span>
<span class="n">RD</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">RD</span><span class="p">,</span> <span class="sh">'</span><span class="s">Ridge</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">Lasso</code></li> </ul> <p>Same methods is used in <code class="language-plaintext highlighter-rouge">Lasso</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">LSparameters</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">:[</span><span class="mf">1e-07</span><span class="p">,</span><span class="mf">1e-06</span><span class="p">,</span><span class="mf">1e-05</span><span class="p">,</span><span class="mf">1e-04</span><span class="p">,</span><span class="mf">1e-03</span><span class="p">,</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">]}</span>
<span class="n">LSopt</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="nc">Lasso</span><span class="p">(),</span><span class="n">LSparameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="n">LSopt</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span><span class="n">target</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">LSopt</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span> <span class="c1">#0.0001
</span>
<span class="n">LS</span> <span class="o">=</span> <span class="nc">Lasso</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">LSopt</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">])</span>
<span class="n">LS_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">LS</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span> <span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Validation data with tuned Lasso: {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">LS_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span>
<span class="c1"># 0.423638
</span>
<span class="n">LS</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">LS</span><span class="p">,</span> <span class="sh">'</span><span class="s">Lasso</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <hr/> <h3 id="step20-random-forest">Step20: Random Forest</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    
    <span class="c1"># configure the hyperparameters range to optimise
</span>    <span class="n">n_estimators</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">n_estimators</span><span class="sh">'</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">min_samples_leaf</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">max_features</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_categorical</span><span class="p">(</span><span class="sh">'</span><span class="s">max_features</span><span class="sh">'</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">auto</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sqrt</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">max_depth</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
    
    <span class="c1"># define the model that need to be used
</span>    <span class="n">RFmodel</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span><span class="p">,</span>  
                                  <span class="n">max_features</span> <span class="o">=</span> <span class="n">max_features</span><span class="p">,</span> 
                                  <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">min_samples_leaf</span><span class="p">,</span>
                                  <span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span><span class="p">,</span>
                                  <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
    
    <span class="c1"># define the criterion for the optimization
</span>    <span class="n">scores</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">RFmodel</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">kfold</span><span class="p">)</span>
    
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">loss</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="nc">TPESampler</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> 
<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="p">.</span><span class="nf">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="sh">'</span><span class="s">minimize</span><span class="sh">'</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
<span class="c1"># the timeout is set to be 30mins
# if you cannot wait that long, please shrink the timeout parameter below
# however, the longer, the more possible the model is well-tuned
</span><span class="n">study</span><span class="p">.</span><span class="nf">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">2400</span><span class="p">)</span> 
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">optuna</code> is used to optimise the hyperparameter</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RF_params</span> <span class="o">=</span> <span class="n">study</span><span class="p">.</span><span class="n">best_params</span>
<span class="n">RF</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">RF_params</span><span class="p">)</span>
<span class="n">RF_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">RF</span><span class="p">,</span>
                                <span class="n">X</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">,</span>
                                <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span>
                                <span class="n">scoring</span> <span class="o">=</span> <span class="n">rmsle_scorer</span><span class="p">,</span>
                                <span class="n">cv</span> <span class="o">=</span> <span class="n">kfold</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Cross-Validation with tuned Random Forest: {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">RF_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span>

<span class="n">RF</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">RF</span><span class="p">,</span> <span class="sh">'</span><span class="s">RandomForest</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>plotting the feature importance for better interpretability</p> <p>the feature importance plotting function will be reused in other models.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_feature_importance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">max_features</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>  
    <span class="sh">'''</span><span class="s">
    This function is only available for models that has the feature_importances_ attribute.
    </span><span class="sh">'''</span>
    <span class="n">feature_importance</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="o">*</span><span class="mi">100</span>    
    <span class="n">feature_importance</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="p">(</span><span class="n">feature_importance</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">))</span>    
    <span class="n">table</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">labels</span><span class="p">).</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>    
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">table</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_features</span><span class="p">:</span>        
        <span class="n">table</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="n">max_features</span><span class="p">:].</span><span class="n">T</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="sh">'</span><span class="s">barh</span><span class="sh">'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>    
    <span class="k">else</span><span class="p">:</span>        
        <span class="n">table</span><span class="p">.</span><span class="n">T</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="sh">'</span><span class="s">barh</span><span class="sh">'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>    
    <span class="n">ax</span><span class="p">.</span><span class="nf">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="sa">u</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>     
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Variable importance</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>    
    <span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">()</span>    
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>

<span class="n">feature_names</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="nf">to_list</span><span class="p">()</span>

<span class="nf">plot_feature_importance</span><span class="p">(</span><span class="n">RF</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <p><img src="D:/program%20files/typora/imgbed/random%20forest%20plot.png" alt="random forest plot"/></p> <hr/> <h3 id="step-21-xgboost">Step 21: XGBoost</h3> <p>XGBoost is widely used and perform relatively well in recent regression problems.</p> <p><code class="language-plaintext highlighter-rouge">GridSearchCV</code> is used for finding the optimised hyperparameters.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clf</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="nc">XGBRegressor</span><span class="p">(),</span>
                   <span class="p">{</span><span class="sh">'</span><span class="s">n_estimators</span><span class="sh">'</span><span class="p">:[</span><span class="mi">400</span><span class="p">,</span><span class="mi">500</span><span class="p">],</span>
                    <span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span>
                    <span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">:[</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.07</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,]},</span> 
                   <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                   <span class="n">scoring</span> <span class="o">=</span> <span class="n">rmsle_scorer</span><span class="p">,</span>
                  <span class="p">)</span>

<span class="n">X_xgb</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">.</span><span class="n">values</span>

<span class="n">clf_result</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_xgb</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">clf_result</span><span class="p">.</span><span class="n">best_score_</span><span class="p">)</span> 
<span class="c1"># -0.37892
</span><span class="nf">print</span><span class="p">(</span><span class="n">clf_result</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># learning_rate : 0.04, max_depth : 8, n_estimators : 500
</span></code></pre></div></div> <p>Train the model and predict,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#configure the model 
</span><span class="n">XGB</span> <span class="o">=</span> <span class="nc">XGBRegressor</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">clf_result</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">],</span>
                       <span class="n">max_depth</span> <span class="o">=</span> <span class="n">clf_result</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">],</span>
                       <span class="n">n_estimators</span> <span class="o">=</span> <span class="n">clf_result</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">n_estimators</span><span class="sh">'</span><span class="p">],)</span>

<span class="c1"># cross validation
</span><span class="n">XGB_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">XGB</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">X_xgb</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span> <span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Cross-Validation data with tuned XGBoost: {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">XGB_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span> <span class="c1">#0.378497
</span>
<span class="c1"># predict with the trained model
</span><span class="n">XGB</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_xgb</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="n">X_test_xgb</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">values</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">XGB</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_xgb</span><span class="p">)</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">y_hat</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
<span class="n">final_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">XGB</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test_xgb</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj</span>
<span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">final_predict</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])</span>
<span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)</span>
<span class="n">submission</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">{} model prediction.csv</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">'</span><span class="s">XGBoost</span><span class="sh">'</span><span class="p">),</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>

<span class="c1"># print the feature importance
</span><span class="nf">plot_feature_importance</span><span class="p">(</span><span class="n">XGB</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <hr/> <h3 id="step-22-lightgbm">Step 22: LightGBM</h3> <p>lightgbm is also popular in recent regression problem solutions and usually has faster computational speed and better performance than xgboost.</p> <p>We use the original <code class="language-plaintext highlighter-rouge">lightgbm</code> library here instead of the one included in the <code class="language-plaintext highlighter-rouge">sklearn</code> library - the code is slightly different between these two methods (same result though).</p> <p>Using <code class="language-plaintext highlighter-rouge">optuna</code> to optimize the hyperparameter with customized scorer:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nc">Dataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nc">Dataset</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">reference</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">)</span>

<span class="c1"># define a scorer
</span><span class="k">def</span> <span class="nf">rmsle_lgbm</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">define the metrics used in lightgbm hyper parameter tuning</span><span class="sh">'''</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">get_label</span><span class="p">())</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">mean_squared_log_error</span><span class="p">(</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="p">))</span>
    <span class="k">return</span> <span class="sh">'</span><span class="s">rmsle</span><span class="sh">'</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="bp">False</span>

<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">objective</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">regression</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">boosting_type</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">gbdt</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.03</span><span class="p">,</span> 
    <span class="sh">'</span><span class="s">verbose</span><span class="sh">'</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">feature_pre_filter</span><span class="sh">'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">num_leaves</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">num_leaves</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span> <span class="p">:</span><span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">lambda_l1</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_loguniform</span><span class="p">(</span><span class="sh">'</span><span class="s">lambda_l1</span><span class="sh">'</span><span class="p">,</span>  <span class="mf">1e-8</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> 
    <span class="sh">'</span><span class="s">lambda_l2</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_loguniform</span><span class="p">(</span><span class="sh">'</span><span class="s">lambda_l2</span><span class="sh">'</span><span class="p">,</span>  <span class="mf">1e-8</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> 
    <span class="sh">'</span><span class="s">bagging_fraction</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_uniform</span><span class="p">(</span><span class="sh">'</span><span class="s">bagging_fraction</span><span class="sh">'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">bagging_freq</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">bagging_freq</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">feature_fraction</span><span class="sh">'</span><span class="p">:</span>  <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_uniform</span><span class="p">(</span><span class="sh">'</span><span class="s">feature_fraction</span><span class="sh">'</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">min_data_in_leaf</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">min_data_in_leaf</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> 
    <span class="sh">'</span><span class="s">metric</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">custom</span><span class="sh">'</span> <span class="c1"># the key step to use the customized scorer
</span>     <span class="p">}</span>
    
    <span class="c1"># Cross-validation 
</span>    <span class="n">history</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nf">cv</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_boost_round</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">,</span> 
                 <span class="n">nfold</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">feval</span>  <span class="o">=</span> <span class="n">rmsle_lgbm</span><span class="p">,</span> <span class="n">stratified</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">early_stopping_rounds</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>
    
    
    <span class="c1"># Save full set of parameters
</span>    <span class="n">trial</span><span class="p">.</span><span class="nf">set_user_attr</span><span class="p">(</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    
    <span class="c1"># Save the number of boosting iterations selected by early stopping
</span>    <span class="n">trial</span><span class="p">.</span><span class="nf">set_user_attr</span><span class="p">(</span><span class="sh">'</span><span class="s">num_boost_round</span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">rmsle-mean</span><span class="sh">'</span><span class="p">]))</span>
    
    <span class="k">return</span> <span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">rmsle-mean</span><span class="sh">'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># returns CV error for the best trial
</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="nc">TPESampler</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span> 
<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="p">.</span><span class="nf">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="sh">'</span><span class="s">minimize</span><span class="sh">'</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
<span class="n">study</span><span class="p">.</span><span class="nf">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">timeout</span> <span class="o">=</span> <span class="mi">1200</span><span class="p">)</span>  
</code></pre></div></div> <p><em>actually we tried several times on finding the appropriate range for optimization</em></p> <p>Code below shows the optimized hyperparameters:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">params</span> <span class="o">=</span> <span class="n">study</span><span class="p">.</span><span class="n">best_trial</span><span class="p">.</span><span class="n">user_attrs</span><span class="p">[</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">]</span>
<span class="n">num_trees</span> <span class="o">=</span> <span class="n">study</span><span class="p">.</span><span class="n">best_trial</span><span class="p">.</span><span class="n">user_attrs</span><span class="p">[</span><span class="sh">'</span><span class="s">num_boost_round</span><span class="sh">'</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of boosting iterations: </span><span class="si">{</span><span class="n">num_trees</span><span class="si">}</span><span class="s"> </span><span class="se">\n</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Best parameters:</span><span class="sh">'</span><span class="p">)</span>
<span class="n">params</span> 
</code></pre></div></div> <p>output</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Number of boosting iterations: 1161 

Best parameters:
{'objective': 'regression',
 'boosting_type': 'gbdt',
 'learning_rate': 0.03,
 'verbose': -1,
 'feature_pre_filter': False,
 'num_leaves': 57,
 'max_depth': 7,
 'lambda_l1': 5.411628497557572e-05,
 'lambda_l2': 8.521369134520965,
 'bagging_fraction': 0.8835949442193235,
 'bagging_freq': 6,
 'feature_fraction': 0.3567273881450492,
 'min_data_in_leaf': 2,
 'metric': 'custom'}
</code></pre></div></div> <p>see the validation result</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lgbm1</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_boost_round</span> <span class="o">=</span> <span class="n">num_trees</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lgbm1</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">rmsle</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span> 
<span class="c1"># 0.374258 --- the best performance so far
</span></code></pre></div></div> <p>prediction on the test set:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictors</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">'</span><span class="s">[^A-Za-z0-9_]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nc">Dataset</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">final_lgb</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_boost_round</span> <span class="o">=</span> <span class="n">num_trees</span><span class="p">)</span>

<span class="c1"># consider the back transformation bias
</span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">final_lgb</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">predictors</span><span class="p">)</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">y_hat</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
<span class="n">final_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">final_lgb</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj</span>

<span class="c1"># prediction output
</span><span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">final_predict</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])</span>
<span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)</span>

<span class="n">submission</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">LightGBM model prediction.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">lightbgm</code> has its own feature importance plot, which is convenient.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lgb</span><span class="p">.</span><span class="nf">plot_importance</span><span class="p">(</span><span class="n">lgbm1</span><span class="p">,</span><span class="n">max_num_features</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
</code></pre></div></div> <p>original <code class="language-plaintext highlighter-rouge">lightgbm</code> machine does not support to be included in model stacking, therefore, the code below provides an alternative version of the model optimized with <code class="language-plaintext highlighter-rouge">sklearn</code> compatibility.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># StackingCVRegressor does not support original lgb machine,
# a alternative regressor which compatible with StackingCVRegressor is built
# with all the tuned parameters set.
</span><span class="n">LGBMSTACKmodel</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nc">LGBMRegressor</span><span class="p">(</span>
    <span class="n">boosting_type</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">boosting_type</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">num_leaves</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">num_leaves</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">max_depth</span><span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">reg_alpha</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">lambda_l1</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">reg_lambda</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">lambda_l2</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">bagging_fraction</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">bagging_fraction</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">bagging_freq</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">bagging_freq</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">feature_fraction</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">feature_fraction</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">min_data_in_leaf</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">min_data_in_leaf</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">n_estimators</span> <span class="o">=</span> <span class="n">num_trees</span>
<span class="p">)</span>
</code></pre></div></div> <h2 id="5-model-stacking">5. Model Stacking</h2> <p>Model stacking can be regarded as a model of the models - a nested one which uses the result of the first layer of models. - This technique can improve the performance to some extent but also increase the risk of overfitting and reduce the interpretability. More explanation will be introduced in other posts.</p> <p><code class="language-plaintext highlighter-rouge">StackingCVRegressor</code> from <code class="language-plaintext highlighter-rouge">mlxtend.regressor</code> is used for stacking models.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">stack</span> <span class="o">=</span> <span class="nc">StackingCVRegressor</span><span class="p">(</span><span class="n">regressors</span><span class="o">=</span><span class="p">[</span><span class="n">LS</span><span class="p">,</span> <span class="n">RF</span><span class="p">,</span> <span class="n">XGB</span><span class="p">,</span> <span class="n">LGBMSTACKmodel</span><span class="p">],</span> <span class="c1"># the models used
</span>                            <span class="n">meta_regressor</span><span class="o">=</span><span class="n">LGBMSTACKmodel</span><span class="p">,</span> <span class="c1"># the meta model
</span>                            <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="c1"># cross validation
</span>                            <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                            <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                            <span class="n">use_features_in_secondary</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="c1"># original dataset included
</span>                            <span class="n">store_train_meta_features</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                            <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
                           <span class="p">)</span>
<span class="c1"># get rid of the feature names, otherwise it will be errors(only take numpy arrays)
</span><span class="n">predictors_stack</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">.</span><span class="n">values</span>
<span class="n">X_test_stack</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">values</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Cross-Validation data with model stack:</span><span class="sh">'</span><span class="p">,</span>
      <span class="o">-</span><span class="nf">cross_val_score</span><span class="p">(</span><span class="n">stack</span><span class="p">,</span>
                       <span class="n">X</span> <span class="o">=</span> <span class="n">predictors_stack</span><span class="p">,</span>
                       <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span>
                       <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span>
                       <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">,).</span><span class="nf">mean</span><span class="p">()</span> <span class="p">)</span>
<span class="c1"># 0.37202 - better than lightgbm
</span>
<span class="n">stack</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors_stack</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># back transformation bias modification
</span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">stack</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">predictors_stack</span><span class="p">)</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">y_hat</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
<span class="n">final_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">stack</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test_stack</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj</span>

<span class="c1"># prediction of the test set
</span><span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">final_predict</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])</span>
<span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)</span>
<span class="n">submission</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">{} model prediction.csv</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">'</span><span class="s">Stacking</span><span class="sh">'</span><span class="p">),</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>

</code></pre></div></div> <h2 id="6-result">6. Result</h2> <p>The test set, which is the criterion for evaluating the generalization, shows that <code class="language-plaintext highlighter-rouge">lightgbm</code> has the best performance - model stacking is slightly overfitting. (see results in Kaggle competition)</p> <h1 id="reflection">Reflection</h1> <p>There are still a lot of possibilities we do not have enough time to try or optimise. Briefly speaking:</p> <ul> <li>We did not include the neural networks although we have tried but cannot make the result reproducible, it seems that the neural network requires more fixed random seed settings. And the <strong>neural network performs relatively bad, it takes hours of training to achieve a slightly better performance than linear regression</strong>. It is a good idea to <strong>include neural networks into the model stacking</strong> as this is neither linear nor tree-based (similar algorithms improve the stacking result little).</li> <li> <table> <tbody> <tr> <td>The natural language processing techniques are relatively simple, it is considered to use <strong>word2Vec</strong> ([Word2Vec</td> <td>TensorFlow Core](https://www.tensorflow.org/tutorials/text/word2vec)) so that the sentences(some variables we dropped) can be vectorized to extract useful information. This technique is quite complex though.</td> </tr> </tbody> </table> </li> <li>As for linear regression models, only simple linear and regularised ones are tested. There are <strong>elastic net (combining the ridge and lasso), splines, and generalised additive models</strong> that are not tested. Although I do not hold a positive expectation about their performance as the relationship is clearly non-linear with so many features. Tree-based models perform better in this kind of dataset by my experience. However, they can always be included in the model stacking.</li> </ul>]]></content><author><name></name></author><category term="ML"/><summary type="html"><![CDATA[Airbnb Price Prediction]]></summary></entry></feed>