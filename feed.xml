<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ryanque.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ryanque.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-25T13:34:00+00:00</updated><id>https://ryanque.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">A Typical ML Project Workflow</title><link href="https://ryanque.github.io/blog/2022/airbnb6810/" rel="alternate" type="text/html" title="A Typical ML Project Workflow"/><published>2022-10-22T00:00:00+00:00</published><updated>2022-10-22T00:00:00+00:00</updated><id>https://ryanque.github.io/blog/2022/airbnb6810</id><content type="html" xml:base="https://ryanque.github.io/blog/2022/airbnb6810/"><![CDATA[<h2 id="introduction">Introduction</h2> <p><em>This blog post was initially written in 2022 as a summary of a in-class ML project, which won the first place in terms of model performance. <a href="https://www.kaggle.com/c/qbus6810-2021-sem2-regression">check this link.</a> I led a team of 5 and took the responsibility of most EDA, data transformation and feature engineering parts. XGB and LightGBM were tuned and trained by me.</em></p> <p><em>I put a lot of efforts into the project and still took this project as a basic framework for ML projects. Mistakes and shortcomings made in the project constantly inspire me sebsequently.</em></p> <p>The post covers the common practices in a regression ML problem with a real-life dataset given by Airbnb. This is written in a fairly detailed manner, while deeper explanantion of certain techniques are not included.</p> <h3 id="problem-statement">Problem Statement</h3> <p>Airbnb is a global platform that runs an online marketplace for short term travel rentals.</p> <p>Targeting the Airbnb market, the task is developing an advice service for hosts, property managers, and real estate investors.</p> <p>To achieve the project’s goals, we are provided with a dataset containing detailed information on a number of existing Airbnb listings in Sydney. The team has two tasks:</p> <ol> <li> <p>To develop a predictive model for the daily prices of Airbnb rentals based on state-of-the-art techniques from statistical learning. This model will and allow the company to advise hosts on pricing and to help owners and investors to predict the potential revenue of Airbnb rental (which also depends on the occupancy rate).</p> </li> <li> <p>To obtain at least three insights that can help hosts to make better decisions. What are the best hosts doing?</p> </li> </ol> <h3 id="the-procedures-in-a-nutshell">The Procedures in a Nutshell</h3> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/CRISP_DM_Diag-480.webp 480w,/assets/img/posts/airbnb6810/CRISP_DM_Diag-800.webp 800w,/assets/img/posts/airbnb6810/CRISP_DM_Diag-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/CRISP_DM_Diag.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="12%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="caption"> CRISP-DM Process Diagram </div> <p>As shown in the image, the workflow of such machine learning project is highly <strong>iterative</strong>.</p> <p>Although this article is presented as the order of the jupyter notebook, the final version is a result of several iterations of the whole process. EDA, feature engineering and modelling benefit from each other.</p> <h2 id="preparation">Preparation</h2> <h3 id="i-loading-libraries">I. Loading Libraries</h3> <details><summary>Click here for codes</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">missingno</span> <span class="k">as</span> <span class="n">msn</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="n">warnings</span>
<span class="kn">import</span> <span class="n">scipy</span> <span class="k">as</span> <span class="n">sp</span>
<span class="kn">from</span> <span class="n">dataprep.eda</span> <span class="kn">import</span> <span class="n">plot</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="n">xgboost</span> <span class="kn">import</span> <span class="n">XGBRegressor</span><span class="p">,</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_log_error</span><span class="p">,</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span> <span class="n">lightgbm</span> <span class="k">as</span> <span class="n">lgb</span>
<span class="kn">import</span> <span class="n">re</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">import</span> <span class="n">optuna</span>
<span class="kn">from</span> <span class="n">optuna.samplers</span> <span class="kn">import</span> <span class="n">TPESampler</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">from</span> <span class="n">mlxtend.regressor</span> <span class="kn">import</span> <span class="n">StackingCVRegressor</span></code></pre></figure> </details> <p>Some configuration for better output display:</p> <details><summary>Click here for codes</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># filter warnings
</span><span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="nf">set_option</span><span class="p">(</span><span class="sh">'</span><span class="s">display.max_columns</span><span class="sh">'</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>

<span class="c1"># set plot display mode
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="c1"># or
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">notebook</span></code></pre></figure> </details> <h3 id="ii-reproducibility">II. Reproducibility</h3> <p>The random seed determines whether the results would be the same when others want to re-run the code. Reproducibility is particularly <strong>important for sharing</strong> the work.</p> <p>There are several sources about this problem:</p> <blockquote> <p><a href="https://scikit-learn.org/stable/common_pitfalls.html#randomness">10. Common pitfalls and recommended practices — scikit-learn 1.0.2 documentation</a></p> </blockquote> <blockquote> <p><a href="https://stackoverflow.com/questions/52746279/how-to-get-absolutely-reproducible-results-with-scikit-learn">python - How to get absolutely reproducible results with Scikit Learn? - Stack Overflow</a></p> </blockquote> <p>At least the two random seed mentioned below should be determined, because different models/splitting techniques uses different random seeding system.</p> <p>In some models, <code class="language-plaintext highlighter-rouge">random_state</code> should be defined inside the model initializing code, instead of in this global setting.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span></code></pre></figure> <h3 id="iii-read-data">III. Read Data</h3> <details><summary>Click here for codes</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">traindf</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">train.csv</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">traindf</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>

<span class="c1"># data shape, data type, and non-null counts
</span><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">the number of columns: </span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">the number of observations: </span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">*</span><span class="sh">'</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">info</span><span class="p">()</span>

<span class="c1"># random 5 observations for general understanding:
</span><span class="n">df</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="c1">#.head or .tail work fine as well, esp. in time series data</span></code></pre></figure> </details> <h2 id="data-understanding--cleaning">Data Understanding &amp; Cleaning</h2> <p>Understanding data, cleaning and transforming data, and exploratory data analysis often go together and are done in an <strong>iterative</strong> manner.</p> <p>We are doing these steps based on grouping the features by their meaning and the logic would be more coherent.</p> <p><strong>There are 2 principles throughout the whole process :</strong></p> <p><strong>1. As the goal is predicting the price, it is better to think from the perspective of the hosts and users. Considering the situation when we want to book an accommodation on Airbnb and what affects our decision, or when we want to post an accommodation on Airbnb and what factors influence our pricing - these factors are usually considered the key features (which still need statistical evidences).</strong></p> <p><strong>2. When dealing with unstructured data, the process of converting them into structured data should reduce the information loss to the minimum.</strong></p> <h3 id="iv-missing-values">IV. Missing Values</h3> <p>The library <code class="language-plaintext highlighter-rouge">missingno</code> provides several useful plots for understanding the missing value:</p> <blockquote> <p><a href="https://coderzcolumn.com/tutorials/data-science/missingno-visualize-missing-data-in-python">missingno - Visualize Missing Data in Python (coderzcolumn.com)</a></p> </blockquote> <p>Methods include:</p> <ol> <li>their distribution - <code class="language-plaintext highlighter-rouge">.matrix</code></li> <li>proportion/amount - <code class="language-plaintext highlighter-rouge">.bar</code></li> <li>relationship - <code class="language-plaintext highlighter-rouge">.heatmap</code> and <code class="language-plaintext highlighter-rouge">.dendrogram</code></li> </ol> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># drop the columns without missing values for plotting
</span><span class="n">missingvalue_query</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span>
<span class="n">missingvalue_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="n">missingvalue_query</span><span class="p">]]</span>

<span class="c1"># bar chart for missing values
</span><span class="n">msn</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">missingvalue_df</span><span class="p">,</span>
        <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span>
        <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">lightsteelblue</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/barchar-480.webp 480w,/assets/img/posts/airbnb6810/barchar-800.webp 800w,/assets/img/posts/airbnb6810/barchar-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/barchar.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="60%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>Insights:</strong></p> <ul> <li><code class="language-plaintext highlighter-rouge">description</code>, <code class="language-plaintext highlighter-rouge">host_location</code>, <code class="language-plaintext highlighter-rouge">bathrooms_text</code>, <code class="language-plaintext highlighter-rouge">bedrooms</code>, <code class="language-plaintext highlighter-rouge">beds</code> are features with a small portion of missing values.</li> <li><code class="language-plaintext highlighter-rouge">response_time</code> and <code class="language-plaintext highlighter-rouge">response_rate</code> are features with over a half missing values.</li> </ul> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># missing value heatmap
</span><span class="n">msn</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">missingvalue_df</span><span class="p">,</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">24</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span></code></pre></figure> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/heatmap-480.webp 480w,/assets/img/posts/airbnb6810/heatmap-800.webp 800w,/assets/img/posts/airbnb6810/heatmap-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/heatmap.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="60%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>Insights:</strong> High correlated columns have 3 groups:</p> <ul> <li>columns about reviews.</li> <li><code class="language-plaintext highlighter-rouge">neighbourbood</code> and <code class="language-plaintext highlighter-rouge">neighborhood_overview</code>.</li> <li><code class="language-plaintext highlighter-rouge">host_response_rate</code>, <code class="language-plaintext highlighter-rouge">host_response_time</code> <code class="language-plaintext highlighter-rouge">host_acceptance_rate</code></li> </ul> <p>The correlation could obviously explained by the fact that each group belongs to a certain category of information. If the hosts do not enter any data in that field, the columns would be left empty at the same time.</p> <h3 id="v-target-variable---price">V. Target Variable - ‘price’</h3> <p><code class="language-plaintext highlighter-rouge">price</code> column has the format <code class="language-plaintext highlighter-rouge">$XXX.XX</code>, which is in the <code class="language-plaintext highlighter-rouge">string</code> data type. We have to change it into <code class="language-plaintext highlighter-rouge">float</code> type.</p> <p><code class="language-plaintext highlighter-rouge">pandas</code> has a built-in function to do this. Set the <code class="language-plaintext highlighter-rouge">regex</code> parameter as <code class="language-plaintext highlighter-rouge">True</code></p> <p><em>The module <code class="language-plaintext highlighter-rouge">re</code> can also handle this, but <code class="language-plaintext highlighter-rouge">pandas</code> built-in parameters could handle a larger datset faster.</em></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># converting the price column's data type to float
</span><span class="n">df</span><span class="p">.</span><span class="n">price</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">price</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">[\$</span><span class="sh">'</span><span class="s">,]</span><span class="sh">"</span><span class="p">,</span><span class="sh">''</span><span class="p">,</span><span class="n">regex</span><span class="o">=</span> <span class="bp">True</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">dataprep.eda</code> provides a convenient tool for understanding the basic description of data</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># in step1, we have this line:
# from dataprep.eda import plot
</span><span class="nf">plot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>The output has quantile statistics, descriptive statistics, and several plots(histogram, KDE plot, normal Q-Q plot and Boxplot) for understanding the distribution.</p> <p><strong>Insights:</strong> <code class="language-plaintext highlighter-rouge">price</code> is right skewed.</p> <p><strong>NOTE:</strong> Some algorithms require a normal distributed target, which accords with the statistical model assumption for a better regression and prediction result. However, this is optional. Linear models may benefit, but for tree-based algorithm, it may make no big difference. Also, if the skewed data is transformed into a normal distributed one, there will be <strong>transformation bias</strong>, which should be considered when the model is used for prediction.</p> <blockquote> <p>An assey covering the issue: <a href="https://www.amazon.science/publications/identifying-and-overcoming-transformation-bias-in-forecasting-models">identifying-and-overcoming-transformation-bias-in-forecasting-models</a></p> </blockquote> <p>Here, a log transformation is used.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">log_price</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">price</span><span class="p">)</span>
</code></pre></div></div> <hr/> <p>The following steps will elaborate on pre-processing the predictors. There are more than 60 predictors and I decided to group them by their meaning.</p> <hr/> <h3 id="vi-predictors---basic-information">VI. Predictors - Basic Information</h3> <p>Features included: <code class="language-plaintext highlighter-rouge">['name','description]</code></p> <p>These two columns are entered by the host that can be subjective, no one will post any bad words about their accommodation. There are some missing values in the description - it reflects how much effort the host put into advertising it.</p> <p><strong>A new dummy variable created</strong> by:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">description_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">description</span><span class="p">.</span><span class="nf">isna</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</code></pre></div></div> <p><em>There will be similar missing value handling techniques later which will not be elaborated on.</em></p> <p>Then, a t-test is used to seek the difference in price between observations with or without description, the result is significant - there is a difference.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># a t-test for whether there are actually difference in price
</span><span class="n">a</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">description_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="bp">True</span><span class="p">]</span> 
<span class="n">b</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">description_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="bp">False</span><span class="p">]</span> 
<span class="n">sp</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">alternative</span> <span class="o">=</span> <span class="sh">'</span><span class="s">less</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># the output
# Ttest_indResult(statistic=-1.7525150053443874, pvalue=0.039850154641626216)
</span></code></pre></div></div> <p><strong>NOTE:</strong>: Actually, using NLP technique in the description to catch more precise information may be a better way - but would also create more dimensions in the dataset - trade-off*</p> <hr/> <h3 id="vii-predictors---host-related">VII. Predictors - Host Related</h3> <p>Features included:</p> <p><code class="language-plaintext highlighter-rouge">['host_name','host_since','host_location','host_about','host_response_time', 'host_response_rate','host_acceptance_rate','host_is_superhost', 'host_listings_count','host_total_listings_count', 'host_verifications','host_identity_verified']</code></p> <ol> <li><code class="language-plaintext highlighter-rouge">host_name</code></li> </ol> <p>check if every host has a unique host name</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">host_name</span> <span class="o">==</span> <span class="sh">'</span><span class="s">David</span><span class="sh">'</span><span class="p">].</span><span class="n">host_listings_count</span><span class="p">.</span><span class="nf">unique</span><span class="p">()</span>

<span class="c1">#output
</span><span class="nf">array</span><span class="p">([</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span> <span class="mf">23.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span> <span class="mf">27.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">])</span>
</code></pre></div></div> <p>Apparently, different hosts can have the same <code class="language-plaintext highlighter-rouge">host_name</code>, so this predictor is considered useless. <strong>dropped</strong></p> <ol> <li><code class="language-plaintext highlighter-rouge">host_since</code></li> </ol> <p>This column has the <code class="language-plaintext highlighter-rouge">object</code> datatype, and is considered to be converted into how many days to the day it is collected. <em>(however this is also not available, just for approximation, the day for subtraction is the day of Kaggle competition is launched, which is Sep 23rd 2021).</em></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># step 1, convert object to datetime
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># step 2, datetime substraction
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:(</span><span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="sh">'</span><span class="s">2021-09-23</span><span class="sh">'</span><span class="p">)</span><span class="o">-</span><span class="n">x</span><span class="p">).</span><span class="n">days</span><span class="p">)</span>
</code></pre></div></div> <p><strong>NOTE:</strong> <code class="language-plaintext highlighter-rouge">datetime</code> datatype can be calculated directly with <code class="language-plaintext highlighter-rouge">+</code> and <code class="language-plaintext highlighter-rouge">-</code>. And also can be transformed.</p> <blockquote> <p><a href="https://docs.python.org/3/library/datetime.html#datetime.datetime">datetime — Basic date and time types — Python 3.10.2 documentation</a></p> <p><a href="https://blog.csdn.net/DataCastle/article/details/84323603">pythonpandas.to_datetime_DataCastle-CSDN python to_datetime</a></p> </blockquote> <ol> <li><code class="language-plaintext highlighter-rouge">host_location</code></li> </ol> <p>This column is where the host lives instead of where the accommodation is, which is relatively less informative. However, if the host_location is the same as the location of the accommodation, the host may provide more satisfying services.</p> <p>A possible solution is constructing another column with the criterion: “host location == accomodation location”</p> <p>Due to the fact that the formats recording the host location and accomodation location are different, and it takes a lot of effort to transform, here we just simply <strong>drop</strong> the column.</p> <ol> <li><code class="language-plaintext highlighter-rouge">host_about</code></li> </ol> <p>This column is used for hosts introducing themselves, due to its large portion of missing values and subjective content, it is also considered to be less informative.</p> <p>However, this column might give information of whether the host are putting efforts on operating the account and advertising themselves.</p> <p>Here, I built a missing value indicator and <strong>dropped</strong> this predictor.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_about_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_about</span><span class="p">.</span><span class="nf">isna</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">host_about</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <ol> <li><code class="language-plaintext highlighter-rouge">host_response_rate</code> , <code class="language-plaintext highlighter-rouge">host_response_time</code> , <code class="language-plaintext highlighter-rouge">host_acceptance_rate</code></li> </ol> <p>It is mentioned in the missing value overview that these three columns has strong correlation in terms of missing values.</p> <p>These 3 columns are indicators of whether the host and the listing are active.</p> <blockquote> <p><a href="https://www.airbnb.com/resources/hosting-homes/a/sunderstanding-response-rate-and-acceptance-rate-86">Understanding response rate and acceptance rate - Resource Center - Airbnb</a></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># output
within an hour        4727
within a day          1470
within a few hours    1452
a few days or more     736
Name: host_response_time, dtype: int64
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">response_time</code> : It is a low-cardinality categorical variable and we <strong>fill the</strong> <code class="language-plaintext highlighter-rouge">na</code> <strong>value with</strong> <code class="language-plaintext highlighter-rouge">no response</code> <strong>as a new category</strong>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># host_response_time is categorical data:
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">no response</span><span class="sh">'</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">host_response_time</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">violin</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/responsetime-480.webp 480w,/assets/img/posts/airbnb6810/responsetime-800.webp 800w,/assets/img/posts/airbnb6810/responsetime-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/responsetime.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>From the plot above, the distribution of price are a bit different between different response time.</p> <p><code class="language-plaintext highlighter-rouge">host_response_rate</code> and <code class="language-plaintext highlighter-rouge">host_acceptance_rate</code> should be continuous variable, convert them from texts to float numbers, and built 2 missing value indicator variables.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()</span><span class="o">==</span><span class="bp">False</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()</span><span class="o">==</span><span class="bp">False</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># a binary variable to indicate the missing value
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>  <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># fill the missing value with 0
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()]</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div></div> </details> <ol> <li><code class="language-plaintext highlighter-rouge">host_is_superhost</code></li> </ol> <p>About the ‘superhost’ , I found an explanation in Airbnb website:</p> <blockquote> <p><a href="https://www.airbnb.com/d/superhost">Airbnb Superhost program details</a></p> </blockquote> <p>Superhost can be considered as an important factor of measuring the quality of service provided by the host, which will influence the price of the listing. - <em>This is just an assumption and will be statistically tested</em></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># first, convert the t/f column into 0/1 binary variable.
</span><span class="n">df</span><span class="p">.</span><span class="n">host_is_superhost</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_is_superhost</span><span class="p">.</span><span class="nf">map</span><span class="p">({</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_is_superhost</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_is_superhost</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">sp</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">alternative</span> <span class="o">=</span> <span class="sh">'</span><span class="s">greater</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># the output:
# Ttest_indResult(statistic=-0.19814543743616678, pvalue=0.5785333753025225)
</span></code></pre></div></div> <p><strong>Insights:</strong> Statistical test does not support the assumption. - host_is_superhost has no strong correlation with price. However, I did not choose to simply drop the column, there might be some <strong>interation effect</strong> together with other features.</p> <blockquote> <p><a href="https://stats.libretexts.org/Bookshelves/Applied_Statistics/Natural_Resources_Biometrics_(Kiernan)/06%3A_Two-way_Analysis_of_Variance/6.01%3A_Main_Effects_and_Interaction_Effect#:~:text=The%20interaction%20is%20the%20simultaneous,interaction%20effect%20between%20the%20factors.">About interation effect</a></p> </blockquote> <ol> <li><code class="language-plaintext highlighter-rouge">host_listing_count</code>, <code class="language-plaintext highlighter-rouge">host_total_listing_count</code></li> </ol> <p>These two columns are about the accommodations owned by the host.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">host_listings_count</span> <span class="o">==</span> <span class="n">df</span><span class="p">.</span><span class="n">host_total_listings_count</span><span class="p">).</span><span class="nf">unique</span><span class="p">()</span>

<span class="c1"># output:
# array([ True])
</span></code></pre></div></div> <p><strong>Insights:</strong> These two columns are <strong>identical</strong>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">host_total_listings_count</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="n">host_listings_count</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">().</span><span class="nf">sort_index</span><span class="p">()</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_listings_count</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_listings_count</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">sp</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">alternative</span> <span class="o">=</span> <span class="sh">'</span><span class="s">less</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># output:
# Ttest_indResult(statistic=-7.6451367678834385, pvalue=1.0896805499204671e-14)
</span></code></pre></div></div> <p><strong>Insights:</strong> Statistically tested, the fact that accommodation’s host having more than 1 listings, relates to a higher price. It can be explained that the host who has more than 1 listings are much more wealthy than the one with only one or less, whose accommodation might be more luxury, which leads to higher price.</p> <p>However, the explanation above indicates that there might be correlation between the accommodation’s condition with the <code class="language-plaintext highlighter-rouge">host_listings_count</code>, which will cause multicollinearity in linear models.(correlation is analysed later.)</p> <p><em>Clustering by the count of listings could be used for more precise result. Here I just keep the continuous variable.</em></p> <ol> <li><code class="language-plaintext highlighter-rouge">host_verifications</code>,<code class="language-plaintext highlighter-rouge">host_identity_verified</code></li> </ol> <p>These two columns are measuring whether the host’s identity is verified and to what extent they are verified. Verified ones with more verification methods are considered as more reliable host.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert the list-like string to list data type
</span><span class="n">df</span><span class="p">.</span><span class="n">host_verifications</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_verifications</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">strip</span><span class="p">(</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"'"</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">))</span>

<span class="c1"># convert the t/f to 1/0
</span><span class="n">df</span><span class="p">.</span><span class="n">host_identity_verified</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_identity_verified</span><span class="p">.</span><span class="nf">map</span><span class="p">({</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="c1"># counting the number of verification - how host varifies seems not a relevant indicator
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">num_host_verification</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_verifications</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">'</span><span class="s">num_host_verification</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">hue</span> <span class="o">=</span> <span class="sh">'</span><span class="s">host_identity_verified</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">boxen</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/verification-480.webp 480w,/assets/img/posts/airbnb6810/verification-800.webp 800w,/assets/img/posts/airbnb6810/verification-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/verification.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>Insights:</strong> It is observed that accommodations with identity-verified host will have slightly higher prices. With number of verification increasing, there is no obvious increment in price.</p> <h3 id="viii-predictors---location-related">VIII. Predictors - Location Related</h3> <p>By looking at some entries of the dataset:</p> <ul> <li> <p>four text predictors relate to the location of the accommodation:</p> <ol> <li><code class="language-plaintext highlighter-rouge">neighbourhood_cleansed</code> is the cleansed version of <code class="language-plaintext highlighter-rouge">neighbourhood</code> (no missing value and categorical compared with the original one.)</li> <li><code class="language-plaintext highlighter-rouge">neighborhood_overview</code> contains more precise information about the location, but it is recorded with human language which needs NLP techniques to extract useful information.</li> <li><code class="language-plaintext highlighter-rouge">host_neighbourhood</code> is the neighbourhood of the host, instead of the accommodation, which is useless.</li> </ol> </li> <li> <p>two continuous variables describe the exact location of the accommodation, which are the most precise location information.</p> </li> </ul> <p>Here, there are two things I did:</p> <ol> <li>drop useless predictors - <code class="language-plaintext highlighter-rouge">host_neighbourhood</code> and <code class="language-plaintext highlighter-rouge">neighbourhood</code></li> <li>Plotting the <code class="language-plaintext highlighter-rouge">longitude</code> and <code class="language-plaintext highlighter-rouge">latitude</code> with log_price - geometric distribution</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">latitude</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">longitude</span><span class="p">,</span>
           <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">4</span><span class="p">,</span>
           <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span>
           <span class="n">s</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
           <span class="n">c</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">log_price</span><span class="p">,</span>
           <span class="n">cmap</span> <span class="o">=</span> <span class="sh">"</span><span class="s">coolwarm</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">latitude</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">longitude</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Price geometric distribution</span><span class="sh">"</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">()</span>
<span class="n">a</span><span class="p">.</span><span class="nf">set_label</span><span class="p">(</span><span class="sh">'</span><span class="s">log_price</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/geometric_distribution-480.webp 480w,/assets/img/posts/airbnb6810/geometric_distribution-800.webp 800w,/assets/img/posts/airbnb6810/geometric_distribution-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/geometric_distribution.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>NOTE</strong>: This figure can be improved by using more advanced visualization technique. For example, 1) combining with the real map, 2) use some kind of density graph instead of this scatter plot.</p> <p><strong>Insights:</strong> It is observed from the plot that geometric location of the accommodation has some complex relationship with price.</p> <p>And these two variables are more complete, authentic and precise compared with <code class="language-plaintext highlighter-rouge">neighborhood_overview</code>. Therefore, <strong>we only keep <code class="language-plaintext highlighter-rouge">longitude</code> and <code class="language-plaintext highlighter-rouge">latitude</code>.</strong> <em>However, NLP can be used to extract useful information in the predictor<code class="language-plaintext highlighter-rouge">neighborhood_overview</code>.</em></p> <p><strong>NOTE</strong>:</p> <p>This step can be improved to optimise the performance of the predicting model.</p> <p>WHY?</p> <p>The place of the accommodation affect the price greatly in common sense. The closer the place is to the central area, the more expensive it would be.</p> <p>HOW?</p> <p>Possible solution: Make a grid map that divide the whole area into 100*100 blockas and 1)assigning each block an identifier and make it a feature or 2) clustering the blocks into different hierarch for less constructed features.</p> <p>Another possible solution: divide the map by postcode, such information could be found in government website.</p> <h3 id="ix-predictors---accommodation-related">IX. Predictors - Accommodation Related</h3> <p>The quality and facilities of the accommodation are the key factors in determining the price, based on common sense.</p> <ol> <li><code class="language-plaintext highlighter-rouge">Property_type</code></li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">property_type</span><span class="p">.</span><span class="nf">unique</span><span class="p">()</span>
</code></pre></div></div> <p><strong>Insights:</strong> From the output, This predictors can be taken as categorical with high cardinality, but also can be taken as human language and can be reduced by NLP techniques.</p> <p><em>This part will be elaborated in the Feature Engineering part.</em></p> <ol> <li><code class="language-plaintext highlighter-rouge">room_type</code></li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">room_type</span><span class="p">.</span><span class="nf">unique</span><span class="p">()</span>
<span class="c1"># Result shows that there are only 4 categories in this predictor
</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="sh">"</span><span class="s">room_type</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">y</span> <span class="o">=</span> <span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span>
            <span class="n">kind</span> <span class="o">=</span> <span class="sh">"</span><span class="s">violin</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/room_type-480.webp 480w,/assets/img/posts/airbnb6810/room_type-800.webp 800w,/assets/img/posts/airbnb6810/room_type-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/room_type.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>Insights:</strong> The plot shows that private room and shared room are relatively low in price while entire home/apt and hotel room are relatively high in price.</p> <ol> <li><code class="language-plaintext highlighter-rouge">accommodates</code></li> </ol> <p>This column indicates the amount of people to live in the place.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">accommodates</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">boxen</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/accommodates-480.webp 480w,/assets/img/posts/airbnb6810/accommodates-800.webp 800w,/assets/img/posts/airbnb6810/accommodates-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/accommodates.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>Insights:</strong> From the boxplot, it is observed that when <code class="language-plaintext highlighter-rouge">accommodates</code> are less than 10, the price has approximately positive linear relationship with <code class="language-plaintext highlighter-rouge">accommodates</code>. Accommodations with more than 10 <code class="language-plaintext highlighter-rouge">accommodates</code> has no obvious relationship with price.</p> <p><em>clustering can be used here - construct a indicator variable with the threshold of <code class="language-plaintext highlighter-rouge">accommodates = 10</code></em></p> <ol> <li><code class="language-plaintext highlighter-rouge">bathrooms_text</code></li> </ol> <p>Used <code class="language-plaintext highlighter-rouge">.unique()</code> and we see that the predictor can be separated into a number and an adjective. This part will also be elaborated on the feature engineering part.</p> <ol> <li><code class="language-plaintext highlighter-rouge">bedrooms</code></li> </ol> <p>use <code class="language-plaintext highlighter-rouge">value_counts()</code> - the amount of bedrooms vary from 1 to 16, and there are missing values.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># na means no bedroom
</span><span class="n">df</span><span class="p">.</span><span class="n">bedrooms</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">bedrooms</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">bedrooms</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span> 
               <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">boxen</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/bedrooms-480.webp 480w,/assets/img/posts/airbnb6810/bedrooms-800.webp 800w,/assets/img/posts/airbnb6810/bedrooms-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/bedrooms.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>Insights:</strong> the correlation is obvious positive but not linear.</p> <p><em>A new predictor with the value of <code class="language-plaintext highlighter-rouge">bedrooms**2</code> or more power can be constructed (I did not do it here, it would somehow impact the interpretability)</em></p> <p>And I performed the similar procedure with <code class="language-plaintext highlighter-rouge">beds</code> and find similar pattern.</p> <ol> <li><code class="language-plaintext highlighter-rouge">amenities</code></li> </ol> <p>This predictor can taken as a nested list and entered in the <code class="language-plaintext highlighter-rouge">string</code> format.</p> <p>The following steps did these things:</p> <ul> <li>convert the string into a list of lists</li> <li>count unrepeated items appeared in the deepest list.</li> </ul> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert the amenities column from string to list.
</span><span class="n">df</span><span class="p">.</span><span class="n">amenities</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">strip</span><span class="p">(</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"'"</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">))</span>

<span class="c1"># try to get all the unique items in the amenities list.
</span><span class="k">def</span> <span class="nf">GetAme</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    This function takes one parameter which should be a 2-times-nested list(list of lists)
    Return with a list with all the non-repeated items in the deepest list
    </span><span class="sh">"""</span>
    <span class="n">AmeList</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">AnObservation</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">AnObservation</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">'"'</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">AmeList</span><span class="p">:</span>
                <span class="n">AmeList</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">'"'</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">AmeList</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="nc">GetAme</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">amenities</span><span class="p">)))</span> <span class="c1"># output 623
</span></code></pre></div></div> </details> <p><em>This may not be the best way to analyse the predictor, because some of the amenities have the brand and repeatedly counted – some advanced NLP techniques can be used here to furthermore reduce the cardinality.</em></p> <p><strong>NOTE:</strong> Here we could draw a plot using price against amount of amenities.</p> <p>Again, further processes will be elaborated on in the feature engineering part.</p> <h3 id="x-predictors---availability-related">X. Predictors - Availability Related</h3> <ol> <li>night stay related</li> </ol> <p>including:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="sh">'</span><span class="s">minimum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">maximum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">minimum_minimum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">maximum_minimum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">minimum_maximum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">maximum_maximum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">minimum_nights_avg_ntm</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">maximum_nights_avg_ntm</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <p>Related Airbnb minimum night stay explanation:</p> <blockquote> <table> <tbody> <tr> <td>[What’s the Best Minimum Night Stay Policy on Airbnb?</td> <td>AirDNA](https://www.airdna.co/blog/whats-the-best-minimum-night-stay-policy-on-airbnb)</td> </tr> </tbody> </table> </blockquote> <p>Host can set minimum nights and maximum nights a customer can book for the accommodation. And such setting can vary in different period of time during the year, indicating a high/low season or the availability of the host.</p> <p>Longer minimum nights sometimes means lower price as the host will not have to bother in introducing and settling the accommodation.</p> <p>Based on life experience, in the high season, if there are strategy in changing the settings of the minimum nights and maximum nights, minimum nights and maximum nights will be shorter, and the situation will be the opposite in the low season.</p> <p><code class="language-plaintext highlighter-rouge">minimum_nights_avg_ntm</code> and <code class="language-plaintext highlighter-rouge">maximum_nights_avg_ntm</code> might be good predictors as it is the weighted average of the number of nights setting.</p> <p>The following codes categorize the minimum and maximum night stays, then plotted against the target <code class="language-plaintext highlighter-rouge">log_price</code>.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ClassifyNights</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">7</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">within a week</span><span class="sh">'</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">30</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">within a month</span><span class="sh">'</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">365</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">within a year</span><span class="sh">'</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">more than a year</span><span class="sh">'</span>

<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">cate_min_nights</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">minimum_nights_avg_ntm</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">ClassifyNights</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">cate_min_nights</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span> 
               <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">violin</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> </details> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/min_night-480.webp 480w,/assets/img/posts/airbnb6810/min_night-800.webp 800w,/assets/img/posts/airbnb6810/min_night-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/min_night.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">cate_max_nights</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">maximum_nights_avg_ntm</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">ClassifyNights</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">cate_max_nights</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span> 
               <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">violin</span><span class="sh">"</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/max_night-480.webp 480w,/assets/img/posts/airbnb6810/max_night-800.webp 800w,/assets/img/posts/airbnb6810/max_night-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/max_night.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>Insights:</strong> It seems that there is no big difference in price with different settings of minimum nights and maximum nights. The distribution does differ though.</p> <ol> <li>availabilities</li> </ol> <p>Features included:</p> <p><code class="language-plaintext highlighter-rouge">['has_availability','availability_30','availability_60', 'availability_90','availability_365','instant_bookable']</code></p> <p><code class="language-plaintext highlighter-rouge">has_availability</code> has the format of ‘t’s and ‘f’s</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># converting t/f to 1/0
</span><span class="n">df</span><span class="p">.</span><span class="n">has_availability</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">has_availability</span><span class="p">.</span><span class="nf">map</span><span class="p">({</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
<span class="n">df</span><span class="p">.</span><span class="n">instant_bookable</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">instant_bookable</span><span class="p">.</span><span class="nf">map</span><span class="p">({</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="c1">#plotting the has_availability against log_price
</span><span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">has_availability</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
               <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">violin</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/avail-480.webp 480w,/assets/img/posts/airbnb6810/avail-800.webp 800w,/assets/img/posts/airbnb6810/avail-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/avail.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="60%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><em>The same was done to <code class="language-plaintext highlighter-rouge">instant_bookable</code> and the plot shows no difference.</em></p> <p><strong>Insights:</strong> The availability in different time scale are indicators of whether the accommodation is popular or not. Less availability days are considered more popular.</p> <p><code class="language-plaintext highlighter-rouge">availability_365</code> is considered as a more robust indicator, <code class="language-plaintext highlighter-rouge">availability_30</code> can be used to compare with <code class="language-plaintext highlighter-rouge">availability_365</code> (in terms of ratio)to infer whether it is high/low season of the year.</p> <p>However, plots do not support the assumption mentioned above. Some difference (not obvious) in price is observed whether ratio of availability are high/low in the recent month.</p> <h3 id="xi-predictors---review-related">XI. Predictors - Review related</h3> <p>With all the predictor plotted against <code class="language-plaintext highlighter-rouge">log_price</code>, only one thing can be sure:</p> <p>Accommodations with high price rarely have bad rating.</p> <h3 id="xii-predictors---listing-related">XII. Predictors - Listing Related</h3> <p>No obvious relationship is found, so I simply omitted this part.</p> <hr/> <h3 id="xiii-test-set">XIII. Test set</h3> <p>All the data cleaning procedure should be both done in the training set and test set.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># examine whether columns are correct.
</span><span class="n">trainList</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">trainList</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">)</span>
<span class="n">trainList</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="sh">'</span><span class="s">log_price</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">trainList</span> <span class="o">==</span> <span class="nf">list</span><span class="p">(</span><span class="n">test</span><span class="p">.</span><span class="n">columns</span><span class="p">))</span>

<span class="c1"># the output should be:
# True
</span></code></pre></div></div> </details> <hr/> <h2 id="feature-engineering">Feature Engineering</h2> <h3 id="xiv-handling-features-with-natural-language">XIV. Handling features with natural language</h3> <ol> <li><code class="language-plaintext highlighter-rouge">property_type</code></li> </ol> <p>This feature descibes the type of the property. However, types are expressed with human language. The description can be devided by its word class:</p> <ul> <li> <p>adjective: ‘shared’,’private’,’entire’,etc. ;</p> </li> <li> <p>noun: ‘apartment’,’hotel’,’loft’,etc. .</p> </li> </ul> <p>Therefore, with clear pattern, it is processed by code below.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This nested for loop could be optimized. Due to the fact that the dataset is not too large, I just remain the code as-is.
</span><span class="n">property_word_totallist</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">anObs</span> <span class="ow">in</span> <span class="n">train</span><span class="p">.</span><span class="n">property_type</span><span class="p">:</span> <span class="c1"># collect all the non-repeated words in property type
</span>    <span class="n">anObs_low</span> <span class="o">=</span> <span class="n">anObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">anObs_low</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">aWord</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">aWord</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">property_word_totallist</span><span class="p">:</span>
            <span class="n">property_word_totallist</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">aword</span><span class="p">)</span>

<span class="c1"># Constructing detection columns for certain words
</span><span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type_wdlist</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">property_type</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">))</span>
<span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type_wdlist</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">property_type</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">testword</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">property_word_totallist</span><span class="p">):</span>
    <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">property_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">testword</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type_wdlist</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">testword</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">property_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">testword</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type_wdlist</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">testword</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">property_word_totallist</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">property_</span><span class="sh">'</span><span class="o">+</span> <span class="n">testword</span>
    
<span class="c1"># create a list for selected features
</span><span class="n">SelectedFeature</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># include the constructed columns in the dataset
</span><span class="k">for</span> <span class="n">afeature</span> <span class="ow">in</span> <span class="n">property_word_totallist</span><span class="p">:</span>
    <span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">afeature</span><span class="p">)</span>
</code></pre></div></div> </details> <ol> <li><code class="language-plaintext highlighter-rouge">bathroom_text</code></li> </ol> <p>3 predictors are constructed:</p> <ul> <li>the number of bathrooms</li> <li>whether the bath is private - 1 for private and 0 for not private</li> <li>whether the bath is shared - 1 for shared and 0 for not shared</li> </ul> <p><em>some of the description did not mention whether it is private and shared.</em></p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># same as how I processed property types, creating a non-repeated wordlist
</span><span class="n">bath_word_totallist</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">anObs</span> <span class="ow">in</span> <span class="n">train</span><span class="p">.</span><span class="n">bathrooms_text</span><span class="p">:</span>
    <span class="n">anObs_low</span> <span class="o">=</span> <span class="n">anObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">anObs_low</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">aword</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">aword</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">bath_word_totallist</span><span class="p">:</span>
            <span class="n">bath_word_totallist</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">aword</span><span class="p">)</span>

<span class="c1"># a function for counting the number of baths
</span><span class="k">def</span> <span class="nf">bathnum</span><span class="p">(</span><span class="n">AnObs</span><span class="p">):</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">AnObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">half</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">0.5</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">awd</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">anum</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">awd</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">anum</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">continue</span>

<span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">number_of_baths</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathnum</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">number_of_baths</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathnum</span><span class="p">)</span>

<span class="c1"># function for detecting whether the bath is private
</span><span class="k">def</span> <span class="nf">bathprivate</span><span class="p">(</span><span class="n">AnObs</span><span class="p">):</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">AnObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">half</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">0.5</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">private</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>

<span class="n">train</span><span class="p">[</span><span class="sh">"</span><span class="s">bath_private</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathprivate</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="sh">"</span><span class="s">bath_private</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathprivate</span><span class="p">)</span>

<span class="c1"># whether the bath is shared 
</span><span class="k">def</span> <span class="nf">bathshared</span><span class="p">(</span><span class="n">AnObs</span><span class="p">):</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">AnObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">half</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">0.5</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">shared</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    
<span class="n">train</span><span class="p">[</span><span class="sh">"</span><span class="s">bath_shared</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathshared</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="sh">"</span><span class="s">bath_shared</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathshared</span><span class="p">)</span>

<span class="c1"># add the 3 constructed predictors
</span><span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">number_of_baths</span><span class="sh">'</span><span class="p">)</span>
<span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">bath_private</span><span class="sh">'</span><span class="p">)</span>
<span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">bath_shared</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> </details> <ol> <li><code class="language-plaintext highlighter-rouge">amenities</code></li> </ol> <p>As mentioned above, <code class="language-plaintext highlighter-rouge">amenities</code> is a nested list, but entered as text data. There are several steps to extract information and constrcut features:</p> <ul> <li>turn the text data into an actual list</li> <li>construct a non-repeat wordlist for amenities</li> <li>construct features based on the wordlist</li> </ul> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># turn the string dtype into list
</span><span class="n">train</span><span class="p">.</span><span class="n">amenities</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"'"</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'"'</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">strip</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,  </span><span class="sh">"</span><span class="p">))</span>
<span class="n">test</span><span class="p">.</span><span class="n">amenities</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"'"</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'"'</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">strip</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,  </span><span class="sh">"</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">GetAme</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    This function takes one parameter which should be a 2-times-nested list(list of lists)
    Return with a list with all the non-repeated items in the deepest list
    </span><span class="sh">"""</span>
    <span class="n">AmeList</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">AnObservation</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">AnObservation</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">AmeList</span><span class="p">:</span>
                <span class="n">AmeList</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">AmeList</span>

<span class="n">Amenity_list</span> <span class="o">=</span> <span class="nc">GetAme</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">amenities</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">Amenity_list</span><span class="p">))</span> <span class="c1"># output 598
</span></code></pre></div></div> </details> <p>Too many unique items in this list - a new column for each unique item is not a good idea.</p> <p>Instead, I choose the items that occurred more than 30 times.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># a dictionary for counting the amount of times that such amenities occur
</span><span class="n">item_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">Amenity_list</span><span class="p">:</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">AnObs</span> <span class="ow">in</span> <span class="n">train</span><span class="p">.</span><span class="n">amenities</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">AnObs</span><span class="p">:</span>
            <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">item_dict</span><span class="p">[</span><span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">()]</span> <span class="o">=</span> <span class="n">counter</span>
    
<span class="n">freq_ame_list</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">akey</span> <span class="ow">in</span> <span class="n">item_dict</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">item_dict</span><span class="p">[</span><span class="n">akey</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">30</span><span class="p">:</span>
        <span class="n">freq_ame_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">akey</span><span class="p">)</span>
        
<span class="nf">len</span><span class="p">(</span><span class="n">freq_ame_list</span><span class="p">)</span> <span class="c1">#output 120, which is acceptable
</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_item</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">freq_ame_list</span><span class="p">):</span>
    <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">Amenity_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">_item</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nf">int</span><span class="p">(</span><span class="n">_item</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">Amenity_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">_item</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nf">int</span><span class="p">(</span><span class="n">_item</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">freq_ame_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Amenity_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">_item</span>


<span class="k">for</span> <span class="n">afeature</span> <span class="ow">in</span> <span class="n">freq_ame_list</span><span class="p">:</span>
    <span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">afeature</span><span class="p">)</span>
</code></pre></div></div> <p><strong>NOTE:</strong> The threshold for including the item is adjustable. Here I used 30. The larger the value is, the less features will be constructed.</p> <hr/> <h3 id="xv-encoding-the-categorical-data">XV. Encoding the categorical data</h3> <p>including : <code class="language-plaintext highlighter-rouge">host_response_time, neighbourhood_cleansed, room_type</code></p> <p>Encoding is automatically done by the <code class="language-plaintext highlighter-rouge">OneHotEncoder</code> in the <code class="language-plaintext highlighter-rouge">sklearn</code> package.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cate_col</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">neighbourhood_cleansed</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">room_type</span><span class="sh">'</span><span class="p">]</span>
<span class="n">OHEnc</span> <span class="o">=</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="n">OHcols</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">OHEnc</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">cate_col</span><span class="p">]),</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">OHEnc</span><span class="p">.</span><span class="nf">get_feature_names</span><span class="p">())</span>
<span class="n">OHcols_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">OHEnc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">cate_col</span><span class="p">]),</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">OHEnc</span><span class="p">.</span><span class="nf">get_feature_names</span><span class="p">())</span>

<span class="n">othercols</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">cate_col</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">othercols_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">cate_col</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">OHcols</span><span class="p">,</span><span class="n">othercols</span><span class="p">],</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">OHcols_test</span><span class="p">,</span><span class="n">othercols_test</span><span class="p">],</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> </details> <hr/> <h3 id="xvi-collecting-all-the-useful-predictors">XVI. Collecting all the useful predictors</h3> <p>In this example, I splitted all the predictors by its meaning and then did the cleaning and feature engineering. From my perspective, this is useful when there are many predictors that may affect the target.</p> <p>And a list can be constructed to store the filtered predictors’ name for further modelling usage.</p> <p><strong>The feature selection is highly iterative, the decision could be made from the business understanding, the EDA, the feature engineering, and also the modeling results.</strong></p> <hr/> <h2 id="modelling">Modelling</h2> <h3 id="xvii-preparation">XVII. Preparation</h3> <p>There are several procedures need to be done:</p> <ul> <li>Train-valid-test split</li> </ul> <p>In this example, a hidden test set is already given to evaluate the generalization.</p> <p>A second split (as train and validation set) needs to be done for hyperparameter optimisation. In most algorithms, I could use cross-validation - when the dataset is relatively small and computationally feasible.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictors</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">SelectedFeature</span><span class="p">]</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">log_price</span><span class="sh">'</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">SelectedFeature</span><span class="p">]</span> <span class="c1"># the final y_test is in log_price scale, remember to convert back.
</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>Define the RMSLE metric and scorer - The final result is evaluated by RMSLE (root mean squared log error)</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rmsle</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">mean_squared_log_error</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">y_valid</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="p">))</span>

<span class="c1"># log transformed target scorer
</span><span class="n">rmsle_scorer</span> <span class="o">=</span> <span class="nf">make_scorer</span><span class="p">(</span><span class="n">rmsle</span><span class="p">,</span> <span class="n">greater_is_better</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>rename the column names - <code class="language-plaintext highlighter-rouge">XGboost</code> and <code class="language-plaintext highlighter-rouge">LightGBM</code> have some issues regarding the column names</li> </ul> <blockquote> <p>XGboost: <a href="https://stackoverflow.com/questions/42338972/valueerror-feature-names-mismatch-in-xgboost-in-the-predict-function">python - ValueError: feature_names mismatch: in xgboost in the predict() function - Stack Overflow</a></p> <p>LightGBM: <a href="https://stackoverflow.com/questions/60698860/how-to-deal-with-do-not-support-non-ascii-characters-in-feature-name-error-whe">python - How to deal with “Do not support non-ASCII characters in feature name” error when I use lightGBM? - Stack Overflow</a></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">'</span><span class="s">[^A-Za-z0-9_]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="n">X_valid</span> <span class="o">=</span> <span class="n">X_valid</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">'</span><span class="s">[^A-Za-z0-9_]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">'</span><span class="s">[^A-Za-z0-9_]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
</code></pre></div></div> <p><strong>NOTE:</strong> This issue happens in certain versions of XBG and LGBM, so check the documentation if an error occurs.</p> <ul> <li>A function that generate output files</li> </ul> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">nameofmodel</span><span class="p">):</span>
    <span class="c1"># back transformation bias is considered.
</span>    <span class="sh">'''</span><span class="s"> this function takes two parameter,
    model - the already fitted model which has .predict() method
    nameofmodel - a string, the name of the model
    </span><span class="sh">'''</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">predictors</span><span class="p">)</span>
    <span class="n">residuals</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">y_hat</span>
    <span class="n">adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
    <span class="n">final_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj</span>
    <span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">final_predict</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">submission</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">{} model prediction.csv</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">nameofmodel</span><span class="p">),</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>
</code></pre></div></div> </details> <hr/> <h3 id="xviii-benchmark---simple-linear-regression">XVIII. Benchmark - Simple linear regression</h3> <p>Linear regression has a very strong assumption on the relationship between the predictors and target. - The model has good computation speed and interpretation ability but bad performance on prediction especialy when there are lots of predictors. - I use this as a benchmark model, and any model has a worse result will be considered useless.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">LR</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>

<span class="c1"># kfold is used for cross-validation - splitting the dataset into k segments
</span><span class="n">kfold</span> <span class="o">=</span> <span class="nc">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span> <span class="mi">5</span> <span class="p">,</span><span class="n">shuffle</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span> <span class="mi">42</span> <span class="p">)</span>

<span class="n">LR_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">LR</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE Benchmark with linear regression(cross-validation): {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">LR_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span>
<span class="c1"># result(in RMSLE): 0.423998
</span>
<span class="n">LR</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">LR</span><span class="p">,</span> <span class="sh">'</span><span class="s">linearRegression</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <hr/> <h3 id="xix-regularised-linear">XIX. Regularised Linear</h3> <p>Ridge and lasso are regularised linear regression algorithms, they use different penalty mechanism on the coefficient, avoiding it to be too large. These two methods increase the robustness of the prediction model.</p> <ul> <li><code class="language-plaintext highlighter-rouge">Ridge</code></li> </ul> <p>I use <code class="language-plaintext highlighter-rouge">gridsearchcv</code> to search for the best parameter, this is a simple hyperparameter tuning method that simply loop over all the parameters that needs calculation with cross validation.</p> <blockquote> <p><a href="https://scikit-learn.org/stable/modules/grid_search.html">3.2. Tuning the hyper-parameters of an estimator — scikit-learn 1.0.2 documentation</a></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RDparameters</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">]}</span>
<span class="n">RDopt</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="nc">Ridge</span><span class="p">(),</span><span class="n">RDparameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="n">RDopt</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span><span class="n">target</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">RDopt</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span> <span class="c1">#0.6
</span>
<span class="n">RD</span> <span class="o">=</span> <span class="nc">Ridge</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">RDopt</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">])</span>
<span class="n">RD_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">RD</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span> <span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Cross-Validation data with tuned Ridge: {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">RD_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span>
<span class="c1"># 0.423853
</span>
<span class="n">RD</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">RD</span><span class="p">,</span> <span class="sh">'</span><span class="s">Ridge</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">Lasso</code></li> </ul> <p>Same methods is used in <code class="language-plaintext highlighter-rouge">Lasso</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">LSparameters</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">:[</span><span class="mf">1e-07</span><span class="p">,</span><span class="mf">1e-06</span><span class="p">,</span><span class="mf">1e-05</span><span class="p">,</span><span class="mf">1e-04</span><span class="p">,</span><span class="mf">1e-03</span><span class="p">,</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">]}</span>
<span class="n">LSopt</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="nc">Lasso</span><span class="p">(),</span><span class="n">LSparameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="n">LSopt</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span><span class="n">target</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">LSopt</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span> <span class="c1">#0.0001
</span>
<span class="n">LS</span> <span class="o">=</span> <span class="nc">Lasso</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">LSopt</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">])</span>
<span class="n">LS_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">LS</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span> <span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Validation data with tuned Lasso: {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">LS_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span>
<span class="c1"># 0.423638
</span>
<span class="n">LS</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">LS</span><span class="p">,</span> <span class="sh">'</span><span class="s">Lasso</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p><strong>INSIGHTS:</strong> Ridge and Lasso did not obviously improve the model performance. Tree-based algorithms are therefore considered.</p> <hr/> <h3 id="xx-random-forest">XX. Random Forest</h3> <p>Instead of using decision tree, I choose random forest to get started. Random forest is more capable of diminishing the risk of overfitting.</p> <p><code class="language-plaintext highlighter-rouge">optuna</code> is used for optimizing the hyperparameters.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    
    <span class="c1"># configure the hyperparameters range to optimise
</span>    <span class="n">n_estimators</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">n_estimators</span><span class="sh">'</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">min_samples_leaf</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">max_features</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_categorical</span><span class="p">(</span><span class="sh">'</span><span class="s">max_features</span><span class="sh">'</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">auto</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sqrt</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">max_depth</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
    
    <span class="c1"># define the model that need to be used
</span>    <span class="n">RFmodel</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span><span class="p">,</span>  
                                  <span class="n">max_features</span> <span class="o">=</span> <span class="n">max_features</span><span class="p">,</span> 
                                  <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">min_samples_leaf</span><span class="p">,</span>
                                  <span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span><span class="p">,</span>
                                  <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
    
    <span class="c1"># define the criterion for the optimization
</span>    <span class="n">scores</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">RFmodel</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">kfold</span><span class="p">)</span>
    
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">loss</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="nc">TPESampler</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> 
<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="p">.</span><span class="nf">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="sh">'</span><span class="s">minimize</span><span class="sh">'</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
<span class="c1"># the timeout is set to be 30mins
# if you cannot wait that long, please shrink the timeout parameter below
# however, the longer, the more possible the model is well-tuned
</span><span class="n">study</span><span class="p">.</span><span class="nf">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">2400</span><span class="p">)</span> 
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RF_params</span> <span class="o">=</span> <span class="n">study</span><span class="p">.</span><span class="n">best_params</span>
<span class="n">RF</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">RF_params</span><span class="p">)</span>
<span class="n">RF_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">RF</span><span class="p">,</span>
                                <span class="n">X</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">,</span>
                                <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span>
                                <span class="n">scoring</span> <span class="o">=</span> <span class="n">rmsle_scorer</span><span class="p">,</span>
                                <span class="n">cv</span> <span class="o">=</span> <span class="n">kfold</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Cross-Validation with tuned Random Forest: {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">RF_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span>

<span class="n">RF</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">RF</span><span class="p">,</span> <span class="sh">'</span><span class="s">RandomForest</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> </details> <p>Then I plotted the feature importance for better interpretability.</p> <p>Feature importance in tree-based models is based on Gini importance / impurity.</p> <blockquote> <p><a href="https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html">scikit documentation</a></p> </blockquote> <p>the feature importance plotting function will be reused in other models.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_feature_importance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">max_features</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>  
    <span class="sh">'''</span><span class="s">
    This function is only available for models that has the feature_importances_ attribute.
    </span><span class="sh">'''</span>
    <span class="n">feature_importance</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="o">*</span><span class="mi">100</span>    
    <span class="n">feature_importance</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="p">(</span><span class="n">feature_importance</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">))</span>    
    <span class="n">table</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">labels</span><span class="p">).</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>    
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">table</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_features</span><span class="p">:</span>        
        <span class="n">table</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="n">max_features</span><span class="p">:].</span><span class="n">T</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="sh">'</span><span class="s">barh</span><span class="sh">'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>    
    <span class="k">else</span><span class="p">:</span>        
        <span class="n">table</span><span class="p">.</span><span class="n">T</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="sh">'</span><span class="s">barh</span><span class="sh">'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>    
    <span class="n">ax</span><span class="p">.</span><span class="nf">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="sa">u</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>     
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Variable importance</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>    
    <span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">()</span>    
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>

<span class="n">feature_names</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="nf">to_list</span><span class="p">()</span>

<span class="nf">plot_feature_importance</span><span class="p">(</span><span class="n">RF</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> </details> <p>The image shows like this:</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/randomForestPlot-480.webp 480w,/assets/img/posts/airbnb6810/randomForestPlot-800.webp 800w,/assets/img/posts/airbnb6810/randomForestPlot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/randomForestPlot.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>NOTE:</strong> If it is considered that the model is overfitting, we can perform the feature selection based on the image by choosing the top 5 or 10 features and redo the modelling.</p> <hr/> <h3 id="step-xxi-xgboost">Step XXI. XGBoost</h3> <p>XGBoost is widely used and perform relatively well in regression problems.</p> <p><code class="language-plaintext highlighter-rouge">GridSearchCV</code> was used for finding the optimised hyperparameters.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clf</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="nc">XGBRegressor</span><span class="p">(),</span>
                   <span class="p">{</span><span class="sh">'</span><span class="s">n_estimators</span><span class="sh">'</span><span class="p">:[</span><span class="mi">400</span><span class="p">,</span><span class="mi">500</span><span class="p">],</span>
                    <span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span>
                    <span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">:[</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.07</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,]},</span> 
                   <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                   <span class="n">scoring</span> <span class="o">=</span> <span class="n">rmsle_scorer</span><span class="p">,</span>
                  <span class="p">)</span>

<span class="n">X_xgb</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">.</span><span class="n">values</span>

<span class="n">clf_result</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_xgb</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">clf_result</span><span class="p">.</span><span class="n">best_score_</span><span class="p">)</span> 
<span class="c1"># -0.37892
</span><span class="nf">print</span><span class="p">(</span><span class="n">clf_result</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># learning_rate : 0.04, max_depth : 8, n_estimators : 500
</span></code></pre></div></div> <p>Train the model and predict, as well as plot the feature importance.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#configure the model 
</span><span class="n">XGB</span> <span class="o">=</span> <span class="nc">XGBRegressor</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">clf_result</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">],</span>
                       <span class="n">max_depth</span> <span class="o">=</span> <span class="n">clf_result</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">],</span>
                       <span class="n">n_estimators</span> <span class="o">=</span> <span class="n">clf_result</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">n_estimators</span><span class="sh">'</span><span class="p">],)</span>

<span class="c1"># cross validation
</span><span class="n">XGB_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">XGB</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">X_xgb</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span> <span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Cross-Validation data with tuned XGBoost: {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">XGB_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span> <span class="c1">#0.378497
</span>
<span class="c1"># predict with the trained model
</span><span class="n">XGB</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_xgb</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="n">X_test_xgb</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">values</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">XGB</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_xgb</span><span class="p">)</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">y_hat</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
<span class="n">final_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">XGB</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test_xgb</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj</span>
<span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">final_predict</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])</span>
<span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)</span>
<span class="n">submission</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">{} model prediction.csv</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">'</span><span class="s">XGBoost</span><span class="sh">'</span><span class="p">),</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>

<span class="c1"># print the feature importance plot
</span><span class="nf">plot_feature_importance</span><span class="p">(</span><span class="n">XGB</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> </details> <hr/> <h3 id="xxii-lightgbm">XXII. LightGBM</h3> <p>lightgbm is also popular in regression problem solutions and usually has faster computational speed and better performance than xgboost.</p> <p>We use the original <code class="language-plaintext highlighter-rouge">lightgbm</code> library here instead of the one included in the <code class="language-plaintext highlighter-rouge">sklearn</code> library - the code is slightly different between these two methods (same result though).</p> <p>Using <code class="language-plaintext highlighter-rouge">optuna</code> to optimize the hyperparameter with customized scorer:</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nc">Dataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nc">Dataset</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">reference</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">)</span>

<span class="c1"># define a scorer
</span><span class="k">def</span> <span class="nf">rmsle_lgbm</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">define the metrics used in lightgbm hyper parameter tuning</span><span class="sh">'''</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">get_label</span><span class="p">())</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">mean_squared_log_error</span><span class="p">(</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="p">))</span>
    <span class="k">return</span> <span class="sh">'</span><span class="s">rmsle</span><span class="sh">'</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="bp">False</span>

<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">objective</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">regression</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">boosting_type</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">gbdt</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.03</span><span class="p">,</span> 
    <span class="sh">'</span><span class="s">verbose</span><span class="sh">'</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">feature_pre_filter</span><span class="sh">'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">num_leaves</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">num_leaves</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span> <span class="p">:</span><span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">lambda_l1</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_loguniform</span><span class="p">(</span><span class="sh">'</span><span class="s">lambda_l1</span><span class="sh">'</span><span class="p">,</span>  <span class="mf">1e-8</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> 
    <span class="sh">'</span><span class="s">lambda_l2</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_loguniform</span><span class="p">(</span><span class="sh">'</span><span class="s">lambda_l2</span><span class="sh">'</span><span class="p">,</span>  <span class="mf">1e-8</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> 
    <span class="sh">'</span><span class="s">bagging_fraction</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_uniform</span><span class="p">(</span><span class="sh">'</span><span class="s">bagging_fraction</span><span class="sh">'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">bagging_freq</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">bagging_freq</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">feature_fraction</span><span class="sh">'</span><span class="p">:</span>  <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_uniform</span><span class="p">(</span><span class="sh">'</span><span class="s">feature_fraction</span><span class="sh">'</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">min_data_in_leaf</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">min_data_in_leaf</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> 
    <span class="sh">'</span><span class="s">metric</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">custom</span><span class="sh">'</span> <span class="c1"># the key step to use the customized scorer
</span>     <span class="p">}</span>
    
    <span class="c1"># Cross-validation 
</span>    <span class="n">history</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nf">cv</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_boost_round</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">,</span> 
                 <span class="n">nfold</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">feval</span>  <span class="o">=</span> <span class="n">rmsle_lgbm</span><span class="p">,</span> <span class="n">stratified</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">early_stopping_rounds</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>
    
    
    <span class="c1"># Save full set of parameters
</span>    <span class="n">trial</span><span class="p">.</span><span class="nf">set_user_attr</span><span class="p">(</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    
    <span class="c1"># Save the number of boosting iterations selected by early stopping
</span>    <span class="n">trial</span><span class="p">.</span><span class="nf">set_user_attr</span><span class="p">(</span><span class="sh">'</span><span class="s">num_boost_round</span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">rmsle-mean</span><span class="sh">'</span><span class="p">]))</span>
    
    <span class="k">return</span> <span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">rmsle-mean</span><span class="sh">'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># returns CV error for the best trial
</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="nc">TPESampler</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span> 
<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="p">.</span><span class="nf">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="sh">'</span><span class="s">minimize</span><span class="sh">'</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
<span class="n">study</span><span class="p">.</span><span class="nf">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">timeout</span> <span class="o">=</span> <span class="mi">1200</span><span class="p">)</span>  
</code></pre></div></div> </details> <p><em>actually we tried several times on finding the appropriate range for optimization</em></p> <p>Code below shows the optimized hyperparameters:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">params</span> <span class="o">=</span> <span class="n">study</span><span class="p">.</span><span class="n">best_trial</span><span class="p">.</span><span class="n">user_attrs</span><span class="p">[</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">]</span>
<span class="n">num_trees</span> <span class="o">=</span> <span class="n">study</span><span class="p">.</span><span class="n">best_trial</span><span class="p">.</span><span class="n">user_attrs</span><span class="p">[</span><span class="sh">'</span><span class="s">num_boost_round</span><span class="sh">'</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of boosting iterations: </span><span class="si">{</span><span class="n">num_trees</span><span class="si">}</span><span class="s"> </span><span class="se">\n</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Best parameters:</span><span class="sh">'</span><span class="p">)</span>
<span class="n">params</span> 
</code></pre></div></div> <p>Checking the validation result</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lgbm1</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_boost_round</span> <span class="o">=</span> <span class="n">num_trees</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lgbm1</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">rmsle</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span> 
<span class="c1"># 0.374258 --- the best performance so far
</span></code></pre></div></div> <p>prediction on the test set:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictors</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">'</span><span class="s">[^A-Za-z0-9_]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nc">Dataset</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">final_lgb</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_boost_round</span> <span class="o">=</span> <span class="n">num_trees</span><span class="p">)</span>

<span class="c1"># consider the back transformation bias
</span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">final_lgb</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">predictors</span><span class="p">)</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">y_hat</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
<span class="n">final_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">final_lgb</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj</span>

<span class="c1"># prediction output
</span><span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">final_predict</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])</span>
<span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)</span>

<span class="n">submission</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">LightGBM model prediction.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">lightbgm</code> has its own feature importance plot, which is convenient.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lgb</span><span class="p">.</span><span class="nf">plot_importance</span><span class="p">(</span><span class="n">lgbm1</span><span class="p">,</span><span class="n">max_num_features</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
</code></pre></div></div> <p>For the later model stacking, noted that original <code class="language-plaintext highlighter-rouge">lightgbm</code> machine does not support to be included in model stacking, therefore, the code below provides an alternative version of the model optimized with <code class="language-plaintext highlighter-rouge">sklearn</code> compatibility.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># StackingCVRegressor does not support original lgb machine,
# a alternative regressor which compatible with StackingCVRegressor is built
# with all the tuned parameters set.
</span><span class="n">LGBMSTACKmodel</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nc">LGBMRegressor</span><span class="p">(</span>
    <span class="n">boosting_type</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">boosting_type</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">num_leaves</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">num_leaves</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">max_depth</span><span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">reg_alpha</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">lambda_l1</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">reg_lambda</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">lambda_l2</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">bagging_fraction</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">bagging_fraction</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">bagging_freq</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">bagging_freq</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">feature_fraction</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">feature_fraction</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">min_data_in_leaf</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">min_data_in_leaf</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">n_estimators</span> <span class="o">=</span> <span class="n">num_trees</span>
<span class="p">)</span>
</code></pre></div></div> </details> <h2 id="5-model-stacking">5. Model Stacking</h2> <p>Model stacking can be regarded as a model of the models - a nested one which uses the result of the first layer of models. - This technique can improve the performance to some extent but also increase the risk of overfitting and largely reduce the interpretability.</p> <p><code class="language-plaintext highlighter-rouge">StackingCVRegressor</code> from <code class="language-plaintext highlighter-rouge">mlxtend.regressor</code> is used for stacking models.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">stack</span> <span class="o">=</span> <span class="nc">StackingCVRegressor</span><span class="p">(</span><span class="n">regressors</span><span class="o">=</span><span class="p">[</span><span class="n">LS</span><span class="p">,</span> <span class="n">RF</span><span class="p">,</span> <span class="n">XGB</span><span class="p">,</span> <span class="n">LGBMSTACKmodel</span><span class="p">],</span> <span class="c1"># the models being used
</span>                            <span class="n">meta_regressor</span><span class="o">=</span><span class="n">LGBMSTACKmodel</span><span class="p">,</span> <span class="c1"># the meta model
</span>                            <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="c1"># cross validation
</span>                            <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                            <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                            <span class="n">use_features_in_secondary</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="c1"># original dataset included
</span>                            <span class="n">store_train_meta_features</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                            <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
                           <span class="p">)</span>
<span class="c1"># get rid of the feature names, otherwise there will be errors(only take numpy arrays)
</span><span class="n">predictors_stack</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">.</span><span class="n">values</span>
<span class="n">X_test_stack</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">values</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Cross-Validation data with model stack:</span><span class="sh">'</span><span class="p">,</span>
      <span class="o">-</span><span class="nf">cross_val_score</span><span class="p">(</span><span class="n">stack</span><span class="p">,</span>
                       <span class="n">X</span> <span class="o">=</span> <span class="n">predictors_stack</span><span class="p">,</span>
                       <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span>
                       <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span>
                       <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">,).</span><span class="nf">mean</span><span class="p">()</span> <span class="p">)</span>
<span class="c1"># 0.37202 - better than lightgbm
</span>
<span class="n">stack</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors_stack</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># back transformation bias modification
</span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">stack</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">predictors_stack</span><span class="p">)</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">y_hat</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
<span class="n">final_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">stack</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test_stack</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj</span>

<span class="c1"># prediction of the test set
</span><span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">final_predict</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])</span>
<span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)</span>
<span class="n">submission</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">{} model prediction.csv</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">'</span><span class="s">Stacking</span><span class="sh">'</span><span class="p">),</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>

</code></pre></div></div> </details> <p>As a result, the model stacking did not improve the performance significantly, and later proved in the test set, it was overfiting.</p> <h2 id="result">Result</h2> <p>The test set, which is the criterion for evaluating the generalization on the unseen data, shows that <code class="language-plaintext highlighter-rouge">lightgbm</code> has the best performance - model stacking is slightly overfitting. (see results in Kaggle competition)</p> <h2 id="reflection">Reflection</h2> <p>The project was done in 2022, and I was lacking the experience in deeper analysis, as well as more complicated techniques in coding and modelling. There are still a lot of possibilities to try or optimise. Here are some of the possibilities:</p> <ul> <li> <p>We did not include the neural networks although we have tried but cannot make the result reproducible, it seems that the neural network requires more fixed random seed settings. And based on the result, the <strong>neural network performs relatively bad, it takes hours of training to achieve a slightly better performance than linear regression</strong>. It is a good idea to <strong>consider neural networks in the model stacking</strong> as this is neither linear nor tree-based (similar algorithms improve the stacking result little). Moreover, designing the structure and hyperparameter tuning is more complicated compared to the models mentioned above.</p> </li> <li> <table> <tbody> <tr> <td>The natural language processing techniques are relatively simple, it is considered to use <strong>word2Vec</strong> ([Word2Vec</td> <td>TensorFlow Core](https://www.tensorflow.org/tutorials/text/word2vec)) so that the sentences(some variables we dropped) can be vectorized to extract useful information.</td> </tr> </tbody> </table> </li> <li> <p>As for linear regression models, only simple linear and regularised ones are tested. There are <strong>elastic net (combining the ridge and lasso), SVM, splines, and generalised additive models</strong> that are not tested. Although I do not hold a positive expectation about their performance as the relationship is clearly non-linear with so many features. Tree-based models perform better in this kind of dataset by my experience. However, they can always be included in the model stacking.</p> </li> <li>Coding habits and structure is an issue as I went through the jupyter notebook. 1) Naming the variables - <code class="language-plaintext highlighter-rouge">anExampleVariableName</code> such naming pattern is considered a good habit. 2) splitting the notebook into several separate files and commnicating using .csv(for datasets) .py(for scripts) would be better to read, manage, and maintain if the project is an ongoing service.</li> </ul>]]></content><author><name></name></author><category term="ML"/><summary type="html"><![CDATA[Airbnb Price Prediction]]></summary></entry></feed>