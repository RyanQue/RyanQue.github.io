<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://ryanque.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://ryanque.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-26T15:30:52+00:00</updated><id>https://ryanque.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html"></title><link href="https://ryanque.github.io/blog/2024/2022-03-05-NLP6850_1/" rel="alternate" type="text/html" title=""/><published>2024-02-26T15:30:52+00:00</published><updated>2024-02-26T15:30:52+00:00</updated><id>https://ryanque.github.io/blog/2024/2022-03-05-NLP6850_1</id><content type="html" xml:base="https://ryanque.github.io/blog/2024/2022-03-05-NLP6850_1/"><![CDATA[<h2 id="introduction">Introduction</h2> <p><em>This blog post was initially written in 2022 as a summary of a in-class ML project. <a href="https://www.kaggle.com/competitions/qbus6850-2022s1-assignment/overview">check this link.</a> Several articles shed light upon the structure of the neural network I developed in this project, which gave me a basic idea of how to construct a neural network, as well as the modulized design behind the scene.</em></p> <p>This link contains <a href="https://github.com/RyanQue/backupRepo/tree/43cd3f76ce6272f44021584ecd3737a0fca0f6ee/githubPage/NLP6850">the files of the project</a>.</p> <p>In this blog, natural language processing and neural network are the major 2 parts that would be elaborate on, including several techniques, libraries that are usually would not be used when handling ordinary numerical data.</p> <h2 id="task-description">Task description</h2> <p>Customer review is important for the business to reflect on and improve the products/services. Due to the complex nature of human natural language, manually handing these unstructured data cannot fulfil the current business requirement.</p> <p>Sentiment Analysis can be adopted to categorize and sort the opinions by <em>positive, neutral, negative</em>. (could be more nuanced in the categories) It helps to understand what customers like/dislike about the product/service.</p> <p>In this project, machine learning methods are used to perform sentiment analysis &amp; classification to a dataset which contains Amazon customer reviews on Kindle Book.</p> <blockquote> <p>Dataset link: <a href="http://jmcauley.ucsd.edu/data/amazon/">Amazon review data (ucsd.edu)</a></p> </blockquote> <p>We only use 9000 samples from the dataset, with sensitive information pre-processed - thus only the review text (long text), summary (short text), and the rating (target, numerical, 1 to 5) are used in the modelling.</p> <p><strong>GOAL:</strong> build machine learning models that can predict the rating based on the text data.</p> <p>The metrics used for evaluation is the F1-score (weighted average F1-score of each label as this is a multi-label task)</p> <h2 id="procedures">Procedures</h2> <p>First of all, importing all the libraries, setting random seed, configuration, read data, etc..</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># basic EDA libs
</span><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">import</span> <span class="n">missingno</span> <span class="k">as</span> <span class="n">msn</span>
<span class="kn">import</span> <span class="n">warnings</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">import</span> <span class="n">math</span>

<span class="c1"># setting
</span><span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="nf">set_option</span><span class="p">(</span><span class="sh">"</span><span class="s">display.max_columns</span><span class="sh">"</span><span class="p">,</span> <span class="mi">20</span><span class="p">)</span>

<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="n">re</span>

<span class="kn">import</span> <span class="n">torch</span>

<span class="c1"># reproducibility (global setting)
</span><span class="n">torch</span><span class="p">.</span><span class="nf">manual_seed</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
<span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>

<span class="c1"># NLP libs
</span><span class="kn">import</span> <span class="n">pkg_resources</span>
<span class="kn">from</span> <span class="n">symspellpy</span> <span class="kn">import</span> <span class="n">SymSpell</span><span class="p">,</span> <span class="n">Verbosity</span>

<span class="kn">from</span> <span class="n">nltk.tokenize</span> <span class="kn">import</span> <span class="n">word_tokenize</span>
<span class="kn">from</span> <span class="n">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="kn">import</span> <span class="n">string</span>
<span class="kn">import</span> <span class="n">contractions</span>
<span class="kn">import</span> <span class="n">html</span>
<span class="kn">import</span> <span class="n">spacy</span>

<span class="c1"># run line below if the lib is never used before
# spacy.cli.download("en_core_web_sm")
</span><span class="n">spacyNLP</span> <span class="o">=</span> <span class="n">spacy</span><span class="p">.</span><span class="nf">load</span><span class="p">(</span><span class="sh">"</span><span class="s">en_core_web_sm</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># read data
</span><span class="n">originData</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">train.csv</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># create a deep copy - make sure the original dataset is not changed.
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">originData</span><span class="p">.</span><span class="nf">copy</span><span class="p">(</span><span class="n">deep</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
</code></pre></div></div> </details> <h3 id="i-eda">I EDA</h3> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>
</code></pre></div></div> <table> <thead> <tr> <th style="text-align: left"> </th> <th style="text-align: left">rating</th> <th style="text-align: left">reviewText</th> <th>summary</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">1306</td> <td style="text-align: left">4</td> <td style="text-align: left">I really enjoyed this book because it ended on…</td> <td>Surviving The Game</td> </tr> <tr> <td style="text-align: left">4120</td> <td style="text-align: left">5</td> <td style="text-align: left">This is a very dark and twisted tale of the da…</td> <td>Very twisted</td> </tr> <tr> <td style="text-align: left">4422</td> <td style="text-align: left">1</td> <td style="text-align: left">Thank heavens this was an Amazon freebie when …</td> <td>Failed resurrection.</td> </tr> </tbody> </table> <ul> <li><code class="language-plaintext highlighter-rouge">rating</code> -numerical, the target</li> <li><code class="language-plaintext highlighter-rouge">reviewText</code> - longer text review, feature</li> <li> <p><code class="language-plaintext highlighter-rouge">summary</code> - shorter text review, feature</p> </li> <li>check missing value <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">msn</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">lightsteelblue</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div> </div> <p><strong>INSIGHTS:</strong> no missing value</p> </li> </ul> <h4 id="target---rating">target - <code class="language-plaintext highlighter-rouge">rating</code></h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="sh">'</span><span class="s">rating</span><span class="sh">'</span><span class="p">,</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/NLP6850/targetBar-480.webp 480w,/assets/img/posts/NLP6850/targetBar-800.webp 800w,/assets/img/posts/NLP6850/targetBar-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/NLP6850/targetBar.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>INSIGHTS:</strong></p> <ul> <li>This is a multi-classfication problem</li> <li><strong>Classes have rank relationship from 1 to 5, but the number does not imply the ratio.</strong></li> <li>slightly unbalanced dataset - 4 and 5 have more samples and 3 has less.</li> </ul> <h4 id="reviewtext"><code class="language-plaintext highlighter-rouge">reviewText</code></h4> <ul> <li>A histogram for counting the characters in the <code class="language-plaintext highlighter-rouge">reviewText</code></li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">reviewTextCharCount</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">reviewTextCharCount</span><span class="sh">'</span><span class="p">],</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/NLP6850/reviewTextBar-480.webp 480w,/assets/img/posts/NLP6850/reviewTextBar-800.webp 800w,/assets/img/posts/NLP6850/reviewTextBar-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/NLP6850/reviewTextBar.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>INSIGHTS:</strong></p> <p>The graph shows that there are some reviews that write a really long message while some just have a few words. Apparently right skewed.</p> <h4 id="summary"><code class="language-plaintext highlighter-rouge">summary</code></h4> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">summaryCharCount</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">summaryCharCount</span><span class="sh">'</span><span class="p">],</span> <span class="n">bins</span> <span class="o">=</span> <span class="mi">12</span><span class="p">)</span>
</code></pre></div></div> <p>The image shows that <code class="language-plaintext highlighter-rouge">summary</code> has much shorter length but it is also right skewed.</p> <h4 id="relation-between-the-target-and-a-feature">Relation between the target and a feature</h4> <p>The most accessible numerical feature is the length of review, plotting it against the rating to see if there is any difference.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">)</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="sh">'</span><span class="s">rating</span><span class="sh">'</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="sh">'</span><span class="s">summaryCharCount</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">showfliers</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span> <span class="n">ax1</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">boxplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="sh">'</span><span class="s">rating</span><span class="sh">'</span><span class="p">,</span><span class="n">y</span><span class="o">=</span><span class="sh">'</span><span class="s">reviewTextCharCount</span><span class="sh">'</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">showfliers</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax2</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">subplots_adjust</span><span class="p">(</span><span class="n">wspace</span><span class="o">=</span><span class="mf">0.4</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/NLP6850/featureXTarget-480.webp 480w,/assets/img/posts/NLP6850/featureXTarget-800.webp 800w,/assets/img/posts/NLP6850/featureXTarget-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/NLP6850/featureXTarget.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 80%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>INSIGHTS:</strong></p> <p>As is shown in the boxplot(outlier excluded), there is little difference in the length of reviews and summaries between different ratings.</p> <p>Review text length is less on rating 1 and 5, with other ratings have longer text, the difference is not abvious though.</p> <h4 id="relation-between-features">Relation between features</h4> <p>See if there is any similarity of words between two features. And plotting it against the target variable.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># define the overlap similarity score
# we use overlap instead of other methods 
# because the difference in length between two columns are quite big
</span><span class="k">def</span> <span class="nf">overlapSim</span><span class="p">(</span><span class="n">str1</span><span class="p">,</span> <span class="n">str2</span><span class="p">):</span>
    <span class="n">a</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">str1</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">split</span><span class="p">())</span> 
    <span class="n">b</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">str2</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">split</span><span class="p">())</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">a</span><span class="p">.</span><span class="nf">intersection</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
    <span class="k">return</span> <span class="nf">float</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">c</span><span class="p">))</span> <span class="o">/</span> <span class="nf">min</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">a</span><span class="p">),</span><span class="nf">len</span><span class="p">(</span><span class="n">b</span><span class="p">))</span>

<span class="n">overlapScoreResult</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span><span class="n">row</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">.</span><span class="nf">iterrows</span><span class="p">():</span>
    <span class="n">s1</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="n">reviewText</span>
    <span class="n">s2</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="n">summary</span>
    <span class="n">overlapScore</span> <span class="o">=</span> <span class="nf">overlapSim</span><span class="p">(</span><span class="n">s1</span><span class="p">,</span> <span class="n">s2</span><span class="p">)</span>
    <span class="n">overlapScoreResult</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">overlapScore</span><span class="p">)</span>

<span class="n">dataset</span><span class="p">.</span><span class="nf">insert</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>
              <span class="n">column</span> <span class="o">=</span> <span class="sh">'</span><span class="s">overlapScore</span><span class="sh">'</span><span class="p">,</span>
              <span class="n">value</span> <span class="o">=</span> <span class="n">overlapScoreResult</span><span class="p">)</span>

<span class="c1">#plotting the overlapscore
</span><span class="n">sns</span><span class="p">.</span><span class="nf">histplot</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">overlapScore</span><span class="sh">'</span><span class="p">],</span><span class="n">bins</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/NLP6850/overlap-480.webp 480w,/assets/img/posts/NLP6850/overlap-800.webp 800w,/assets/img/posts/NLP6850/overlap-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/NLP6850/overlap.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 80%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>There is a large proportion of reviews that its summary has no <strong>word similarity</strong> with its content.</p> <p>However, this does not necessarily mean they do not have <strong>semantic similarity</strong>, more advanced techniques(using trained model / vectorized representation / after normalization) can be used to analyse the sementical similarity.</p> <p>The reason why similarity is analysed here is that <code class="language-plaintext highlighter-rouge">summary</code> may not provide accurate attitude and will be elaborate on the longer <code class="language-plaintext highlighter-rouge">reviewText</code>.</p> <h3 id="ii-data-pre-processing">II Data Pre-processing</h3> <p>Some of the deeper EDAs is better done after pre-processing because dirty data would influence the accuracy of the analysis.</p> <p>Text is better transformed into numerical representation, in order to be fed to the model. Due to the fact that the Text-to-number is rather a complicated task for computer, cleaning the data is vital to mitigate the information loss/variation.</p> <p>Here is a typical example:</p> <ul> <li><code class="language-plaintext highlighter-rouge">'good', 'GOOD', 'Goooood', 'best', 'great', 'graet', 'good!'</code> should mean the same thing with only slight difference in terms of <strong>form, puntuation, upper/lower case, typo, etc.</strong>. But the model may consider them as different word if only simple methods is used to transform them.</li> </ul> <p>There are also many methods to tranform the texts into numbers:</p> <ol> <li>Bag of words</li> <li>TF-idf</li> <li>Advanced embedding method (vectorization)</li> </ol> <p><strong>NOTE that some methods may cause data leakage</strong> - methods that involve information in the test/validation set. - We should retrict these methods to be deployed in the training set only.</p> <h4 id="html-entities">html entities</h4> <p>There are html entities in the text, which need to be converted into its readable form.</p> <blockquote> <p><a href="https://www.w3schools.com/html/html_entities.asp">HTML Entities (w3schools.com)</a></p> </blockquote> <p>example: <code class="language-plaintext highlighter-rouge">&amp;#39;</code> -&gt; <code class="language-plaintext highlighter-rouge">'</code></p> <p>A python library <code class="language-plaintext highlighter-rouge">html</code> can deal with such entities</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">htmlEntityTran</span><span class="p">(</span><span class="n">DF</span><span class="p">,</span> <span class="n">columns</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">acol</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
        <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">]</span> <span class="o">=</span> <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">html</span><span class="p">.</span><span class="nf">unescape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div></div> <h4 id="contraction-expansion">contraction expansion</h4> <p>contraction should be expanded to its full text:</p> <p>example: <code class="language-plaintext highlighter-rouge">I'm</code> -&gt; <code class="language-plaintext highlighter-rouge">I am</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">contractionExpansion</span><span class="p">(</span><span class="n">DF</span><span class="p">,</span> <span class="n">columns</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">acol</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
        <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">]</span> <span class="o">=</span> <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">contractions</span><span class="p">.</span><span class="nf">fix</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</code></pre></div></div> <h4 id="punctuation-processing">punctuation processing</h4> <p>There are a lot of emoticons and misuse of punctuations in the text because the book reviews text is from online source without careful check.</p> <p>In the process below, we define all the possible emoticons(not comprehensive) that can be identified and process them with its meaning.</p> <p><em>The emoticon lists was copied from a repository in Github</em></p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">punctuationProcess</span><span class="p">(</span><span class="n">DF</span><span class="p">,</span> <span class="n">columns</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">acol</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
        <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">]</span> <span class="o">=</span> <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">puncFix</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        
<span class="n">smileEmo</span> <span class="o">=</span> <span class="sa">r</span><span class="sh">"""</span><span class="s">:-) :) :-] :] :-&gt; :&gt; 8-) 8) :-} :} :o) :c) :^) =] =) ^_^ ^^ :</span><span class="sh">'</span><span class="s">) :3 :-3 =3 x3 X3 (: (-: ))</span><span class="sh">"""</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span> 

<span class="n">laughEmo</span> <span class="o">=</span>  <span class="sa">r</span><span class="sh">"""</span><span class="s">:-D :D 8-D 8D =D =3 B^D c: x-D xD X-D XD C:]</span><span class="sh">"""</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>

<span class="n">winkEmo</span> <span class="o">=</span> <span class="sa">r</span><span class="sh">"""</span><span class="s">;-) ;) *-) *) ;-] ;] ;^) ;&gt; :-, ;D ;3</span><span class="sh">"""</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>

<span class="n">sadEmo</span> <span class="o">=</span> <span class="sa">r</span><span class="sh">"""</span><span class="s">:-( :( :-c :c :-&lt; :&lt; :-[ :[ :-|| &gt;:[ :{ :@ :( ;( :</span><span class="sh">'</span><span class="s">-( :</span><span class="sh">'</span><span class="s">( :=( :$ ): </span><span class="sh">"""</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>

<span class="n">skepEmo</span> <span class="o">=</span><span class="sa">r</span><span class="sh">"""</span><span class="s">
:-/ 
:/ 
:-. 
&gt;:\
&gt;:/
=/
=\
:L
=L
:S
:-|
:|
-_-
</span><span class="sh">"""</span><span class="p">.</span><span class="nf">split</span><span class="p">()</span>
           
<span class="n">stunEmo</span> <span class="o">=</span> <span class="sa">r</span><span class="sh">"""</span><span class="s">:-O :O :-o :o :-0 8‑0 &gt;:O =O =o =0 O_O o_o O-O o-o O_o o_O</span><span class="sh">"""</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">puncFix</span><span class="p">(</span><span class="n">row</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">emoticon</span> <span class="ow">in</span> <span class="n">smileEmo</span><span class="p">:</span>        
        <span class="n">row</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="n">emoticon</span><span class="p">,</span> <span class="sh">'</span><span class="s">smileface</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">emoticon</span> <span class="ow">in</span> <span class="n">laughEmo</span><span class="p">:</span>        
        <span class="n">row</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="n">emoticon</span><span class="p">,</span> <span class="sh">'</span><span class="s">laughface</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">emoticon</span> <span class="ow">in</span> <span class="n">winkEmo</span><span class="p">:</span>        
        <span class="n">row</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="n">emoticon</span><span class="p">,</span> <span class="sh">'</span><span class="s">winkface</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">emoticon</span> <span class="ow">in</span> <span class="n">sadEmo</span><span class="p">:</span>        
        <span class="n">row</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="n">emoticon</span><span class="p">,</span> <span class="sh">'</span><span class="s">sadface</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">emoticon</span> <span class="ow">in</span> <span class="n">skepEmo</span><span class="p">:</span>        
        <span class="n">row</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="n">emoticon</span><span class="p">,</span> <span class="sh">'</span><span class="s">skepticalface</span><span class="sh">'</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">emoticon</span> <span class="ow">in</span> <span class="n">stunEmo</span><span class="p">:</span>        
        <span class="n">row</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="n">emoticon</span><span class="p">,</span> <span class="sh">'</span><span class="s">stunnedface</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># ↑ emoticons processed
# ↓ special punctuations processed
</span>    <span class="n">row</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">$$</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">ss</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">$</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">money</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">w/</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">with</span><span class="sh">'</span><span class="p">)</span>
<span class="c1"># the 2 steps below are adding spaces between punctuation and character.
</span>    <span class="n">row</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">"""</span><span class="s">(?&lt;=[,.!</span><span class="sh">'"</span><span class="s">;:()*?/-])(?=[a-zA-Z])</span><span class="sh">"""</span><span class="p">,</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">,</span> <span class="n">row</span><span class="p">)</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">"""</span><span class="s">(?&lt;=[a-zA-Z])(?=[,.!</span><span class="sh">'"</span><span class="s">;:()*?/-])</span><span class="sh">"""</span><span class="p">,</span> <span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">,</span> <span class="n">row</span><span class="p">)</span>

<span class="c1"># render the repeating punctuations consistent
</span>    <span class="n">row</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">"</span><span class="s">[...][.]+</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">...</span><span class="sh">'</span><span class="p">,</span> <span class="n">row</span><span class="p">)</span>
    <span class="n">row</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sa">r</span><span class="sh">"</span><span class="s">[--][-]+</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">row</span><span class="p">)</span>

<span class="c1"># adding spaces before and after **
</span>    <span class="n">row</span> <span class="p">:</span> <span class="n">row</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'</span><span class="s">**</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s"> ** </span><span class="sh">'</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">row</span>
</code></pre></div></div> </details> <p>This process could be improved with much more careful look into the data samples and find relevant improvement potentials.</p> <p><strong>A tool to check the special punctuations are provided later in this section</strong></p> <h4 id="lower-case">lower case</h4> <p>This process turn any upper case into lower case.</p> <p>This process should be improved, there are several concerns regarding:</p> <ul> <li>upper case for intensify the emotions expressed</li> <li>upper case for abbreviation</li> </ul> <p>If simply transform all the characteristics into lower case, there could be some important information being dumped.</p> <p>In this project, we still define the function and use it with certain order (after some other procedures like counting uppercase amount) to avoid information loss.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># lower case
# A =&gt; a
</span><span class="k">def</span> <span class="nf">lowercaseCountTranformer</span><span class="p">(</span><span class="n">DF</span><span class="p">,</span> <span class="n">columns</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    This function transform all the characters into lower case,
    And store the number of upper case
    </span><span class="sh">"""</span>
    <span class="k">for</span> <span class="n">acol</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
        <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="o">+</span><span class="sh">'</span><span class="s">UpperCount</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="nf">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">x</span> <span class="k">if</span> <span class="n">c</span><span class="p">.</span><span class="nf">isupper</span><span class="p">()</span> <span class="p">)</span> <span class="p">)</span>
        <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">]</span> <span class="o">=</span> <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">())</span>
</code></pre></div></div> <h4 id="lemmatization-and-stemming">Lemmatization and Stemming</h4> <blockquote> <p><a href="https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html">Stemming and lemmatization (stanford.edu)</a> This website introduce the basic idea of lemmatization and stemming.</p> </blockquote> <p>In short word, Lemmatization transform the word into its original form precisely, considering the spelling, part of speech, comparative form, etc. - needs more computation power but provide better results in general. Stemming is relatively simple - chops off the ends of words to collapse the derivationally related words.</p> <p><strong>EXAMPLE:</strong></p> <p><code class="language-plaintext highlighter-rouge">saw</code> – lemma –&gt; <code class="language-plaintext highlighter-rouge">see </code> – little information loss</p> <p><code class="language-plaintext highlighter-rouge">saw</code> –stem–&gt; <code class="language-plaintext highlighter-rouge">s</code> – large information loss</p> <p>There are still more considerations in choosing these two methods to clean the data, which is <strong>task-specific</strong>.</p> <p>In this project, due to the small size of samples, we choose lemmatization which is provided by <code class="language-plaintext highlighter-rouge">spaCy</code> (standfordNLP library is too slow, I tried)</p> <blockquote> <p><a href="https://spacy.io/">spaCy · Industrial-strength Natural Language Processing in Python</a></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># lemmatization and stemming
# turn the word back to its original form
</span>
<span class="c1"># tokenization
# turning a sentense into a list of words
</span>
<span class="k">def</span> <span class="nf">LemmatizationTransform</span><span class="p">(</span><span class="n">DF</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Lemma</span><span class="sh">"</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    spacy is used but only the tokenization and lemmatization pipeline component is used.
    NLTK(also standfordNLP) has some similar functions but lack the precision and speed

    tokenization is also done by this step together in SpaCy
    </span><span class="sh">"""</span>
    <span class="k">for</span> <span class="n">acol</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="sh">"</span><span class="s">Lemma</span><span class="sh">"</span><span class="p">:</span>
            <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="o">+</span><span class="sh">'</span><span class="s">tokenized</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">[</span><span class="n">token</span><span class="p">.</span><span class="n">lemma_</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="nf">spacyNLP</span><span class="p">(</span><span class="n">row</span><span class="p">)])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="o">+</span><span class="sh">'</span><span class="s">tokenized</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span><span class="p">:</span> <span class="p">[</span><span class="n">token</span><span class="p">.</span><span class="n">text</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="nf">spacyNLP</span><span class="p">(</span><span class="n">row</span><span class="p">)])</span>
</code></pre></div></div> <h4 id="stop-word-removal">Stop word removal</h4> <p>stop word removal process is also <strong>task-specific</strong>. The goal of this project is predicting the sentiment which has negative and positive directions - Some stop words would indicate a turning point in the meaning that would possibly impact the sentiment. We customize the stop word list to fit our purpose of the project.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># check the stopword removal wordlist
</span><span class="nf">print</span><span class="p">(</span><span class="n">stopwords</span><span class="p">.</span><span class="nf">words</span><span class="p">(</span><span class="sh">'</span><span class="s">english</span><span class="sh">'</span><span class="p">))</span>
</code></pre></div></div> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">origin</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">stopwords</span><span class="p">.</span><span class="nf">words</span><span class="p">(</span><span class="sh">'</span><span class="s">english</span><span class="sh">'</span><span class="p">))</span>

<span class="n">wanted</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">what</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">but</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">against</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">down</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">up</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">on</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">off</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">over</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">under</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">out</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">same</span><span class="sh">'</span>
                <span class="sh">'</span><span class="s">again</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">further</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">why</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">what</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">how</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">all</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">any</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">with</span><span class="sh">'</span>
                <span class="sh">'</span><span class="s">few</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">more</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">most</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">other</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">no</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">nor</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">not</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">only</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">than</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">too</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">very</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">just</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">should</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ain</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">aren</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">aren</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">couldn</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">couldn</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">didn</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">didn</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">doesn</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">doesn</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">hadn</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">hadn</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">hasn</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">hasn</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">haven</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">haven</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">isn</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">isn</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">ma</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">mightn</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">mightn</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">mustn</span><span class="sh">'</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">mustn</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">needn</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">needn</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">shan</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">shan</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">shouldn</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">shouldn</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span>
                <span class="sh">'</span><span class="s">wasn</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">wasn</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">weren</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">weren</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">won</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">won</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">wouldn</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">wouldn</span><span class="sh">'</span><span class="s">t</span><span class="sh">"</span><span class="p">}</span>

<span class="n">unwanted</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">the</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">I</span><span class="sh">'</span><span class="p">,</span><span class="sh">"'</span><span class="s">s</span><span class="sh">"</span><span class="p">}</span>

<span class="n">StopWordCustom_Deep</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">origin</span> <span class="o">-</span> <span class="n">wanted</span> <span class="o">|</span> <span class="n">unwanted</span><span class="p">)</span>

<span class="n">StopWordCustom_Shallow</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">it</span><span class="sh">'</span><span class="s">s</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">their</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">re</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">she</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ours</span><span class="sh">'</span><span class="p">,</span> 
                          <span class="sh">'</span><span class="s">it</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ve</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">you</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">o</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">themselves</span><span class="sh">'</span><span class="p">,</span>
                          <span class="sh">'</span><span class="s">your</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">yours</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">m</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">you</span><span class="sh">'</span><span class="s">d</span><span class="sh">"</span><span class="p">,</span>
                          <span class="sh">"</span><span class="s">you</span><span class="sh">'</span><span class="s">re</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">and</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">its</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">you</span><span class="sh">'</span><span class="s">ve</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">that</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">ourselves</span><span class="sh">'</span><span class="p">,</span>
                          <span class="sh">'</span><span class="s">himself</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">this</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">been</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">you</span><span class="sh">'</span><span class="s">ll</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">an</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">my</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">me</span><span class="sh">'</span><span class="p">,</span>
                          <span class="sh">'</span><span class="s">myself</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">a</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">these</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">which</span><span class="sh">'</span><span class="p">,</span>
                          <span class="sh">'</span><span class="s">he</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">his</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">I</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">them</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">the</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"'</span><span class="s">s</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">yourselves</span><span class="sh">'</span><span class="p">,</span> 
                          <span class="sh">'</span><span class="s">our</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">s</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">yourself</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">theirs</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">herself</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">they</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">she</span><span class="sh">'</span><span class="s">s</span><span class="sh">"</span><span class="p">,</span>
                          <span class="sh">'</span><span class="s">hers</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">we</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">those</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">him</span><span class="sh">'</span><span class="p">,</span> <span class="sh">"</span><span class="s">that</span><span class="sh">'</span><span class="s">ll</span><span class="sh">"</span><span class="p">,</span> <span class="sh">'</span><span class="s">i</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">her</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">itself</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># stopword removal function
</span><span class="k">def</span> <span class="nf">stopWordRemove</span><span class="p">(</span><span class="n">DF</span><span class="p">,</span> <span class="n">columns</span><span class="p">,</span> <span class="n">deep</span> <span class="o">=</span> <span class="bp">True</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">acol</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">deep</span> <span class="o">==</span> <span class="bp">True</span><span class="p">:</span>
            <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">]</span> <span class="o">=</span> <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">alist</span><span class="p">:</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">alist</span> <span class="k">if</span> <span class="n">item</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">StopWordCustom_Deep</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">]</span> <span class="o">=</span> <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">alist</span><span class="p">:</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">alist</span> <span class="k">if</span> <span class="n">item</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">StopWordCustom_Shallow</span><span class="p">])</span>

</code></pre></div></div> </details> <h4 id="punctuation-removal">Punctuation removal</h4> <p>‘…’ and ‘!’ and ‘?’ would contain some information about the sentiment, other punctuations are relatively less informative.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># punctuation
# '...' and '!' and '?' would contain some information about the sentiment
</span><span class="n">punctList</span> <span class="o">=</span> <span class="nf">set</span><span class="p">(</span><span class="n">string</span><span class="p">.</span><span class="n">punctuation</span><span class="p">)</span>
<span class="n">puncwanted</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">!</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">?</span><span class="sh">'</span><span class="p">}</span>
<span class="n">puncunwanted</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s"> </span><span class="sh">'</span><span class="p">}</span>
<span class="n">punctList</span> <span class="o">=</span> <span class="n">punctList</span> <span class="o">-</span> <span class="n">puncwanted</span> <span class="o">|</span> <span class="n">puncunwanted</span> 

<span class="k">def</span> <span class="nf">punctRemover</span><span class="p">(</span><span class="n">DF</span><span class="p">,</span> <span class="n">columns</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">acol</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
        <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">]</span> <span class="o">=</span> <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">alist</span><span class="p">:</span> <span class="p">[</span><span class="n">item</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">alist</span> <span class="k">if</span> <span class="n">item</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">punctList</span><span class="p">])</span>
</code></pre></div></div> <h4 id="spell-mistakes-fix">Spell mistakes fix</h4> <p>It is noticed that in the dataset there are several misspells which affects the data quality. The library <code class="language-plaintext highlighter-rouge">symspell</code> do the job of fixing the spell mistakes. The algorithm is based on edit distance, and a special searching method to accelerate the process.</p> <blockquote> <p>The github page: <a href="https://github.com/wolfgarbe/SymSpell">wolfgarbe/SymSpell: SymSpell: 1 million times faster spelling correction &amp; fuzzy search through Symmetric Delete spelling correction algorithm (github.com)</a></p> <table> <tbody> <tr> <td>The algorithm: [1000x Faster Spelling Correction algorithm</td> <td>SeekStorm](https://seekstorm.com/blog/1000x-spelling-correction/)</td> </tr> </tbody> </table> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># the library also works on the punctuations, which we do not hope to happen.
# Therefore, we create a exception list where things in the list would not change
</span><span class="n">punctuationException</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">?</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">!</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">...</span><span class="sh">'</span><span class="p">}</span>
<span class="n">others</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">eh</span><span class="sh">'</span><span class="p">}</span>
<span class="n">symspellException</span> <span class="o">=</span> <span class="n">punctuationException</span> <span class="o">|</span> <span class="n">others</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sym_spell</span> <span class="o">=</span> <span class="nc">SymSpell</span><span class="p">(</span><span class="n">max_dictionary_edit_distance</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">prefix_length</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">dictionary_path</span> <span class="o">=</span> <span class="n">pkg_resources</span><span class="p">.</span><span class="nf">resource_filename</span><span class="p">(</span>
    <span class="sh">"</span><span class="s">symspellpy</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">frequency_dictionary_en_82_765.txt</span><span class="sh">"</span>
<span class="p">)</span>
<span class="c1"># term_index is the column of the term and count_index is the
# column of the term frequency
</span><span class="n">sym_spell</span><span class="p">.</span><span class="nf">load_dictionary</span><span class="p">(</span><span class="n">dictionary_path</span><span class="p">,</span> <span class="n">term_index</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">count_index</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">spellcheck</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
    <span class="n">checkedtokens</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">:</span>
        <span class="nf">if </span><span class="p">(</span><span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">symspellException</span><span class="p">)</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="n">token</span><span class="p">.</span><span class="nf">isnumeric</span><span class="p">()):</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">checkedtokens</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">sym_spell</span><span class="p">.</span><span class="nf">lookup</span><span class="p">(</span><span class="n">token</span><span class="p">,</span> <span class="n">Verbosity</span><span class="p">.</span><span class="n">CLOSEST</span><span class="p">,</span> <span class="n">max_edit_distance</span><span class="o">=</span><span class="mi">2</span><span class="p">)[</span><span class="mi">0</span><span class="p">].</span><span class="n">term</span><span class="p">)</span>
            <span class="k">except</span><span class="p">:</span>
                <span class="n">checkedtokens</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">checkedtokens</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">checkedtokens</span>

<span class="k">def</span> <span class="nf">spellCheckReplace</span><span class="p">(</span><span class="n">DF</span><span class="p">,</span> <span class="n">columns</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">acol</span> <span class="ow">in</span> <span class="n">columns</span><span class="p">:</span>
        <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">]</span> <span class="o">=</span> <span class="n">DF</span><span class="p">[</span><span class="n">acol</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">spellcheck</span><span class="p">)</span>
</code></pre></div></div> <h4 id="pre-process-pipeline">pre-process pipeline</h4> <p>We define all the cleaning processes as functions instead of directly doing it - so that we can <strong>create different levels of pre-process to fit certain structure of models.</strong></p> <p><strong>EXAMPLE:</strong></p> <ul> <li> <p>LSTM and CNN do consider the context of certain word - where some stop words would be kept.</p> </li> <li> <p>If BOW or TF-IDF is used for text representation - the order of the words is not considered - pre-process can be deep, removing all the noisy texts.</p> </li> </ul> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Workflow of deep preprocess
</span><span class="k">def</span> <span class="nf">DeepPreprocess</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="nf">htmlEntityTran</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># &amp;#34; =&gt; "
</span>    <span class="nf">contractionExpansion</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># I'm =&gt; I am
</span>    <span class="nf">punctuationProcess</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># add space before puncs; emoticon; normalize
</span>    <span class="nf">lowercaseCountTranformer</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># A =&gt; a ; add count column
</span>    <span class="nc">LemmatizationTransform</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># smiled =&gt; smile; tokenized
</span>    <span class="nf">stopWordRemove</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewTexttokenized</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summarytokenized</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># delete "I"
</span>    <span class="nf">punctRemover</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewTexttokenized</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summarytokenized</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># delete meaningless punctuation
</span>    <span class="nf">spellCheckReplace</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewTexttokenized</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summarytokenized</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># graet =&gt; great
</span>    
<span class="nc">DeepPreprocess</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

<span class="c1">#DeepPreprocess(dataset)
#subData = pd.read_csv('test.csv')
#DeepPreprocess(subData)
#subData.to_csv('preprocessedtest_deep.csv')
#dataset.to_csv('preprocessedtrain_deep.csv')
</span>
<span class="c1"># shallow preprocessing (for neural networks that can learn grammar)
</span><span class="k">def</span> <span class="nf">ShallowPreprocess</span><span class="p">(</span><span class="n">df</span><span class="p">):</span>
    <span class="nf">htmlEntityTran</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># &amp;#34; =&gt; "
</span>    <span class="nf">contractionExpansion</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># I'm =&gt; I am
</span>    <span class="nf">punctuationProcess</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># add space before puncs; emoticon; normalize
</span>    <span class="nf">lowercaseCountTranformer</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># A =&gt; a ; add count column
</span>    <span class="nc">LemmatizationTransform</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">],</span> <span class="n">mode</span> <span class="o">=</span> <span class="sh">"</span><span class="s">shallow</span><span class="sh">"</span><span class="p">)</span> <span class="c1"># only tokenized
</span>    <span class="nf">stopWordRemove</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewTexttokenized</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summarytokenized</span><span class="sh">'</span><span class="p">],</span> <span class="n">deep</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span> <span class="c1"># delete "I"
</span>    <span class="nf">punctRemover</span><span class="p">(</span><span class="n">df</span><span class="p">,[</span><span class="sh">'</span><span class="s">reviewTexttokenized</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">summarytokenized</span><span class="sh">'</span><span class="p">])</span> <span class="c1"># delete meaningless punctuation
</span>
<span class="c1"># run this to do shallow preprocess 
# keep the proposition 
# avoid using misspelling correction - 
# it may do wrongly and convert useful information to something else
</span>
<span class="c1">#subData = pd.read_csv('test.csv')
#ShallowPreprocess(dataset)
#ShallowPreprocess(subData)
</span>
<span class="n">subData</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">preprocessedtest_deep.csv</span><span class="sh">'</span><span class="p">)</span>
<span class="n">dataset</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">preprocessedtrain_deep.csv</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> </details> <h4 id="data-quality-checker">data quality checker</h4> <p>This is used for comparing between the original text and the modified/cleaned text.</p> <p>Keep iterating the process to improve.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">a</span> <span class="o">=</span> <span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">9000</span><span class="p">)</span>
<span class="c1">#a = 8983
</span><span class="nf">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">reviewTexttokenized</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">==============================</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">summarytokenized</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">==============================</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">==============================</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">******************************</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">originData</span><span class="p">[</span><span class="sh">'</span><span class="s">reviewText</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">==============================</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">originData</span><span class="p">[</span><span class="sh">'</span><span class="s">summary</span><span class="sh">'</span><span class="p">].</span><span class="n">iloc</span><span class="p">[</span><span class="n">a</span><span class="p">])</span>
</code></pre></div></div> <ul> <li>counting the length of different features</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="n">counter</span> <span class="o">=</span> <span class="nc">Counter</span><span class="p">()</span>

<span class="n">MaxLengthReview</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">MaxLengthSummary</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">reviewTexttokenized</span><span class="sh">'</span><span class="p">]:</span>
    <span class="n">counter</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">MaxLengthReview</span><span class="p">:</span>
        <span class="n">MaxLengthReview</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>

<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">summarytokenized</span><span class="sh">'</span><span class="p">]:</span>
    <span class="n">counter</span><span class="p">.</span><span class="nf">update</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">row</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">MaxLengthSummary</span><span class="p">:</span>
        <span class="n">MaxLengthSummary</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">row</span><span class="p">)</span>
        
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">MaxLengthReview</span><span class="sh">'</span><span class="p">,</span> <span class="n">MaxLengthReview</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">MaxLengthSummary</span><span class="sh">'</span><span class="p">,</span><span class="n">MaxLengthSummary</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>Check the punctuation to seek for improvement.</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">akey</span> <span class="ow">in</span> <span class="nf">sorted</span><span class="p">(</span><span class="n">counter</span><span class="p">.</span><span class="nf">keys</span><span class="p">()):</span>
    <span class="k">for</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">akey</span><span class="p">:</span>
        <span class="n">a</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">if</span> <span class="n">char</span> <span class="ow">in</span> <span class="n">string</span><span class="p">.</span><span class="n">punctuation</span><span class="p">:</span>
            <span class="n">a</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="mi">1</span>
    <span class="k">if</span> <span class="n">a</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
<span class="c1">#        if counter[akey]&gt;=2:
</span>        <span class="nf">print</span><span class="p">(</span><span class="n">akey</span><span class="p">,</span> <span class="sh">'</span><span class="s">|===&gt;</span><span class="sh">'</span><span class="p">,</span> <span class="n">counter</span><span class="p">[</span><span class="n">akey</span><span class="p">])</span> 
</code></pre></div></div> </details> <p>After data is pre-processed, a cleansed dataset is generated and stored in .csv format. and modelling would be done in seperated files.</p> <h3 id="iii-before-modelling">III Before Modelling</h3> <p>loading data etc..</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#Text is pre-processed
</span><span class="n">dataset</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">preprocessedtrain_deep.csv</span><span class="sh">'</span><span class="p">,</span>
                      <span class="n">index_col</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                      <span class="n">converters</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">reviewTexttokenized</span><span class="sh">'</span><span class="p">:</span> <span class="nb">eval</span><span class="p">,</span>
                                    <span class="sh">'</span><span class="s">summarytokenized</span><span class="sh">'</span><span class="p">:</span> <span class="nb">eval</span><span class="p">}</span>
                     <span class="p">)</span>

<span class="c1"># add more 2 features - the percentage of capital letters
</span><span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">reviewCapitalPer</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">reviewTextUpperCount</span><span class="sh">'</span><span class="p">]</span> <span class="o">/</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">reviewTextCharCount</span><span class="sh">'</span><span class="p">]</span>
<span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">summaryCapitalPer</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">summaryUpperCount</span><span class="sh">'</span><span class="p">]</span> <span class="o">/</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">summaryCharCount</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> </details> <h4 id="text-data-representation">Text Data Representation</h4> <p>Very common methods to represent text data include <strong>BoW</strong> (Bag of Words), <strong>TF-iDF</strong> (Term Frequency-Inverse Document Frequency).</p> <p>TF-iDF considers whether the word is important, while BoW only counts the occurrences. - TF-iDF usually work better in practice.</p> <blockquote> <p><a href="https://medium.com/@jyotikhetan2/a-practical-guide-to-tf-idf-and-term-frequency-in-text-analysis-b332c0405639">A Medium blog explaining TF-IDF</a></p> </blockquote> <ul> <li>Data leakage problem</li> </ul> <p>TF-iDF should be done after the splitting of train/valid/test data - otherwise there would be data leakage risk.</p> <blockquote> <p><strong>Why?</strong></p> \[TF(term\ frequency) = \frac {count\ of\ term\ in\ document }{number\ of\ words\ in\ document}\] \[iDF(inverse\ Document\ Frequency) =log( \frac{number\ of\ documents}{number\ of\ documents\ that\ have\ the\ term})\] <p>If test/valid data is not splitted in advance, TF-iDF calculation would contain information of the unseen data.</p> </blockquote> <p>To prevent data leakage - we use pipeline to make sure the TF-iDF calculation is after splitting.</p> <h4 id="stratified-split">Stratified Split</h4> <p>The imbalanced dataset pose a challenge for the model because most algorithms hold the assumption that each class has an equal number of examples.</p> <blockquote> <p><a href="https://machinelearningmastery.com/what-is-imbalanced-classification/">A Gentle Introduction to Imbalanced Classification (machinelearningmastery.com)</a></p> </blockquote> <p>In this project, imbalance is not severe, but for accuracy of the model, we use stratified split - making sure that the proportion of each class in test/valid/train dataset would be the same.</p>]]></content><author><name></name></author></entry><entry><title type="html">Customer Review Analysis and Neural Network Modelling - Modelling and Reflections</title><link href="https://ryanque.github.io/blog/2022/NLP6850_2/" rel="alternate" type="text/html" title="Customer Review Analysis and Neural Network Modelling - Modelling and Reflections"/><published>2022-03-05T00:00:00+00:00</published><updated>2022-03-05T00:00:00+00:00</updated><id>https://ryanque.github.io/blog/2022/NLP6850_2</id><content type="html" xml:base="https://ryanque.github.io/blog/2022/NLP6850_2/"><![CDATA[<h2 id="benchmark-models">Benchmark Models</h2> <p>This is a multi-classification problem and there are <strong>orders between each category</strong> - simply consider the prediction as a <strong>multi-classification</strong> model will result in bad performance as the order information is lost.</p> <p>One instinctive way to solve this:</p> <p>Consider the problem as a regression problem without specific restriction on the output. The the float numbers will be categorized to certain rating levels. Threshold here adopts the method of conforming to the previous level’s distribution. In other words, the proportion of each level in the training set is calculated and mapped these ‘percentiles’ into predicted results, to divide them into 5 classes.</p> <p>It shows that there are 1700 counts for rating 1, 1500 for rating 2, 1200 for rating 3, 2400 for rating 4 and 2200 for rating 5. Using these counts to calculate the proportion, then sort the predicted results from small to large, and split the predictions into classification results. In this way, all numbers are converted into ratings and have a reasonable distribution. Finally, predictions are restored to the original order.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">StratifiedKFold</span>

<span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span><span class="p">,</span> <span class="n">Pipeline</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>

<span class="n">allX</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">concattoken</span><span class="sh">'</span><span class="p">]</span><span class="c1"># ,'reviewCapitalPer','summaryCapitalPer'
</span><span class="n">ally</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">rating</span><span class="sh">'</span><span class="p">]</span>

<span class="c1"># split into train and test set
</span><span class="n">X_tr_va</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_tr_va</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">allX</span><span class="p">,</span> <span class="n">ally</span><span class="p">,</span>
                                                    <span class="n">test_size</span><span class="o">=</span><span class="mi">1</span><span class="o">/</span><span class="mi">6</span><span class="p">,</span>
                                                    <span class="n">random_state</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span> 
                                                    <span class="n">stratify</span> <span class="o">=</span> <span class="n">ally</span><span class="p">)</span>

<span class="c1"># Define the pipeline components
</span><span class="n">SKF</span> <span class="o">=</span> <span class="nc">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">12</span><span class="p">,</span> <span class="n">shuffle</span>  <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">TFVec</span> <span class="o">=</span> <span class="nc">TfidfVectorizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">,</span>
                        <span class="n">lowercase</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span>
                        <span class="n">max_df</span> <span class="o">=</span> <span class="mf">0.95</span><span class="p">,</span>
                        <span class="n">min_df</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
                        <span class="n">max_features</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
                        <span class="n">ngram_range</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">my_pipeline</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([(</span><span class="sh">'</span><span class="s">vectorizer</span><span class="sh">'</span><span class="p">,</span> <span class="n">TFVec</span><span class="p">),</span>
                        <span class="p">(</span><span class="sh">'</span><span class="s">GBR</span><span class="sh">'</span><span class="p">,</span> <span class="nc">GradientBoostingRegressor</span><span class="p">())</span>
                       <span class="p">])</span>

<span class="c1"># GridsearchCV for optimising the hyperparameters
</span><span class="n">searching_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">GBR__learning_rate</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">GBR__n_estimators</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">GBR__max_depth</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">GBR__subsample</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">grid_search</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="n">my_pipeline</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">searching_params</span><span class="p">,</span>
                           <span class="n">cv</span><span class="o">=</span><span class="n">SKF</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">neg_mean_squared_error</span><span class="sh">'</span><span class="p">)</span>
<span class="n">grid_search</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_tr_va</span><span class="p">,</span> <span class="n">y_tr_va</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">grid_search</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>

<span class="c1"># percentage of each categories
</span><span class="n">pred_y</span> <span class="o">=</span> <span class="n">grid_search</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">pred_y</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">pred_y</span><span class="p">)</span>
<span class="n">pred_y</span><span class="p">.</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y</span><span class="sh">'</span><span class="p">]</span>
<span class="n">dataset</span><span class="p">[</span><span class="sh">'</span><span class="s">rating</span><span class="sh">'</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">()</span>
<span class="n">w1</span> <span class="o">=</span> <span class="mi">1700</span><span class="o">/</span><span class="mi">9000</span>
<span class="n">w2</span> <span class="o">=</span> <span class="mi">1500</span><span class="o">/</span><span class="mi">9000</span>
<span class="n">w3</span> <span class="o">=</span> <span class="mi">1200</span><span class="o">/</span><span class="mi">9000</span>
<span class="n">w4</span> <span class="o">=</span> <span class="mi">2400</span><span class="o">/</span><span class="mi">9000</span>
<span class="n">w5</span> <span class="o">=</span> <span class="mi">2200</span><span class="o">/</span><span class="mi">9000</span>

<span class="c1"># calculate the percentile as threshold
</span><span class="n">threshold1</span> <span class="o">=</span> <span class="n">w1</span>
<span class="n">threshold2</span> <span class="o">=</span> <span class="n">w1</span><span class="o">+</span><span class="n">w2</span>
<span class="n">threshold3</span> <span class="o">=</span> <span class="n">w1</span><span class="o">+</span><span class="n">w2</span><span class="o">+</span><span class="n">w3</span>
<span class="n">threshold4</span> <span class="o">=</span> <span class="n">w1</span><span class="o">+</span><span class="n">w2</span><span class="o">+</span><span class="n">w3</span><span class="o">+</span><span class="n">w4</span>
<span class="nf">print</span><span class="p">(</span><span class="n">threshold1</span><span class="p">,</span><span class="n">threshold2</span><span class="p">,</span><span class="n">threshold3</span><span class="p">,</span><span class="n">threshold4</span><span class="p">)</span>

<span class="n">pred_y_sort</span> <span class="o">=</span> <span class="n">pred_y</span><span class="p">.</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="sh">'</span><span class="s">pred_y</span><span class="sh">'</span><span class="p">)</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">pred_y_sort</span><span class="p">,</span><span class="n">threshold1</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="n">t2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">pred_y_sort</span><span class="p">,</span><span class="n">threshold2</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="n">t3</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">pred_y_sort</span><span class="p">,</span><span class="n">threshold3</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="n">t4</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">percentile</span><span class="p">(</span><span class="n">pred_y_sort</span><span class="p">,</span><span class="n">threshold4</span><span class="o">*</span><span class="mi">100</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">t1</span><span class="p">,</span><span class="n">t2</span><span class="p">,</span><span class="n">t3</span><span class="p">,</span><span class="n">t4</span><span class="p">)</span>

<span class="c1"># The function for categorizing the final outcome
</span><span class="k">def</span> <span class="nf">cate</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">t1</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">t1</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">t2</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">2</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">t2</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">t3</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">3</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">t3</span> <span class="ow">and</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="n">t4</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">4</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&gt;</span> <span class="n">t4</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">5</span> 

<span class="n">pred_y</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y_cate</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pred_y</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">cate</span><span class="p">)</span>

<span class="n">y_test</span><span class="p">.</span><span class="nf">reset_index</span><span class="p">(</span><span class="n">drop</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
<span class="n">test_y</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>
<span class="n">test_y</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">test_y</span><span class="sh">'</span><span class="p">]</span>

<span class="n">est_reg</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">pred_y</span><span class="p">,</span><span class="n">test_y</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">est_reg</span>
</code></pre></div></div> </details> <h3 id="classification-method">classification method</h3> <p>As discussed in the previous section, this problem can also be considered as a pure multi-classification problem - ignoring the order information. The code below is implementing this idea.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>

<span class="n">my_pipeline_cla</span> <span class="o">=</span> <span class="nc">Pipeline</span><span class="p">([(</span><span class="sh">'</span><span class="s">vectorizer</span><span class="sh">'</span><span class="p">,</span> <span class="n">TFVec</span><span class="p">),</span>
                            <span class="p">(</span><span class="sh">'</span><span class="s">GBC</span><span class="sh">'</span><span class="p">,</span> <span class="nc">GradientBoostingClassifier</span><span class="p">())</span>
                           <span class="p">])</span>

<span class="n">searching_params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">GBC__learning_rate</span><span class="sh">'</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">GBC__n_estimators</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">200</span><span class="p">,</span> <span class="mi">400</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">GBC__max_depth</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">8</span><span class="p">],</span>
    <span class="sh">'</span><span class="s">GBC__subsample</span><span class="sh">'</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
<span class="p">}</span>

<span class="n">grid_search_cla</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="n">my_pipeline_cla</span><span class="p">,</span> <span class="n">param_grid</span><span class="o">=</span><span class="n">searching_params</span><span class="p">,</span>
                               <span class="n">cv</span><span class="o">=</span><span class="n">SKF</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="sh">'</span><span class="s">f1_weighted</span><span class="sh">'</span><span class="p">)</span>
<span class="n">grid_search_cla</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_tr_va</span><span class="p">,</span> <span class="n">y_tr_va</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">grid_search</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>

<span class="n">pred_y</span><span class="o">=</span> <span class="n">grid_search_cla</span><span class="p">.</span><span class="n">best_estimator_</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="n">pred_y</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">pred_y</span><span class="p">)</span>
<span class="n">pred_y</span><span class="p">.</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y</span><span class="sh">'</span><span class="p">]</span>
<span class="n">est_cla</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">pred_y</span><span class="p">,</span><span class="n">test_y</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">est_cla</span>
</code></pre></div></div> </details> <h3 id="model-evaluation-and-comparison">Model Evaluation and comparison</h3> <p>As is said in the task description, F1 score is used as the criteria for evaluating the model outcome.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span><span class="n">f1_score</span>

<span class="n">columns</span><span class="o">=</span><span class="p">[</span> <span class="sh">'</span><span class="s">Accuracy</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">F1 socre</span><span class="sh">'</span><span class="p">]</span>
<span class="n">rows</span><span class="o">=</span><span class="p">[</span><span class="sh">'</span><span class="s">Regression</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">Classification</span><span class="sh">'</span><span class="p">]</span>
<span class="n">results</span><span class="o">=</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">columns</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">rows</span><span class="p">)</span>

<span class="n">results</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">est_reg</span><span class="p">[</span><span class="sh">'</span><span class="s">test_y</span><span class="sh">'</span><span class="p">],</span> <span class="n">est_reg</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y_cate</span><span class="sh">'</span><span class="p">])</span>
<span class="n">results</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nf">f1_score</span><span class="p">(</span><span class="n">est_reg</span><span class="p">[</span><span class="sh">'</span><span class="s">test_y</span><span class="sh">'</span><span class="p">],</span> <span class="n">est_reg</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y_cate</span><span class="sh">'</span><span class="p">],</span> <span class="n">average</span> <span class="o">=</span> <span class="sh">'</span><span class="s">macro</span><span class="sh">'</span><span class="p">)</span>
<span class="n">results</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="nf">accuracy_score</span><span class="p">(</span><span class="n">est_cla</span><span class="p">[</span><span class="sh">'</span><span class="s">test_y</span><span class="sh">'</span><span class="p">],</span> <span class="n">est_cla</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y</span><span class="sh">'</span><span class="p">])</span>
<span class="n">results</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="nf">f1_score</span><span class="p">(</span><span class="n">est_cla</span><span class="p">[</span><span class="sh">'</span><span class="s">test_y</span><span class="sh">'</span><span class="p">],</span> <span class="n">est_cla</span><span class="p">[</span><span class="sh">'</span><span class="s">pred_y</span><span class="sh">'</span><span class="p">],</span> <span class="n">average</span> <span class="o">=</span> <span class="sh">'</span><span class="s">macro</span><span class="sh">'</span><span class="p">)</span>

<span class="n">results</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
</code></pre></div></div> <table> <thead> <tr> <th style="text-align: left"> </th> <th style="text-align: left">Accuracy</th> <th>F1 socre</th> </tr> </thead> <tbody> <tr> <td style="text-align: left">Regression</td> <td style="text-align: left">0.4267</td> <td>0.4266</td> </tr> <tr> <td style="text-align: left">Classification</td> <td style="text-align: left">0.4680</td> <td>0.4603</td> </tr> </tbody> </table> <p>The result shows that Classification method performs better than regression model, The reason could be - <strong>The evaluation metrics penalize the misclassification equally</strong>, <strong>but the regression model don’t treat the misclassification equally</strong>.</p> <h2 id="embedding-bilstm-cnn-ordinal-regression">Embedding-BiLSTM-CNN-ordinal regression</h2> <h3 id="embeddings">Embeddings</h3> <p>More advanced and modern way to represent text data is embedding.</p> <p>Considering the TF-IDF method of feature engineering creates too many dimensions and discards important information about the meaning of words in the context as it breaks the order of the words in the document.</p> <p>Global Vectors for Word Representation (GloVe) embedding is used to be the vectorized representation for the words in each document. The advantage of using GloVe is that it is able to capture the relationship between different words.</p> <p><strong>EXAMPLE</strong>: <code class="language-plaintext highlighter-rouge">excellent </code> and <code class="language-plaintext highlighter-rouge">brilliant </code> should be considered similar in terms of meaning and sentiment.</p> <p>Moreover, GloVe trains the weights based on the entire corpus which deals with the problem of some words’ rare occurrences. With pre-trained weights, GloVe reduces the bias caused by small datasets as there are only 9000 examples provided.</p> <blockquote> <table> <tbody> <tr> <td>more about embedding techniques: [NLP-101: Understanding Word Embedding</td> <td>Kaggle](https://www.kaggle.com/code/redwankarimsony/nlp-101-understanding-word-embedding/notebook)</td> </tr> </tbody> </table> </blockquote> <p>There are also other kinds of embedding techniques, such as word2vec (derivatives like sent2vec, doc2vec for longer texts), elmo, Fasttext, etc.</p> <blockquote> <table> <tbody> <tr> <td>[All about Embeddings - Word2Vec, Glove, FastText, ELMo, InferSent and Sentence-BERT</td> <td>Medium](https://medium.com/@kashyapkathrani/all-about-embeddings-829c8ff0bf5b)</td> </tr> </tbody> </table> </blockquote> <p>Actually, Glove embedding is also a bit out-of-date and the transformer representation is the current best performing solution for NLP in this field and it is still evolving with a large amount of data feeded in the pretrained model.</p> <blockquote> <p><a href="https://arxiv.org/abs/1810.04805">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (arxiv.org)</a></p> <p><a href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">Attention is All you Need (neurips.cc)</a></p> </blockquote> <p>In this project, only Glove is used as time is limited and Glove shows quite good speed.</p> <h3 id="bi-lstm">Bi-LSTM</h3> <p>Bidirectional long short-term memory(Bi-LSTM) networks are used to extract information in the <code class="language-plaintext highlighter-rouge">reviewText</code> column as this column contains much longer text data (up to 1200 words at maximum after cleaning). Bi-LSTM is expected to learn information about the information in the context of each node.</p> <p>A typical structure of single forward LSTM is shown below.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6850/BiLSTM-480.webp 480w,/assets/img/posts/airbnb6850/BiLSTM-800.webp 800w,/assets/img/posts/airbnb6850/BiLSTM-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6850/BiLSTM.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>An input node represents a GloVe transformed vector and is sent into the LSTM cell. By updating the hidden state of the cell, some information is preserved and some useless information is forgotten. A bidirectional LSTM combines two layers of LSTM which have opposite calculation directions. Works have proven that using the Bi-LSTM structure could enhance the performance of language models.</p> <h3 id="cnn">CNN</h3> <p>In 2014, Yoon Kim proposed a structure of the convolutional neural network that outperforms many other models. TextCNN structure consists of 2 main phases:</p> <ol> <li>Convolution phase. As the input is a series of word vectors that are converted by the embedding layer, kernels of the same dimension(width) but with different lengths are used to perform element-wise multiplication to the input matrix.</li> <li>After the activation function, the computed vectors are going through the max-pooling layer to keep the maximum value and then concatenate as the input of the final full connect to network. By interpreting the structure in tuition, the CNN can be used to extract information and learn useful patterns by combining adjacent words - phrases or small expressions.</li> </ol> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6850/textCNN-480.webp 480w,/assets/img/posts/airbnb6850/textCNN-800.webp 800w,/assets/img/posts/airbnb6850/textCNN-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6850/textCNN.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 80%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <h3 id="ordinal-regression">Ordinal Regression</h3> <p>As is aIready discussed, in this task, sentiments are not only positive and negative that can be treated as a traditional binary classification problem. The targets are <strong>ordered and have multiple classes</strong>. If this task is treated as a multi-class classification problem, information about the order is lost and surely will cause performance loss. If this task is treated as a regression problem, class 5 should have 5 times the sentiment of 1. And bias also occurs when thresholds are applied to the output.</p> <p>Therefore, the method to get the output should be <strong>consistent, ordered and unbiased</strong>. We are using the method used in age estimation in the image recognition field. The multiple outputs of the neural network represent the probability that the prediction is greater than a certain value of rank. This method has proven to be rank consistent and has better performance than existing classification and regression methods.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6850/ordinalReg-480.webp 480w,/assets/img/posts/airbnb6850/ordinalReg-800.webp 800w,/assets/img/posts/airbnb6850/ordinalReg-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6850/ordinalReg.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 80%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">An ariticle proposing a NN with the last layer using ordinal regression</figcaption> </figure> <h2 id="final-structure">Final structure</h2> <p>Considering <code class="language-plaintext highlighter-rouge">reviewText</code> data has long texts, the Bi-LSTM block is used after the embedding layer to learn context information around each word vector. Each step’s output of LSTM is used as the output to be learnt at the TextCNN block, in order to extract important information in specific areas. <code class="language-plaintext highlighter-rouge">summary</code> has much shorter words and can be directly learnt through TextCNN.</p> <p>In the forward propagation view, these two columns are separately learnt because we consider summary as a more important indicator of sentiments and reviewText serves as a fine-tune factor of the result. These two inputs should not share the same weights in the TextCNN block and are expected to be learnt in the network to have different importance.</p> <p>The whole structure visualization of Bi-LSTM-TextCNN-Ordinal regression is shown below.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6850/finalStructure-480.webp 480w,/assets/img/posts/airbnb6850/finalStructure-800.webp 800w,/assets/img/posts/airbnb6850/finalStructure-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6850/finalStructure.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 80%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <ul> <li>Up-left: the structure of the whole network;</li> <li>Up-right: the encoding methods for ordinal regression</li> <li>Downside: The output layer design</li> </ul> <p>Initially, we came up with 2 solutions to this issue. Firstly, we can simply regard the task as a regression task as in Task A, which proves to be less accurate than classification. We also tried to encode the target to a list of new targets which can represent the ordinal information. But this solution has a potential problem that sometimes we can not decode results. For example, if we get a result like [1,0,1,1,1], we can not easily define which group it belongs to.</p> <p>The final solution is using ordinal regression as is proposed. We tried to make the output layer have multiple outputs. Given that there are 5 categories, the target is one hot encoded, as shown in the structure, interpreted as the probability of the predicted value greater than 1 to 4. The loss function is designed as cross-entropy loss. For rank prediction, there will be 4 continuous outputs and the output channels will be marked as 1 if their value is greater than 0.5, and 0 if their value is less than 0.5. It is mathematically proved that the output will be rank consistent. The ultimate rank prediction uses the same decoding as one-hot.</p> <p>The result is that this model will have a much more stable performance than without such a technique - the standard deviation of the validation F1 score is much lower(which is observed in different epochs). However, the maximum value of the validation f1 score is not as large as the network without using this method.</p> <p>We also conducted several hyperparameter tuning but failed to find the optimized one that can outperform the gradient boosting classification model.</p> <table> <thead> <tr> <th>parameter</th> <th>base</th> <th>test1</th> <th>test2</th> <th>test3</th> <th>test4</th> <th>test5</th> <th>test6</th> <th>test7</th> <th>test8</th> <th>test9</th> <th>test10</th> <th>test11</th> <th>test12</th> </tr> </thead> <tbody> <tr> <td>batch_size</td> <td>128</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>epoch</td> <td>12</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>hidden_size</td> <td>100</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>200</td> <td>50</td> </tr> <tr> <td>dropout</td> <td>0.1</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>0.2</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>lstm_layers</td> <td>1</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>2</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>optimizerlearning rate</td> <td>0.001</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>0.0005</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>weight_decay</td> <td>0.001</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>0.005</td> <td>0.0005</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>kernel_num</td> <td>32</td> <td>-</td> <td>-</td> <td>16</td> <td>64</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>kernel_size</td> <td>2,3,4</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>2,4,6</td> <td>-</td> <td>-</td> </tr> <tr> <td>upper count</td> <td>false</td> <td>true</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>ordinal regression</td> <td>True</td> <td>-</td> <td>False</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> <td>-</td> </tr> <tr> <td>result (F1)</td> <td>0.402</td> <td>0.426</td> <td>0.443</td> <td>0.438</td> <td>0.440</td> <td>0.372</td> <td>0.442</td> <td>0.431</td> <td>0.409</td> <td>0.426</td> <td>0.423</td> <td>0.431</td> <td>0.426</td> </tr> </tbody> </table> <p>It is considered that the model is too complicated while the dataset is too small so that the model is not able to learn enough samples to have a decent prediction ability. Moreover, it is proposed that TextCNN can be used after embedding to learn short expressions at first and then feed into the Bi-LSTM block to learn contextual information. Due to the limitation of computation power and time, experiments are far from enough to draw a convincing conclusion.</p> <p>The code is too long to be included here, <a href="https://github.com/RyanQue/backupRepo/blob/43cd3f76ce6272f44021584ecd3737a0fca0f6ee/githubPage/NLP6850/TASK_B_Glove_Bi-LSTM_CNN_OrdinalReg.ipynb">check this link</a>.</p> <h2 id="limitation--reflections">Limitation / Reflections</h2> <p>Due to the limited time and computational power, we considered several limitations of this study:</p> <ol> <li>There is no comparison between the different structures of neural networks in task B, which may improve the model performance. And more hyperparameters can be tuned.</li> <li>Concerning Task A, LightGBM could be a better solution as an advanced gradient boosting method - It has a faster computation speed and better generalization in practice. The ordinal regression method may also work as long as the gradient boosting model can have multiple outputs.</li> <li>We should have dug deeper into the cutting edge techniques of transformer models, there is no comparison using a similar structure to compare the transformer with the embeddings, because the BERT transformation block has already consumed lots of computation power and we have to directly link it to a full connect output layer.</li> <li>As for preprocessing, the data that is learnt by neural networks may not be deep cleaned because the neural network may learn from the propositions or specially named entities. Moreover, the proportion of uppercase in the text should also be considered in the model as they imply a stronger expression of feelings.</li> </ol>]]></content><author><name></name></author><category term="ML"/><summary type="html"><![CDATA[Amazon Review Classification]]></summary></entry><entry><title type="html">A Typical ML Project Workflow</title><link href="https://ryanque.github.io/blog/2021/airbnb6810/" rel="alternate" type="text/html" title="A Typical ML Project Workflow"/><published>2021-11-22T00:00:00+00:00</published><updated>2021-11-22T00:00:00+00:00</updated><id>https://ryanque.github.io/blog/2021/airbnb6810</id><content type="html" xml:base="https://ryanque.github.io/blog/2021/airbnb6810/"><![CDATA[<h2 id="introduction">Introduction</h2> <p><em>This blog post was initially written in 2021 as a summary of a in-class ML project, which won the first place in terms of model performance. <a href="https://www.kaggle.com/c/qbus6810-2021-sem2-regression">check this link.</a> I led a team of 5 and took the responsibility of most EDA, data transformation and feature engineering parts. XGB and LightGBM were tuned and trained by me.</em></p> <p><em>I put a lot of efforts into the project and still took this project as a basic framework for ML projects. Mistakes and shortcomings made in the project constantly inspire me sebsequently.</em></p> <p>For the original Jupyter Notebook and report, <a href="https://github.com/RyanQue/backupRepo/tree/43cd3f76ce6272f44021584ecd3737a0fca0f6ee/githubPage/airbnb6810">check this link</a>.</p> <p>The post covers the common practices in a regression ML problem with a real-life dataset given by Airbnb. This is written in a fairly detailed manner, while deeper explanantion of certain techniques are not included. Further analytical part of the project is also not included.</p> <h3 id="problem-statement">Problem Statement</h3> <p>Airbnb is a global platform that runs an online marketplace for short term travel rentals.</p> <p>Targeting the Airbnb market, the task is developing an advice service for hosts, property managers, and real estate investors.</p> <p>To achieve the project’s goals, we are provided with a dataset containing detailed information on a number of existing Airbnb listings in Sydney. The team has two tasks:</p> <ol> <li> <p>To develop a predictive model for the daily prices of Airbnb rentals based on state-of-the-art techniques from statistical learning. This model will and allow the company to advise hosts on pricing and to help owners and investors to predict the potential revenue of Airbnb rental (which also depends on the occupancy rate).</p> </li> <li> <p>To obtain at least three insights that can help hosts to make better decisions. What are the best hosts doing?</p> </li> </ol> <h3 id="the-procedures-in-a-nutshell">The Procedures in a Nutshell</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/CRISP_DM_Diag-480.webp 480w,/assets/img/posts/airbnb6810/CRISP_DM_Diag-800.webp 800w,/assets/img/posts/airbnb6810/CRISP_DM_Diag-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/CRISP_DM_Diag.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="caption"> CRISP-DM Process Diagram </div> <p>As shown in the image, the workflow of such machine learning project is highly <strong>iterative</strong>.</p> <p>Although this article is presented as the order of the jupyter notebook, the final version is a result of several iterations of the whole process. EDA, feature engineering and modelling benefit from each other.</p> <h2 id="preparation">Preparation</h2> <h3 id="i-loading-libraries">I. Loading Libraries</h3> <details><summary>Click here for codes</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="n">missingno</span> <span class="k">as</span> <span class="n">msn</span>
<span class="kn">import</span> <span class="n">seaborn</span> <span class="k">as</span> <span class="n">sns</span>
<span class="kn">import</span> <span class="n">warnings</span>
<span class="kn">import</span> <span class="n">scipy</span> <span class="k">as</span> <span class="n">sp</span>
<span class="kn">from</span> <span class="n">dataprep.eda</span> <span class="kn">import</span> <span class="n">plot</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span><span class="p">,</span> <span class="n">Ridge</span><span class="p">,</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="n">xgboost</span> <span class="kn">import</span> <span class="n">XGBRegressor</span><span class="p">,</span> <span class="n">XGBClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">mean_squared_log_error</span><span class="p">,</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">roc_auc_score</span>
<span class="kn">import</span> <span class="n">lightgbm</span> <span class="k">as</span> <span class="n">lgb</span>
<span class="kn">import</span> <span class="n">re</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span><span class="p">,</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">import</span> <span class="n">optuna</span>
<span class="kn">from</span> <span class="n">optuna.samplers</span> <span class="kn">import</span> <span class="n">TPESampler</span>
<span class="kn">from</span> <span class="n">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestRegressor</span>
<span class="kn">import</span> <span class="n">random</span>
<span class="kn">from</span> <span class="n">mlxtend.regressor</span> <span class="kn">import</span> <span class="n">StackingCVRegressor</span></code></pre></figure> </details> <p>Some configuration for better output display:</p> <details><summary>Click here for codes</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># filter warnings
</span><span class="n">warnings</span><span class="p">.</span><span class="nf">filterwarnings</span><span class="p">(</span><span class="sh">'</span><span class="s">ignore</span><span class="sh">'</span><span class="p">)</span>
<span class="n">pd</span><span class="p">.</span><span class="nf">set_option</span><span class="p">(</span><span class="sh">'</span><span class="s">display.max_columns</span><span class="sh">'</span><span class="p">,</span> <span class="bp">None</span><span class="p">)</span>

<span class="c1"># set plot display mode
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="c1"># or
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">notebook</span></code></pre></figure> </details> <h3 id="ii-reproducibility">II. Reproducibility</h3> <p>The random seed determines whether the results would be the same when others want to re-run the code. Reproducibility is particularly <strong>important for sharing</strong> the work.</p> <p>There are several sources about this problem:</p> <blockquote> <p><a href="https://scikit-learn.org/stable/common_pitfalls.html#randomness">10. Common pitfalls and recommended practices — scikit-learn 1.0.2 documentation</a></p> </blockquote> <blockquote> <p><a href="https://stackoverflow.com/questions/52746279/how-to-get-absolutely-reproducible-results-with-scikit-learn">python - How to get absolutely reproducible results with Scikit Learn? - Stack Overflow</a></p> </blockquote> <p>At least the two random seed mentioned below should be determined, because different models/splitting techniques uses different random seeding system.</p> <p>In some models, <code class="language-plaintext highlighter-rouge">random_state</code> should be defined inside the model initializing code, instead of in this global setting.</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span></code></pre></figure> <h3 id="iii-read-data">III. Read Data</h3> <details><summary>Click here for codes</summary> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">traindf</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">train.csv</span><span class="sh">"</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">traindf</span><span class="p">.</span><span class="nf">copy</span><span class="p">()</span>

<span class="c1"># data shape, data type, and non-null counts
</span><span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">the number of columns: </span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">the number of observations: </span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">df</span><span class="p">))</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">*</span><span class="sh">'</span><span class="o">*</span><span class="mi">60</span><span class="p">)</span>
<span class="n">df</span><span class="p">.</span><span class="nf">info</span><span class="p">()</span>

<span class="c1"># random 5 observations for general understanding:
</span><span class="n">df</span><span class="p">.</span><span class="nf">sample</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="c1">#.head or .tail work fine as well, esp. in time series data</span></code></pre></figure> </details> <h2 id="data-understanding-and-cleaning">Data Understanding and Cleaning</h2> <p>Understanding data, cleaning and transforming data, and exploratory data analysis often go together and are done in an <strong>iterative</strong> manner.</p> <p>We are doing these steps based on grouping the features by their meaning and the logic would be more coherent.</p> <p><strong>There are 2 principles throughout the whole process :</strong></p> <p><strong>1. As the goal is predicting the price, it is better to think from the perspective of the hosts and users. Considering the situation when we want to book an accommodation on Airbnb and what affects our decision, or when we want to post an accommodation on Airbnb and what factors influence our pricing - these factors are usually considered the key features (which still need statistical evidences).</strong></p> <p><strong>2. When dealing with unstructured data, the process of converting them into structured data should reduce the information loss to the minimum.</strong></p> <h3 id="iv-missing-values">IV. Missing Values</h3> <p>The library <code class="language-plaintext highlighter-rouge">missingno</code> provides several useful plots for understanding the missing value:</p> <blockquote> <p><a href="https://coderzcolumn.com/tutorials/data-science/missingno-visualize-missing-data-in-python">missingno - Visualize Missing Data in Python (coderzcolumn.com)</a></p> </blockquote> <p>Methods include:</p> <ol> <li>their distribution - <code class="language-plaintext highlighter-rouge">.matrix</code></li> <li>proportion/amount - <code class="language-plaintext highlighter-rouge">.bar</code></li> <li>relationship - <code class="language-plaintext highlighter-rouge">.heatmap</code> and <code class="language-plaintext highlighter-rouge">.dendrogram</code></li> </ol> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># drop the columns without missing values for plotting
</span><span class="n">missingvalue_query</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">isnull</span><span class="p">().</span><span class="nf">sum</span><span class="p">()</span> <span class="o">!=</span> <span class="mi">0</span>
<span class="n">missingvalue_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="n">missingvalue_query</span><span class="p">]]</span>

<span class="c1"># bar chart for missing values
</span><span class="n">msn</span><span class="p">.</span><span class="nf">bar</span><span class="p">(</span><span class="n">missingvalue_df</span><span class="p">,</span>
        <span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">12</span><span class="p">),</span>
        <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">lightsteelblue</span><span class="sh">'</span><span class="p">)</span></code></pre></figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/barchar-480.webp 480w,/assets/img/posts/airbnb6810/barchar-800.webp 800w,/assets/img/posts/airbnb6810/barchar-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/barchar.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 80%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Insights:</strong></p> <ul> <li><code class="language-plaintext highlighter-rouge">description</code>, <code class="language-plaintext highlighter-rouge">host_location</code>, <code class="language-plaintext highlighter-rouge">bathrooms_text</code>, <code class="language-plaintext highlighter-rouge">bedrooms</code>, <code class="language-plaintext highlighter-rouge">beds</code> are features with a small portion of missing values.</li> <li><code class="language-plaintext highlighter-rouge">response_time</code> and <code class="language-plaintext highlighter-rouge">response_rate</code> are features with over a half missing values.</li> </ul> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># missing value heatmap
</span><span class="n">msn</span><span class="p">.</span><span class="nf">heatmap</span><span class="p">(</span><span class="n">missingvalue_df</span><span class="p">,</span><span class="n">figsize</span> <span class="o">=</span> <span class="p">(</span><span class="mi">24</span><span class="p">,</span><span class="mi">20</span><span class="p">))</span></code></pre></figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/heatmap-480.webp 480w,/assets/img/posts/airbnb6810/heatmap-800.webp 800w,/assets/img/posts/airbnb6810/heatmap-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/heatmap.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 80%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Insights:</strong> High correlated columns have 3 groups:</p> <ul> <li>columns about reviews.</li> <li><code class="language-plaintext highlighter-rouge">neighbourbood</code> and <code class="language-plaintext highlighter-rouge">neighborhood_overview</code>.</li> <li><code class="language-plaintext highlighter-rouge">host_response_rate</code>, <code class="language-plaintext highlighter-rouge">host_response_time</code> <code class="language-plaintext highlighter-rouge">host_acceptance_rate</code></li> </ul> <p>The correlation could obviously explained by the fact that each group belongs to a certain category of information. If the hosts do not enter any data in that field, the columns would be left empty at the same time.</p> <h3 id="v-target-variable---price">V. Target Variable - ‘price’</h3> <p><code class="language-plaintext highlighter-rouge">price</code> column has the format <code class="language-plaintext highlighter-rouge">$XXX.XX</code>, which is in the <code class="language-plaintext highlighter-rouge">string</code> data type. We have to change it into <code class="language-plaintext highlighter-rouge">float</code> type.</p> <p><code class="language-plaintext highlighter-rouge">pandas</code> has a built-in function to do this. Set the <code class="language-plaintext highlighter-rouge">regex</code> parameter as <code class="language-plaintext highlighter-rouge">True</code></p> <p><em>The module <code class="language-plaintext highlighter-rouge">re</code> can also handle this, but <code class="language-plaintext highlighter-rouge">pandas</code> built-in parameters could handle a larger datset faster.</em></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># converting the price column's data type to float
</span><span class="n">df</span><span class="p">.</span><span class="n">price</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">price</span><span class="p">.</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">[\$</span><span class="sh">'</span><span class="s">,]</span><span class="sh">"</span><span class="p">,</span><span class="sh">''</span><span class="p">,</span><span class="n">regex</span><span class="o">=</span> <span class="bp">True</span><span class="p">).</span><span class="nf">astype</span><span class="p">(</span><span class="nb">float</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">dataprep.eda</code> provides a convenient tool for understanding the basic description of data</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># in step1, we have this line:
# from dataprep.eda import plot
</span><span class="nf">plot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p>The output has quantile statistics, descriptive statistics, and several plots(histogram, KDE plot, normal Q-Q plot and Boxplot) for understanding the distribution.</p> <p><strong>Insights:</strong> <code class="language-plaintext highlighter-rouge">price</code> is right skewed.</p> <p><strong>NOTE:</strong> Some algorithms require a normal distributed target, which accords with the statistical model assumption for a better regression and prediction result. However, this is optional. Linear models may benefit, but for tree-based algorithm, it may make no big difference. Also, if the skewed data is transformed into a normal distributed one, there will be <strong>transformation bias</strong>, which should be considered when the model is used for prediction.</p> <blockquote> <p>An assey covering the issue: <a href="https://www.amazon.science/publications/identifying-and-overcoming-transformation-bias-in-forecasting-models">identifying-and-overcoming-transformation-bias-in-forecasting-models</a></p> </blockquote> <p>Here, a log transformation is used.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">log_price</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">price</span><span class="p">)</span>
</code></pre></div></div> <hr/> <p>The following steps will elaborate on pre-processing the predictors. There are more than 60 predictors and I decided to group them by their meaning.</p> <hr/> <h3 id="vi-predictors---basic-information">VI. Predictors - Basic Information</h3> <p>Features included: <code class="language-plaintext highlighter-rouge">['name','description]</code></p> <p>These two columns are entered by the host that can be subjective, no one will post any bad words about their accommodation. There are some missing values in the description - it reflects how much effort the host put into advertising it.</p> <p><strong>A new dummy variable created</strong> by:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">description_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">description</span><span class="p">.</span><span class="nf">isna</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</code></pre></div></div> <p><em>There will be similar missing value handling techniques later which will not be elaborated on.</em></p> <p>Then, a t-test is used to seek the difference in price between observations with or without description, the result is significant - there is a difference.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># a t-test for whether there are actually difference in price
</span><span class="n">a</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">description_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="bp">True</span><span class="p">]</span> 
<span class="n">b</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">description_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="bp">False</span><span class="p">]</span> 
<span class="n">sp</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">alternative</span> <span class="o">=</span> <span class="sh">'</span><span class="s">less</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># the output
# Ttest_indResult(statistic=-1.7525150053443874, pvalue=0.039850154641626216)
</span></code></pre></div></div> <p><strong>NOTE:</strong>: Actually, using NLP technique in the description to catch more precise information may be a better way - but would also create more dimensions in the dataset - trade-off*</p> <hr/> <h3 id="vii-predictors---host-related">VII. Predictors - Host Related</h3> <p>Features included:</p> <p><code class="language-plaintext highlighter-rouge">['host_name','host_since','host_location','host_about','host_response_time', 'host_response_rate','host_acceptance_rate','host_is_superhost', 'host_listings_count','host_total_listings_count', 'host_verifications','host_identity_verified']</code></p> <ul> <li><code class="language-plaintext highlighter-rouge">host_name</code></li> </ul> <p>check if every host has a unique host name</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">host_name</span> <span class="o">==</span> <span class="sh">'</span><span class="s">David</span><span class="sh">'</span><span class="p">].</span><span class="n">host_listings_count</span><span class="p">.</span><span class="nf">unique</span><span class="p">()</span>

<span class="c1">#output
</span><span class="nf">array</span><span class="p">([</span> <span class="mf">6.</span><span class="p">,</span>  <span class="mf">3.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">,</span> <span class="mf">23.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span> <span class="mf">11.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">,</span> <span class="mf">27.</span><span class="p">,</span>  <span class="mf">5.</span><span class="p">,</span>  <span class="mf">7.</span><span class="p">])</span>
</code></pre></div></div> <p>Apparently, different hosts can have the same <code class="language-plaintext highlighter-rouge">host_name</code>, so this predictor is considered useless. <strong>dropped</strong></p> <ul> <li><code class="language-plaintext highlighter-rouge">host_since</code></li> </ul> <p>This column has the <code class="language-plaintext highlighter-rouge">object</code> datatype, and is considered to be converted into how many days to the day it is collected. <em>(however this is also not available, just for approximation, the day for subtraction is the day of Kaggle competition is launched, which is Sep 23rd 2021).</em></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># step 1, convert object to datetime
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">])</span>

<span class="c1"># step 2, datetime substraction
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_since</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:(</span><span class="n">pd</span><span class="p">.</span><span class="nf">to_datetime</span><span class="p">(</span><span class="sh">'</span><span class="s">2021-09-23</span><span class="sh">'</span><span class="p">)</span><span class="o">-</span><span class="n">x</span><span class="p">).</span><span class="n">days</span><span class="p">)</span>
</code></pre></div></div> <p><strong>NOTE:</strong> <code class="language-plaintext highlighter-rouge">datetime</code> datatype can be calculated directly with <code class="language-plaintext highlighter-rouge">+</code> and <code class="language-plaintext highlighter-rouge">-</code>. And also can be transformed.</p> <blockquote> <p><a href="https://docs.python.org/3/library/datetime.html#datetime.datetime">datetime — Basic date and time types — Python 3.10.2 documentation</a></p> <p><a href="https://blog.csdn.net/DataCastle/article/details/84323603">pythonpandas.to_datetime_DataCastle-CSDN python to_datetime</a></p> </blockquote> <ul> <li><code class="language-plaintext highlighter-rouge">host_location</code></li> </ul> <p>This column is where the host lives instead of where the accommodation is, which is relatively less informative. However, if the host_location is the same as the location of the accommodation, the host may provide more satisfying services.</p> <p>A possible solution is constructing another column with the criterion: “host location == accomodation location”</p> <p>Due to the fact that the formats recording the host location and accomodation location are different, and it takes a lot of effort to transform, here we just simply <strong>drop</strong> the column.</p> <ul> <li><code class="language-plaintext highlighter-rouge">host_about</code></li> </ul> <p>This column is used for hosts introducing themselves, due to its large portion of missing values and subjective content, it is also considered to be less informative.</p> <p>However, this column might give information of whether the host are putting efforts on operating the account and advertising themselves.</p> <p>Here, I built a missing value indicator and <strong>dropped</strong> this predictor.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_about_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_about</span><span class="p">.</span><span class="nf">isna</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">host_about</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">host_response_rate</code> , <code class="language-plaintext highlighter-rouge">host_response_time</code> , <code class="language-plaintext highlighter-rouge">host_acceptance_rate</code></li> </ul> <p>It is mentioned in the missing value overview that these three columns has strong correlation in terms of missing values.</p> <p>These 3 columns are indicators of whether the host and the listing are active.</p> <blockquote> <p><a href="https://www.airbnb.com/resources/hosting-homes/a/sunderstanding-response-rate-and-acceptance-rate-86">Understanding response rate and acceptance rate - Resource Center - Airbnb</a></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">].</span><span class="nf">value_counts</span><span class="p">()</span>
</code></pre></div></div> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code># output
within an hour        4727
within a day          1470
within a few hours    1452
a few days or more     736
Name: host_response_time, dtype: int64
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">response_time</code> : It is a low-cardinality categorical variable and we <strong>fill the</strong> <code class="language-plaintext highlighter-rouge">na</code> <strong>value with</strong> <code class="language-plaintext highlighter-rouge">no response</code> <strong>as a new category</strong>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># host_response_time is categorical data:
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">no response</span><span class="sh">'</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">host_response_time</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">violin</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/responsetime-480.webp 480w,/assets/img/posts/airbnb6810/responsetime-800.webp 800w,/assets/img/posts/airbnb6810/responsetime-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/responsetime.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p>From the plot above, the distribution of price are a bit different between different response time.</p> <p><code class="language-plaintext highlighter-rouge">host_response_rate</code> and <code class="language-plaintext highlighter-rouge">host_acceptance_rate</code> should be continuous variable, convert them from texts to float numbers, and built 2 missing value indicator variables.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()</span><span class="o">==</span><span class="bp">False</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>

<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()</span><span class="o">==</span><span class="bp">False</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">x</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># a binary variable to indicate the missing value
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate_isna</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span>  <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">().</span><span class="nf">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

<span class="c1"># fill the missing value with 0
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_response_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_acceptance_rate</span><span class="sh">'</span><span class="p">].</span><span class="nf">isna</span><span class="p">()]</span> <span class="o">=</span> <span class="mi">0</span>
</code></pre></div></div> </details> <ul> <li><code class="language-plaintext highlighter-rouge">host_is_superhost</code></li> </ul> <p>About the ‘superhost’ , I found an explanation in Airbnb website:</p> <blockquote> <p><a href="https://www.airbnb.com/d/superhost">Airbnb Superhost program details</a></p> </blockquote> <p>Superhost can be considered as an important factor of measuring the quality of service provided by the host, which will influence the price of the listing. - <em>This is just an assumption and will be statistically tested</em></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># first, convert the t/f column into 0/1 binary variable.
</span><span class="n">df</span><span class="p">.</span><span class="n">host_is_superhost</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_is_superhost</span><span class="p">.</span><span class="nf">map</span><span class="p">({</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_is_superhost</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_is_superhost</span><span class="sh">'</span><span class="p">]</span> <span class="o">==</span> <span class="mi">0</span><span class="p">]</span>
<span class="n">sp</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">alternative</span> <span class="o">=</span> <span class="sh">'</span><span class="s">greater</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># the output:
# Ttest_indResult(statistic=-0.19814543743616678, pvalue=0.5785333753025225)
</span></code></pre></div></div> <p><strong>Insights:</strong> Statistical test does not support the assumption. - host_is_superhost has no strong correlation with price. However, I did not choose to simply drop the column, there might be some <strong>interation effect</strong> together with other features.</p> <blockquote> <p><a href="https://stats.libretexts.org/Bookshelves/Applied_Statistics/Natural_Resources_Biometrics_(Kiernan)/06%3A_Two-way_Analysis_of_Variance/6.01%3A_Main_Effects_and_Interaction_Effect#:~:text=The%20interaction%20is%20the%20simultaneous,interaction%20effect%20between%20the%20factors.">About interation effect</a></p> </blockquote> <ul> <li><code class="language-plaintext highlighter-rouge">host_listing_count</code>, <code class="language-plaintext highlighter-rouge">host_total_listing_count</code></li> </ul> <p>These two columns are about the accommodations owned by the host.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">host_listings_count</span> <span class="o">==</span> <span class="n">df</span><span class="p">.</span><span class="n">host_total_listings_count</span><span class="p">).</span><span class="nf">unique</span><span class="p">()</span>

<span class="c1"># output:
# array([ True])
</span></code></pre></div></div> <p><strong>Insights:</strong> These two columns are <strong>identical</strong>.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="sh">'</span><span class="s">host_total_listings_count</span><span class="sh">'</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">df</span><span class="p">.</span><span class="n">host_listings_count</span><span class="p">.</span><span class="nf">value_counts</span><span class="p">().</span><span class="nf">sort_index</span><span class="p">()</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_listings_count</span><span class="sh">'</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">][</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">host_listings_count</span><span class="sh">'</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">]</span>
<span class="n">sp</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="nf">ttest_ind</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">,</span><span class="n">alternative</span> <span class="o">=</span> <span class="sh">'</span><span class="s">less</span><span class="sh">'</span><span class="p">)</span>

<span class="c1"># output:
# Ttest_indResult(statistic=-7.6451367678834385, pvalue=1.0896805499204671e-14)
</span></code></pre></div></div> <p><strong>Insights:</strong> Statistically tested, the fact that accommodation’s host having more than 1 listings, relates to a higher price. It can be explained that the host who has more than 1 listings are much more wealthy than the one with only one or less, whose accommodation might be more luxury, which leads to higher price.</p> <p>However, the explanation above indicates that there might be correlation between the accommodation’s condition with the <code class="language-plaintext highlighter-rouge">host_listings_count</code>, which will cause multicollinearity in linear models.(correlation is analysed later.)</p> <p><em>Clustering by the count of listings could be used for more precise result. Here I just keep the continuous variable.</em></p> <ul> <li><code class="language-plaintext highlighter-rouge">host_verifications</code>,<code class="language-plaintext highlighter-rouge">host_identity_verified</code></li> </ul> <p>These two columns are measuring whether the host’s identity is verified and to what extent they are verified. Verified ones with more verification methods are considered as more reliable host.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert the list-like string to list data type
</span><span class="n">df</span><span class="p">.</span><span class="n">host_verifications</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_verifications</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">strip</span><span class="p">(</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"'"</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">))</span>

<span class="c1"># convert the t/f to 1/0
</span><span class="n">df</span><span class="p">.</span><span class="n">host_identity_verified</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_identity_verified</span><span class="p">.</span><span class="nf">map</span><span class="p">({</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="c1"># counting the number of verification - how host varifies seems not a relevant indicator
</span><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">num_host_verification</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">host_verifications</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="nb">len</span><span class="p">)</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">'</span><span class="s">num_host_verification</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">hue</span> <span class="o">=</span> <span class="sh">'</span><span class="s">host_identity_verified</span><span class="sh">'</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">boxen</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/verification-480.webp 480w,/assets/img/posts/airbnb6810/verification-800.webp 800w,/assets/img/posts/airbnb6810/verification-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/verification.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Insights:</strong> It is observed that accommodations with identity-verified host will have slightly higher prices. With number of verification increasing, there is no obvious increment in price.</p> <h3 id="viii-predictors---location-related">VIII. Predictors - Location Related</h3> <p>By looking at some entries of the dataset:</p> <ul> <li> <p>four text predictors relate to the location of the accommodation:</p> <ol> <li><code class="language-plaintext highlighter-rouge">neighbourhood_cleansed</code> is the cleansed version of <code class="language-plaintext highlighter-rouge">neighbourhood</code> (no missing value and categorical compared with the original one.)</li> <li><code class="language-plaintext highlighter-rouge">neighborhood_overview</code> contains more precise information about the location, but it is recorded with human language which needs NLP techniques to extract useful information.</li> <li><code class="language-plaintext highlighter-rouge">host_neighbourhood</code> is the neighbourhood of the host, instead of the accommodation, which is useless.</li> </ol> </li> <li> <p>two continuous variables describe the exact location of the accommodation, which are the most precise location information.</p> </li> </ul> <p>Here, there are two things I did:</p> <ol> <li>drop useless predictors - <code class="language-plaintext highlighter-rouge">host_neighbourhood</code> and <code class="language-plaintext highlighter-rouge">neighbourhood</code></li> <li>Plotting the <code class="language-plaintext highlighter-rouge">longitude</code> and <code class="language-plaintext highlighter-rouge">latitude</code> with log_price - geometric distribution</li> </ol> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">latitude</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">longitude</span><span class="p">,</span>
           <span class="n">linewidths</span><span class="o">=</span><span class="mf">0.03</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="p">.</span><span class="mi">4</span><span class="p">,</span>
           <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">k</span><span class="sh">'</span><span class="p">,</span>
           <span class="n">s</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
           <span class="n">c</span><span class="o">=</span><span class="n">df</span><span class="p">.</span><span class="n">log_price</span><span class="p">,</span>
           <span class="n">cmap</span> <span class="o">=</span> <span class="sh">"</span><span class="s">coolwarm</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">"</span><span class="s">latitude</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">"</span><span class="s">longitude</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Price geometric distribution</span><span class="sh">"</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">colorbar</span><span class="p">()</span>
<span class="n">a</span><span class="p">.</span><span class="nf">set_label</span><span class="p">(</span><span class="sh">'</span><span class="s">log_price</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/geometric_distribution-480.webp 480w,/assets/img/posts/airbnb6810/geometric_distribution-800.webp 800w,/assets/img/posts/airbnb6810/geometric_distribution-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/geometric_distribution.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>NOTE</strong>: This figure can be improved by using more advanced visualization technique. For example, 1) combining with the real map, 2) use some kind of density graph instead of this scatter plot.</p> <p><strong>Insights:</strong> It is observed from the plot that geometric location of the accommodation has some complex relationship with price.</p> <p>And these two variables are more complete, authentic and precise compared with <code class="language-plaintext highlighter-rouge">neighborhood_overview</code>. Therefore, <strong>we only keep <code class="language-plaintext highlighter-rouge">longitude</code> and <code class="language-plaintext highlighter-rouge">latitude</code>.</strong> <em>However, NLP can be used to extract useful information in the predictor<code class="language-plaintext highlighter-rouge">neighborhood_overview</code>.</em></p> <p><strong>NOTE</strong>:</p> <p>This step can be improved to optimise the performance of the predicting model.</p> <p>WHY?</p> <p>The place of the accommodation affect the price greatly in common sense. The closer the place is to the central area, the more expensive it would be.</p> <p>HOW?</p> <p>Possible solution: Make a grid map that divide the whole area into 100*100 blockas and 1)assigning each block an identifier and make it a feature or 2) clustering the blocks into different hierarch for less constructed features.</p> <p>Another possible solution: divide the map by postcode, such information could be found in government website.</p> <h3 id="ix-predictors---accommodation-related">IX. Predictors - Accommodation Related</h3> <p>The quality and facilities of the accommodation are the key factors in determining the price, based on common sense.</p> <ul> <li><code class="language-plaintext highlighter-rouge">Property_type</code></li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">property_type</span><span class="p">.</span><span class="nf">unique</span><span class="p">()</span>
</code></pre></div></div> <p><strong>Insights:</strong> From the output, This predictors can be taken as categorical with high cardinality, but also can be taken as human language and can be reduced by NLP techniques.</p> <p><em>This part will be elaborated in the Feature Engineering part.</em></p> <ul> <li><code class="language-plaintext highlighter-rouge">room_type</code></li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">.</span><span class="n">room_type</span><span class="p">.</span><span class="nf">unique</span><span class="p">()</span>
<span class="c1"># Result shows that there are only 4 categories in this predictor
</span>
<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="sh">"</span><span class="s">room_type</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">y</span> <span class="o">=</span> <span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span>
            <span class="n">kind</span> <span class="o">=</span> <span class="sh">"</span><span class="s">violin</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/room_type-480.webp 480w,/assets/img/posts/airbnb6810/room_type-800.webp 800w,/assets/img/posts/airbnb6810/room_type-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/room_type.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Insights:</strong> The plot shows that private room and shared room are relatively low in price while entire home/apt and hotel room are relatively high in price.</p> <ul> <li><code class="language-plaintext highlighter-rouge">accommodates</code></li> </ul> <p>This column indicates the amount of people to live in the place.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">accommodates</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
            <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">boxen</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/accommodates-480.webp 480w,/assets/img/posts/airbnb6810/accommodates-800.webp 800w,/assets/img/posts/airbnb6810/accommodates-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/accommodates.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Insights:</strong> From the boxplot, it is observed that when <code class="language-plaintext highlighter-rouge">accommodates</code> are less than 10, the price has approximately positive linear relationship with <code class="language-plaintext highlighter-rouge">accommodates</code>. Accommodations with more than 10 <code class="language-plaintext highlighter-rouge">accommodates</code> has no obvious relationship with price.</p> <p><em>clustering can be used here - construct a indicator variable with the threshold of <code class="language-plaintext highlighter-rouge">accommodates = 10</code></em></p> <ul> <li><code class="language-plaintext highlighter-rouge">bathrooms_text</code></li> </ul> <p>Used <code class="language-plaintext highlighter-rouge">.unique()</code> and we see that the predictor can be separated into a number and an adjective. This part will also be elaborated on the feature engineering part.</p> <ul> <li><code class="language-plaintext highlighter-rouge">bedrooms</code></li> </ul> <p>use <code class="language-plaintext highlighter-rouge">value_counts()</code> - the amount of bedrooms vary from 1 to 16, and there are missing values.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># na means no bedroom
</span><span class="n">df</span><span class="p">.</span><span class="n">bedrooms</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">bedrooms</span><span class="p">.</span><span class="nf">fillna</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">bedrooms</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span> 
               <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">boxen</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/bedrooms-480.webp 480w,/assets/img/posts/airbnb6810/bedrooms-800.webp 800w,/assets/img/posts/airbnb6810/bedrooms-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/bedrooms.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Insights:</strong> the correlation is obvious positive but not linear.</p> <p><em>A new predictor with the value of <code class="language-plaintext highlighter-rouge">bedrooms**2</code> or more power can be constructed (I did not do it here, it would somehow impact the interpretability)</em></p> <p>And I performed the similar procedure with <code class="language-plaintext highlighter-rouge">beds</code> and find similar pattern.</p> <ul> <li><code class="language-plaintext highlighter-rouge">amenities</code></li> </ul> <p>This predictor can taken as a nested list and entered in the <code class="language-plaintext highlighter-rouge">string</code> format.</p> <p>The following steps did these things:</p> <ul> <li>convert the string into a list of lists</li> <li>count unrepeated items appeared in the deepest list.</li> </ul> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># convert the amenities column from string to list.
</span><span class="n">df</span><span class="p">.</span><span class="n">amenities</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">strip</span><span class="p">(</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"'"</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,</span><span class="sh">"</span><span class="p">))</span>

<span class="c1"># try to get all the unique items in the amenities list.
</span><span class="k">def</span> <span class="nf">GetAme</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    This function takes one parameter which should be a 2-times-nested list(list of lists)
    Return with a list with all the non-repeated items in the deepest list
    </span><span class="sh">"""</span>
    <span class="n">AmeList</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">AnObservation</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">AnObservation</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">'"'</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">AmeList</span><span class="p">:</span>
                <span class="n">AmeList</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">'"'</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">AmeList</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="nc">GetAme</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">amenities</span><span class="p">)))</span> <span class="c1"># output 623
</span></code></pre></div></div> </details> <p><em>This may not be the best way to analyse the predictor, because some of the amenities have the brand and repeatedly counted – some advanced NLP techniques can be used here to furthermore reduce the cardinality.</em></p> <p><strong>NOTE:</strong> Here we could draw a plot using price against amount of amenities.</p> <p>Again, further processes will be elaborated on in the feature engineering part.</p> <h3 id="x-predictors---availability-related">X. Predictors - Availability Related</h3> <ul> <li>night stay related</li> </ul> <p>including:</p> <div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">[</span><span class="sh">'</span><span class="s">minimum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">maximum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">minimum_minimum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">maximum_minimum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">minimum_maximum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">maximum_maximum_nights</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">minimum_nights_avg_ntm</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">maximum_nights_avg_ntm</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <p>Related Airbnb minimum night stay explanation:</p> <blockquote> <table> <tbody> <tr> <td>[What’s the Best Minimum Night Stay Policy on Airbnb?</td> <td>AirDNA](https://www.airdna.co/blog/whats-the-best-minimum-night-stay-policy-on-airbnb)</td> </tr> </tbody> </table> </blockquote> <p>Host can set minimum nights and maximum nights a customer can book for the accommodation. And such setting can vary in different period of time during the year, indicating a high/low season or the availability of the host.</p> <p>Longer minimum nights sometimes means lower price as the host will not have to bother in introducing and settling the accommodation.</p> <p>Based on life experience, in the high season, if there are strategy in changing the settings of the minimum nights and maximum nights, minimum nights and maximum nights will be shorter, and the situation will be the opposite in the low season.</p> <p><code class="language-plaintext highlighter-rouge">minimum_nights_avg_ntm</code> and <code class="language-plaintext highlighter-rouge">maximum_nights_avg_ntm</code> might be good predictors as it is the weighted average of the number of nights setting.</p> <p>The following codes categorize the minimum and maximum night stays, then plotted against the target <code class="language-plaintext highlighter-rouge">log_price</code>.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ClassifyNights</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">7</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">within a week</span><span class="sh">'</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">30</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">within a month</span><span class="sh">'</span>
    <span class="k">elif</span> <span class="n">x</span> <span class="o">&lt;=</span> <span class="mi">365</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">within a year</span><span class="sh">'</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="sh">'</span><span class="s">more than a year</span><span class="sh">'</span>

<span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">cate_min_nights</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">minimum_nights_avg_ntm</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">ClassifyNights</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">cate_min_nights</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span> 
               <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">violin</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> </details> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/min_night-480.webp 480w,/assets/img/posts/airbnb6810/min_night-800.webp 800w,/assets/img/posts/airbnb6810/min_night-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/min_night.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">df</span><span class="p">[</span><span class="sh">'</span><span class="s">cate_max_nights</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">maximum_nights_avg_ntm</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="n">ClassifyNights</span><span class="p">)</span>

<span class="n">sns</span><span class="p">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">cate_max_nights</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span> 
               <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">violin</span><span class="sh">"</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/max_night-480.webp 480w,/assets/img/posts/airbnb6810/max_night-800.webp 800w,/assets/img/posts/airbnb6810/max_night-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/max_night.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>Insights:</strong> It seems that there is no big difference in price with different settings of minimum nights and maximum nights. The distribution does differ though.</p> <ul> <li>availabilities</li> </ul> <p>Features included:</p> <p><code class="language-plaintext highlighter-rouge">['has_availability','availability_30','availability_60', 'availability_90','availability_365','instant_bookable']</code></p> <p><code class="language-plaintext highlighter-rouge">has_availability</code> has the format of ‘t’s and ‘f’s</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># converting t/f to 1/0
</span><span class="n">df</span><span class="p">.</span><span class="n">has_availability</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">has_availability</span><span class="p">.</span><span class="nf">map</span><span class="p">({</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>
<span class="n">df</span><span class="p">.</span><span class="n">instant_bookable</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">instant_bookable</span><span class="p">.</span><span class="nf">map</span><span class="p">({</span><span class="sh">'</span><span class="s">t</span><span class="sh">'</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="sh">'</span><span class="s">f</span><span class="sh">'</span><span class="p">:</span> <span class="mi">0</span><span class="p">})</span>

<span class="c1">#plotting the has_availability against log_price
</span><span class="n">sns</span><span class="p">.</span><span class="nf">catplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">has_availability</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">log_price</span><span class="sh">"</span><span class="p">,</span>
               <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="sh">"</span><span class="s">violin</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/avail-480.webp 480w,/assets/img/posts/airbnb6810/avail-800.webp 800w,/assets/img/posts/airbnb6810/avail-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/avail.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 60%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><em>The same was done to <code class="language-plaintext highlighter-rouge">instant_bookable</code> and the plot shows no difference.</em></p> <p><strong>Insights:</strong> The availability in different time scale are indicators of whether the accommodation is popular or not. Less availability days are considered more popular.</p> <p><code class="language-plaintext highlighter-rouge">availability_365</code> is considered as a more robust indicator, <code class="language-plaintext highlighter-rouge">availability_30</code> can be used to compare with <code class="language-plaintext highlighter-rouge">availability_365</code> (in terms of ratio)to infer whether it is high/low season of the year.</p> <p>However, plots do not support the assumption mentioned above. Some difference (not obvious) in price is observed whether ratio of availability are high/low in the recent month.</p> <h3 id="xi-predictors---review-related">XI. Predictors - Review related</h3> <p>With all the predictor plotted against <code class="language-plaintext highlighter-rouge">log_price</code>, only one thing can be sure:</p> <p>Accommodations with high price rarely have bad rating.</p> <h3 id="xii-predictors---listing-related">XII. Predictors - Listing Related</h3> <p>No obvious relationship is found, so I simply omitted this part.</p> <hr/> <h3 id="xiii-test-set">XIII. Test set</h3> <p>All the data cleaning procedure should be both done in the training set and test set.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># examine whether columns are correct.
</span><span class="n">trainList</span> <span class="o">=</span> <span class="nf">list</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
<span class="n">trainList</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">)</span>
<span class="n">trainList</span><span class="p">.</span><span class="nf">remove</span><span class="p">(</span><span class="sh">'</span><span class="s">log_price</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">trainList</span> <span class="o">==</span> <span class="nf">list</span><span class="p">(</span><span class="n">test</span><span class="p">.</span><span class="n">columns</span><span class="p">))</span>

<span class="c1"># the output should be:
# True
</span></code></pre></div></div> </details> <hr/> <h2 id="feature-engineering">Feature Engineering</h2> <h3 id="xiv-handling-features-with-natural-language">XIV. Handling features with natural language</h3> <ul> <li><code class="language-plaintext highlighter-rouge">property_type</code></li> </ul> <p>This feature descibes the type of the property. However, types are expressed with human language. The description can be devided by its word class:</p> <ul> <li> <p>adjective: ‘shared’,’private’,’entire’,etc. ;</p> </li> <li> <p>noun: ‘apartment’,’hotel’,’loft’,etc. .</p> </li> </ul> <p>Therefore, with clear pattern, it is processed by code below.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># This nested for loop could be optimized. Due to the fact that the dataset is not too large, I just remain the code as-is.
</span><span class="n">property_word_totallist</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">anObs</span> <span class="ow">in</span> <span class="n">train</span><span class="p">.</span><span class="n">property_type</span><span class="p">:</span> <span class="c1"># collect all the non-repeated words in property type
</span>    <span class="n">anObs_low</span> <span class="o">=</span> <span class="n">anObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">anObs_low</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">aWord</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">aWord</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">property_word_totallist</span><span class="p">:</span>
            <span class="n">property_word_totallist</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">aword</span><span class="p">)</span>

<span class="c1"># Constructing detection columns for certain words
</span><span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type_wdlist</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">property_type</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">))</span>
<span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type_wdlist</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">property_type</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">testword</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">property_word_totallist</span><span class="p">):</span>
    <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">property_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">testword</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type_wdlist</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">testword</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">property_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">testword</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">property_type_wdlist</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="nf">int</span><span class="p">(</span><span class="n">testword</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">property_word_totallist</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">property_</span><span class="sh">'</span><span class="o">+</span> <span class="n">testword</span>
    
<span class="c1"># create a list for selected features
</span><span class="n">SelectedFeature</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># include the constructed columns in the dataset
</span><span class="k">for</span> <span class="n">afeature</span> <span class="ow">in</span> <span class="n">property_word_totallist</span><span class="p">:</span>
    <span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">afeature</span><span class="p">)</span>
</code></pre></div></div> </details> <ul> <li><code class="language-plaintext highlighter-rouge">bathroom_text</code></li> </ul> <p>3 predictors are constructed:</p> <ul> <li>the number of bathrooms</li> <li>whether the bath is private - 1 for private and 0 for not private</li> <li>whether the bath is shared - 1 for shared and 0 for not shared</li> </ul> <p><em>some of the description did not mention whether it is private and shared.</em></p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># same as how I processed property types, creating a non-repeated wordlist
</span><span class="n">bath_word_totallist</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">anObs</span> <span class="ow">in</span> <span class="n">train</span><span class="p">.</span><span class="n">bathrooms_text</span><span class="p">:</span>
    <span class="n">anObs_low</span> <span class="o">=</span> <span class="n">anObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">()</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">anObs_low</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">aword</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">aword</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">bath_word_totallist</span><span class="p">:</span>
            <span class="n">bath_word_totallist</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">aword</span><span class="p">)</span>

<span class="c1"># a function for counting the number of baths
</span><span class="k">def</span> <span class="nf">bathnum</span><span class="p">(</span><span class="n">AnObs</span><span class="p">):</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">AnObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">half</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">0.5</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">awd</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">anum</span> <span class="o">=</span> <span class="nf">float</span><span class="p">(</span><span class="n">awd</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">anum</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">continue</span>

<span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">number_of_baths</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathnum</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">number_of_baths</span><span class="sh">'</span><span class="p">]</span><span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathnum</span><span class="p">)</span>

<span class="c1"># function for detecting whether the bath is private
</span><span class="k">def</span> <span class="nf">bathprivate</span><span class="p">(</span><span class="n">AnObs</span><span class="p">):</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">AnObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">half</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">0.5</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">private</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>

<span class="n">train</span><span class="p">[</span><span class="sh">"</span><span class="s">bath_private</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathprivate</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="sh">"</span><span class="s">bath_private</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathprivate</span><span class="p">)</span>

<span class="c1"># whether the bath is shared 
</span><span class="k">def</span> <span class="nf">bathshared</span><span class="p">(</span><span class="n">AnObs</span><span class="p">):</span>
    <span class="n">wordlist</span> <span class="o">=</span> <span class="n">AnObs</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">half</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s">0.5</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"</span><span class="s">-</span><span class="sh">"</span><span class="p">,</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">).</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
    <span class="k">if</span> <span class="sh">'</span><span class="s">shared</span><span class="sh">'</span> <span class="ow">in</span> <span class="n">wordlist</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
    
<span class="n">train</span><span class="p">[</span><span class="sh">"</span><span class="s">bath_shared</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathshared</span><span class="p">)</span>
<span class="n">test</span><span class="p">[</span><span class="sh">"</span><span class="s">bath_shared</span><span class="sh">"</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">bathrooms_text</span><span class="sh">'</span><span class="p">].</span><span class="nf">apply</span><span class="p">(</span><span class="n">bathshared</span><span class="p">)</span>

<span class="c1"># add the 3 constructed predictors
</span><span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">number_of_baths</span><span class="sh">'</span><span class="p">)</span>
<span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">bath_private</span><span class="sh">'</span><span class="p">)</span>
<span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="sh">'</span><span class="s">bath_shared</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> </details> <ul> <li><code class="language-plaintext highlighter-rouge">amenities</code></li> </ul> <p>As mentioned above, <code class="language-plaintext highlighter-rouge">amenities</code> is a nested list, but entered as text data. There are several steps to extract information and constrcut features:</p> <ul> <li>turn the text data into an actual list</li> <li>construct a non-repeat wordlist for amenities</li> <li>construct features based on the wordlist</li> </ul> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># turn the string dtype into list
</span><span class="n">train</span><span class="p">.</span><span class="n">amenities</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"'"</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'"'</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">strip</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,  </span><span class="sh">"</span><span class="p">))</span>
<span class="n">test</span><span class="p">.</span><span class="n">amenities</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">.</span><span class="nf">lower</span><span class="p">().</span><span class="nf">strip</span><span class="p">(</span><span class="sh">"</span><span class="s">[]</span><span class="sh">"</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">"'"</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">replace</span><span class="p">(</span><span class="sh">'"'</span><span class="p">,</span><span class="sh">""</span><span class="p">).</span><span class="nf">strip</span><span class="p">().</span><span class="nf">split</span><span class="p">(</span><span class="sh">"</span><span class="s">,  </span><span class="sh">"</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">GetAme</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s">
    This function takes one parameter which should be a 2-times-nested list(list of lists)
    Return with a list with all the non-repeated items in the deepest list
    </span><span class="sh">"""</span>
    <span class="n">AmeList</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">AnObservation</span> <span class="ow">in</span> <span class="n">x</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">AnObservation</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">AmeList</span><span class="p">:</span>
                <span class="n">AmeList</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">())</span>
    <span class="k">return</span> <span class="n">AmeList</span>

<span class="n">Amenity_list</span> <span class="o">=</span> <span class="nc">GetAme</span><span class="p">(</span><span class="n">train</span><span class="p">.</span><span class="n">amenities</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">Amenity_list</span><span class="p">))</span> <span class="c1"># output 598
</span></code></pre></div></div> </details> <p>Too many unique items in this list - a new column for each unique item is not a good idea.</p> <p>Instead, I choose the items that occurred more than 30 times.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># a dictionary for counting the amount of times that such amenities occur
</span><span class="n">item_dict</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">Amenity_list</span><span class="p">:</span>
    <span class="n">counter</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">AnObs</span> <span class="ow">in</span> <span class="n">train</span><span class="p">.</span><span class="n">amenities</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">AnObs</span><span class="p">:</span>
            <span class="n">counter</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="n">item_dict</span><span class="p">[</span><span class="n">item</span><span class="p">.</span><span class="nf">strip</span><span class="p">()]</span> <span class="o">=</span> <span class="n">counter</span>
    
<span class="n">freq_ame_list</span><span class="o">=</span><span class="p">[]</span>
<span class="k">for</span> <span class="n">akey</span> <span class="ow">in</span> <span class="n">item_dict</span><span class="p">.</span><span class="nf">keys</span><span class="p">():</span>
    <span class="k">if</span> <span class="n">item_dict</span><span class="p">[</span><span class="n">akey</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mi">30</span><span class="p">:</span>
        <span class="n">freq_ame_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">akey</span><span class="p">)</span>
        
<span class="nf">len</span><span class="p">(</span><span class="n">freq_ame_list</span><span class="p">)</span> <span class="c1">#output 120, which is acceptable
</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">_item</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">freq_ame_list</span><span class="p">):</span>
    <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">Amenity_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">_item</span><span class="p">]</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nf">int</span><span class="p">(</span><span class="n">_item</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">test</span><span class="p">[</span><span class="sh">'</span><span class="s">Amenity_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">_item</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="n">amenities</span><span class="p">.</span><span class="nf">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span> <span class="p">:</span> <span class="nf">int</span><span class="p">(</span><span class="n">_item</span> <span class="ow">in</span> <span class="n">x</span><span class="p">))</span>
    <span class="n">freq_ame_list</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="sh">'</span><span class="s">Amenity_</span><span class="sh">'</span> <span class="o">+</span> <span class="n">_item</span>


<span class="k">for</span> <span class="n">afeature</span> <span class="ow">in</span> <span class="n">freq_ame_list</span><span class="p">:</span>
    <span class="n">SelectedFeature</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">afeature</span><span class="p">)</span>
</code></pre></div></div> <p><strong>NOTE:</strong> The threshold for including the item is adjustable. Here I used 30. The larger the value is, the less features will be constructed.</p> <hr/> <h3 id="xv-encoding-the-categorical-data">XV. Encoding the categorical data</h3> <p>including : <code class="language-plaintext highlighter-rouge">host_response_time, neighbourhood_cleansed, room_type</code></p> <p>Encoding is automatically done by the <code class="language-plaintext highlighter-rouge">OneHotEncoder</code> in the <code class="language-plaintext highlighter-rouge">sklearn</code> package.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cate_col</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">host_response_time</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">neighbourhood_cleansed</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">room_type</span><span class="sh">'</span><span class="p">]</span>
<span class="n">OHEnc</span> <span class="o">=</span> <span class="nc">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>

<span class="n">OHcols</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">OHEnc</span><span class="p">.</span><span class="nf">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="n">cate_col</span><span class="p">]),</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">OHEnc</span><span class="p">.</span><span class="nf">get_feature_names</span><span class="p">())</span>
<span class="n">OHcols_test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">OHEnc</span><span class="p">.</span><span class="nf">transform</span><span class="p">(</span><span class="n">test</span><span class="p">[</span><span class="n">cate_col</span><span class="p">]),</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">OHEnc</span><span class="p">.</span><span class="nf">get_feature_names</span><span class="p">())</span>

<span class="n">othercols</span> <span class="o">=</span> <span class="n">train</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">cate_col</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">othercols_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">.</span><span class="nf">drop</span><span class="p">(</span><span class="n">cate_col</span><span class="p">,</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">OHcols</span><span class="p">,</span><span class="n">othercols</span><span class="p">],</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">([</span><span class="n">OHcols_test</span><span class="p">,</span><span class="n">othercols_test</span><span class="p">],</span><span class="n">axis</span> <span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> </details> <hr/> <h3 id="xvi-collecting-all-the-useful-predictors">XVI. Collecting all the useful predictors</h3> <p>In this example, I splitted all the predictors by its meaning and then did the cleaning and feature engineering. From my perspective, this is useful when there are many predictors that may affect the target.</p> <p>And a list can be constructed to store the filtered predictors’ name for further modelling usage.</p> <p><strong>The feature selection is highly iterative, the decision could be made from the business understanding, the EDA, the feature engineering, and also the modeling results.</strong></p> <hr/> <h2 id="modelling">Modelling</h2> <h3 id="xvii-preparation">XVII. Preparation</h3> <p>There are several procedures need to be done:</p> <ul> <li>Train-valid-test split</li> </ul> <p>In this example, a hidden test set is already given to evaluate the generalization.</p> <p>A second split (as train and validation set) needs to be done for hyperparameter optimisation. In most algorithms, I could use cross-validation - when the dataset is relatively small and computationally feasible.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictors</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">SelectedFeature</span><span class="p">]</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="sh">'</span><span class="s">log_price</span><span class="sh">'</span><span class="p">]</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">SelectedFeature</span><span class="p">]</span> <span class="c1"># the final y_test is in log_price scale, remember to convert back.
</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_valid</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_valid</span> <span class="o">=</span> <span class="nf">train_test_split</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>Define the RMSLE metric and scorer - The final result is evaluated by RMSLE (root mean squared log error)</li> </ul> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rmsle</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">mean_squared_log_error</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">y_valid</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="p">))</span>

<span class="c1"># log transformed target scorer
</span><span class="n">rmsle_scorer</span> <span class="o">=</span> <span class="nf">make_scorer</span><span class="p">(</span><span class="n">rmsle</span><span class="p">,</span> <span class="n">greater_is_better</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
</code></pre></div></div> <ul> <li>rename the column names - <code class="language-plaintext highlighter-rouge">XGboost</code> and <code class="language-plaintext highlighter-rouge">LightGBM</code> have some issues regarding the column names</li> </ul> <blockquote> <p>XGboost: <a href="https://stackoverflow.com/questions/42338972/valueerror-feature-names-mismatch-in-xgboost-in-the-predict-function">python - ValueError: feature_names mismatch: in xgboost in the predict() function - Stack Overflow</a></p> <p>LightGBM: <a href="https://stackoverflow.com/questions/60698860/how-to-deal-with-do-not-support-non-ascii-characters-in-feature-name-error-whe">python - How to deal with “Do not support non-ASCII characters in feature name” error when I use lightGBM? - Stack Overflow</a></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X_train</span> <span class="o">=</span> <span class="n">X_train</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">'</span><span class="s">[^A-Za-z0-9_]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="n">X_valid</span> <span class="o">=</span> <span class="n">X_valid</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">'</span><span class="s">[^A-Za-z0-9_]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="n">X_test</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">'</span><span class="s">[^A-Za-z0-9_]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
</code></pre></div></div> <p><strong>NOTE:</strong> This issue happens in certain versions of XBG and LGBM, so check the documentation if an error occurs.</p> <ul> <li>A function that generate output files</li> </ul> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">nameofmodel</span><span class="p">):</span>
    <span class="c1"># back transformation bias is considered.
</span>    <span class="sh">'''</span><span class="s"> this function takes two parameter,
    model - the already fitted model which has .predict() method
    nameofmodel - a string, the name of the model
    </span><span class="sh">'''</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">predictors</span><span class="p">)</span>
    <span class="n">residuals</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">y_hat</span>
    <span class="n">adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
    <span class="n">final_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj</span>
    <span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">final_predict</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)</span>
    <span class="n">submission</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">{} model prediction.csv</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">nameofmodel</span><span class="p">),</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>
</code></pre></div></div> </details> <hr/> <h3 id="xviii-benchmark---simple-linear-regression">XVIII. Benchmark - Simple linear regression</h3> <p>Linear regression has a very strong assumption on the relationship between the predictors and target. - The model has good computation speed and interpretation ability but bad performance on prediction especialy when there are lots of predictors. - I use this as a benchmark model, and any model has a worse result will be considered useless.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">LR</span> <span class="o">=</span> <span class="nc">LinearRegression</span><span class="p">()</span>

<span class="c1"># kfold is used for cross-validation - splitting the dataset into k segments
</span><span class="n">kfold</span> <span class="o">=</span> <span class="nc">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span> <span class="mi">5</span> <span class="p">,</span><span class="n">shuffle</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span> <span class="mi">42</span> <span class="p">)</span>

<span class="n">LR_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">LR</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE Benchmark with linear regression(cross-validation): {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">LR_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span>
<span class="c1"># result(in RMSLE): 0.423998
</span>
<span class="n">LR</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">LR</span><span class="p">,</span> <span class="sh">'</span><span class="s">linearRegression</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <hr/> <h3 id="xix-regularised-linear">XIX. Regularised Linear</h3> <p>Ridge and lasso are regularised linear regression algorithms, they use different penalty mechanism on the coefficient, avoiding it to be too large. These two methods increase the robustness of the prediction model.</p> <ul> <li><code class="language-plaintext highlighter-rouge">Ridge</code></li> </ul> <p>I use <code class="language-plaintext highlighter-rouge">gridsearchcv</code> to search for the best parameter, this is a simple hyperparameter tuning method that simply loop over all the parameters that needs calculation with cross validation.</p> <blockquote> <p><a href="https://scikit-learn.org/stable/modules/grid_search.html">3.2. Tuning the hyper-parameters of an estimator — scikit-learn 1.0.2 documentation</a></p> </blockquote> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RDparameters</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">:[</span><span class="mf">0.1</span><span class="p">,</span><span class="mf">0.2</span><span class="p">,</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.6</span><span class="p">,</span><span class="mf">0.7</span><span class="p">,</span><span class="mf">0.8</span><span class="p">,</span><span class="mf">0.9</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">]}</span>
<span class="n">RDopt</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="nc">Ridge</span><span class="p">(),</span><span class="n">RDparameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="n">RDopt</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span><span class="n">target</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">RDopt</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span> <span class="c1">#0.6
</span>
<span class="n">RD</span> <span class="o">=</span> <span class="nc">Ridge</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">RDopt</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">])</span>
<span class="n">RD_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">RD</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span> <span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Cross-Validation data with tuned Ridge: {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">RD_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span>
<span class="c1"># 0.423853
</span>
<span class="n">RD</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">RD</span><span class="p">,</span> <span class="sh">'</span><span class="s">Ridge</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <ul> <li><code class="language-plaintext highlighter-rouge">Lasso</code></li> </ul> <p>Same methods is used in <code class="language-plaintext highlighter-rouge">Lasso</code></p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">LSparameters</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">:[</span><span class="mf">1e-07</span><span class="p">,</span><span class="mf">1e-06</span><span class="p">,</span><span class="mf">1e-05</span><span class="p">,</span><span class="mf">1e-04</span><span class="p">,</span><span class="mf">1e-03</span><span class="p">,</span><span class="mf">0.01</span><span class="p">,</span><span class="mf">0.1</span><span class="p">,</span><span class="mi">1</span><span class="p">]}</span>
<span class="n">LSopt</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="nc">Lasso</span><span class="p">(),</span><span class="n">LSparameters</span><span class="p">,</span><span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="n">LSopt</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span><span class="n">target</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">LSopt</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span> <span class="c1">#0.0001
</span>
<span class="n">LS</span> <span class="o">=</span> <span class="nc">Lasso</span><span class="p">(</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">LSopt</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">alpha</span><span class="sh">'</span><span class="p">])</span>
<span class="n">LS_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">LS</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span> <span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Validation data with tuned Lasso: {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">LS_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span>
<span class="c1"># 0.423638
</span>
<span class="n">LS</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">LS</span><span class="p">,</span> <span class="sh">'</span><span class="s">Lasso</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <p><strong>INSIGHTS:</strong> Ridge and Lasso did not obviously improve the model performance. Tree-based algorithms are therefore considered.</p> <hr/> <h3 id="xx-random-forest">XX. Random Forest</h3> <p>Instead of using decision tree, I choose random forest to get started. Random forest is more capable of diminishing the risk of overfitting.</p> <p><code class="language-plaintext highlighter-rouge">optuna</code> is used for optimizing the hyperparameters.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    
    <span class="c1"># configure the hyperparameters range to optimise
</span>    <span class="n">n_estimators</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">n_estimators</span><span class="sh">'</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">300</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
    <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">min_samples_leaf</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">max_features</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_categorical</span><span class="p">(</span><span class="sh">'</span><span class="s">max_features</span><span class="sh">'</span><span class="p">,</span> <span class="p">[</span><span class="sh">'</span><span class="s">auto</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">sqrt</span><span class="sh">'</span><span class="p">])</span>
    <span class="n">max_depth</span> <span class="o">=</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="n">step</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
    
    <span class="c1"># define the model that need to be used
</span>    <span class="n">RFmodel</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span><span class="n">n_estimators</span> <span class="o">=</span> <span class="n">n_estimators</span><span class="p">,</span>  
                                  <span class="n">max_features</span> <span class="o">=</span> <span class="n">max_features</span><span class="p">,</span> 
                                  <span class="n">min_samples_leaf</span> <span class="o">=</span> <span class="n">min_samples_leaf</span><span class="p">,</span>
                                  <span class="n">max_depth</span> <span class="o">=</span> <span class="n">max_depth</span><span class="p">,</span>
                                  <span class="n">random_state</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
    
    <span class="c1"># define the criterion for the optimization
</span>    <span class="n">scores</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">RFmodel</span><span class="p">,</span> <span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span> <span class="n">cv</span> <span class="o">=</span> <span class="n">kfold</span><span class="p">)</span>
    
    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">loss</span>

<span class="n">sampler</span> <span class="o">=</span> <span class="nc">TPESampler</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span> 
<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="p">.</span><span class="nf">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="sh">'</span><span class="s">minimize</span><span class="sh">'</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
<span class="c1"># the timeout is set to be 30mins
# if you cannot wait that long, please shrink the timeout parameter below
# however, the longer, the more possible the model is well-tuned
</span><span class="n">study</span><span class="p">.</span><span class="nf">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">timeout</span><span class="o">=</span><span class="mi">2400</span><span class="p">)</span> 
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">RF_params</span> <span class="o">=</span> <span class="n">study</span><span class="p">.</span><span class="n">best_params</span>
<span class="n">RF</span> <span class="o">=</span> <span class="nc">RandomForestRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">RF_params</span><span class="p">)</span>
<span class="n">RF_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">RF</span><span class="p">,</span>
                                <span class="n">X</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">,</span>
                                <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span>
                                <span class="n">scoring</span> <span class="o">=</span> <span class="n">rmsle_scorer</span><span class="p">,</span>
                                <span class="n">cv</span> <span class="o">=</span> <span class="n">kfold</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Cross-Validation with tuned Random Forest: {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">RF_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span>

<span class="n">RF</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="nf">submit_tocsv_adjusted</span><span class="p">(</span><span class="n">RF</span><span class="p">,</span> <span class="sh">'</span><span class="s">RandomForest</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> </details> <p>Then I plotted the feature importance for better interpretability.</p> <p>Feature importance in tree-based models is based on Gini importance / impurity.</p> <blockquote> <p><a href="https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html">scikit documentation</a></p> </blockquote> <p>the feature importance plotting function will be reused in other models.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_feature_importance</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">labels</span><span class="p">,</span> <span class="n">max_features</span> <span class="o">=</span> <span class="mi">20</span><span class="p">):</span>  
    <span class="sh">'''</span><span class="s">
    This function is only available for models that has the feature_importances_ attribute.
    </span><span class="sh">'''</span>
    <span class="n">feature_importance</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">feature_importances_</span><span class="o">*</span><span class="mi">100</span>    
    <span class="n">feature_importance</span> <span class="o">=</span> <span class="mi">100</span><span class="o">*</span><span class="p">(</span><span class="n">feature_importance</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="nf">max</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">))</span>    
    <span class="n">table</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">feature_importance</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="n">labels</span><span class="p">).</span><span class="nf">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="nf">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">9</span><span class="p">,</span><span class="mi">6</span><span class="p">))</span>    
    <span class="k">if</span> <span class="nf">len</span><span class="p">(</span><span class="n">table</span><span class="p">)</span> <span class="o">&gt;</span> <span class="n">max_features</span><span class="p">:</span>        
        <span class="n">table</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="n">max_features</span><span class="p">:].</span><span class="n">T</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="sh">'</span><span class="s">barh</span><span class="sh">'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>    
    <span class="k">else</span><span class="p">:</span>        
        <span class="n">table</span><span class="p">.</span><span class="n">T</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">kind</span><span class="o">=</span><span class="sh">'</span><span class="s">barh</span><span class="sh">'</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="sh">'</span><span class="s">black</span><span class="sh">'</span><span class="p">,</span> <span class="n">width</span><span class="o">=</span><span class="mf">0.7</span><span class="p">,</span> <span class="n">linewidth</span><span class="o">=</span><span class="p">.</span><span class="mi">8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.9</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>    
    <span class="n">ax</span><span class="p">.</span><span class="nf">tick_params</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="sa">u</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">,</span> <span class="n">length</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>     
    <span class="n">ax</span><span class="p">.</span><span class="nf">set_title</span><span class="p">(</span><span class="sh">'</span><span class="s">Variable importance</span><span class="sh">'</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">13</span><span class="p">)</span>    
    <span class="n">sns</span><span class="p">.</span><span class="nf">despine</span><span class="p">()</span>    
    <span class="k">return</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span>

<span class="n">feature_names</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="nf">to_list</span><span class="p">()</span>

<span class="nf">plot_feature_importance</span><span class="p">(</span><span class="n">RF</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> </details> <p>The image shows like this:</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/airbnb6810/randomForestPlot-480.webp 480w,/assets/img/posts/airbnb6810/randomForestPlot-800.webp 800w,/assets/img/posts/airbnb6810/randomForestPlot-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/airbnb6810/randomForestPlot.png" class="img-fluid rounded mx-auto d-block z-depth-1" width="100%" height="auto" style=" max-width: 80%; " data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <p><strong>NOTE:</strong> If it is considered that the model is overfitting, we can perform the feature selection based on the image by choosing the top 5 or 10 features and redo the modelling.</p> <hr/> <h3 id="step-xxi-xgboost">Step XXI. XGBoost</h3> <p>XGBoost is widely used and perform relatively well in regression problems.</p> <p><code class="language-plaintext highlighter-rouge">GridSearchCV</code> was used for finding the optimised hyperparameters.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">clf</span> <span class="o">=</span> <span class="nc">GridSearchCV</span><span class="p">(</span><span class="nc">XGBRegressor</span><span class="p">(),</span>
                   <span class="p">{</span><span class="sh">'</span><span class="s">n_estimators</span><span class="sh">'</span><span class="p">:[</span><span class="mi">400</span><span class="p">,</span><span class="mi">500</span><span class="p">],</span>
                    <span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">:[</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span>
                    <span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">:[</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.07</span><span class="p">,</span> <span class="mf">0.04</span><span class="p">,]},</span> 
                   <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                   <span class="n">scoring</span> <span class="o">=</span> <span class="n">rmsle_scorer</span><span class="p">,</span>
                  <span class="p">)</span>

<span class="n">X_xgb</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">.</span><span class="n">values</span>

<span class="n">clf_result</span> <span class="o">=</span> <span class="n">clf</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_xgb</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">clf_result</span><span class="p">.</span><span class="n">best_score_</span><span class="p">)</span> 
<span class="c1"># -0.37892
</span><span class="nf">print</span><span class="p">(</span><span class="n">clf_result</span><span class="p">.</span><span class="n">best_params_</span><span class="p">)</span>
<span class="c1"># learning_rate : 0.04, max_depth : 8, n_estimators : 500
</span></code></pre></div></div> <p>Train the model and predict, as well as plot the feature importance.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1">#configure the model 
</span><span class="n">XGB</span> <span class="o">=</span> <span class="nc">XGBRegressor</span><span class="p">(</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">clf_result</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">],</span>
                       <span class="n">max_depth</span> <span class="o">=</span> <span class="n">clf_result</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">],</span>
                       <span class="n">n_estimators</span> <span class="o">=</span> <span class="n">clf_result</span><span class="p">.</span><span class="n">best_params_</span><span class="p">[</span><span class="sh">'</span><span class="s">n_estimators</span><span class="sh">'</span><span class="p">],)</span>

<span class="c1"># cross validation
</span><span class="n">XGB_CV_results</span> <span class="o">=</span> <span class="nf">cross_val_score</span><span class="p">(</span><span class="n">XGB</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">X_xgb</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span> <span class="p">,</span><span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Cross-Validation data with tuned XGBoost: {:.6f}</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="o">-</span><span class="n">XGB_CV_results</span><span class="p">.</span><span class="nf">mean</span><span class="p">()))</span> <span class="c1">#0.378497
</span>
<span class="c1"># predict with the trained model
</span><span class="n">XGB</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">X_xgb</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="n">X_test_xgb</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">values</span>

<span class="n">y_hat</span> <span class="o">=</span> <span class="n">XGB</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_xgb</span><span class="p">)</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">y_hat</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
<span class="n">final_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">XGB</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test_xgb</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj</span>
<span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">final_predict</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])</span>
<span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)</span>
<span class="n">submission</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">{} model prediction.csv</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">'</span><span class="s">XGBoost</span><span class="sh">'</span><span class="p">),</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>

<span class="c1"># print the feature importance plot
</span><span class="nf">plot_feature_importance</span><span class="p">(</span><span class="n">XGB</span><span class="p">,</span> <span class="n">feature_names</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span>
</code></pre></div></div> </details> <hr/> <h3 id="xxii-lightgbm">XXII. LightGBM</h3> <p>lightgbm is also popular in regression problem solutions and usually has faster computational speed and better performance than xgboost.</p> <p>We use the original <code class="language-plaintext highlighter-rouge">lightgbm</code> library here instead of the one included in the <code class="language-plaintext highlighter-rouge">sklearn</code> library - the code is slightly different between these two methods (same result though).</p> <p>Using <code class="language-plaintext highlighter-rouge">optuna</code> to optimize the hyperparameter with customized scorer:</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nc">Dataset</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nc">Dataset</span><span class="p">(</span><span class="n">X_valid</span><span class="p">,</span> <span class="n">y_valid</span><span class="p">,</span> <span class="n">reference</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">)</span>

<span class="c1"># define a scorer
</span><span class="k">def</span> <span class="nf">rmsle_lgbm</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
    <span class="sh">'''</span><span class="s">define the metrics used in lightgbm hyper parameter tuning</span><span class="sh">'''</span>
    <span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">(</span><span class="n">data</span><span class="p">.</span><span class="nf">get_label</span><span class="p">())</span>
    <span class="n">score</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="nf">mean_squared_log_error</span><span class="p">(</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">y_true</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span> <span class="p">))</span>
    <span class="k">return</span> <span class="sh">'</span><span class="s">rmsle</span><span class="sh">'</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="bp">False</span>

<span class="k">def</span> <span class="nf">objective</span><span class="p">(</span><span class="n">trial</span><span class="p">):</span>
    
    <span class="n">params</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">'</span><span class="s">objective</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">regression</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">boosting_type</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">gbdt</span><span class="sh">'</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">:</span> <span class="mf">0.03</span><span class="p">,</span> 
    <span class="sh">'</span><span class="s">verbose</span><span class="sh">'</span> <span class="p">:</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">feature_pre_filter</span><span class="sh">'</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
    <span class="sh">'</span><span class="s">num_leaves</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">num_leaves</span><span class="sh">'</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">64</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span> <span class="p">:</span><span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">lambda_l1</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_loguniform</span><span class="p">(</span><span class="sh">'</span><span class="s">lambda_l1</span><span class="sh">'</span><span class="p">,</span>  <span class="mf">1e-8</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> 
    <span class="sh">'</span><span class="s">lambda_l2</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_loguniform</span><span class="p">(</span><span class="sh">'</span><span class="s">lambda_l2</span><span class="sh">'</span><span class="p">,</span>  <span class="mf">1e-8</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> 
    <span class="sh">'</span><span class="s">bagging_fraction</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_uniform</span><span class="p">(</span><span class="sh">'</span><span class="s">bagging_fraction</span><span class="sh">'</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">bagging_freq</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">bagging_freq</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">feature_fraction</span><span class="sh">'</span><span class="p">:</span>  <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_uniform</span><span class="p">(</span><span class="sh">'</span><span class="s">feature_fraction</span><span class="sh">'</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
    <span class="sh">'</span><span class="s">min_data_in_leaf</span><span class="sh">'</span><span class="p">:</span> <span class="n">trial</span><span class="p">.</span><span class="nf">suggest_int</span><span class="p">(</span><span class="sh">'</span><span class="s">min_data_in_leaf</span><span class="sh">'</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> 
    <span class="sh">'</span><span class="s">metric</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">custom</span><span class="sh">'</span> <span class="c1"># the key step to use the customized scorer
</span>     <span class="p">}</span>
    
    <span class="c1"># Cross-validation 
</span>    <span class="n">history</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nf">cv</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_boost_round</span> <span class="o">=</span> <span class="mi">5000</span><span class="p">,</span> 
                 <span class="n">nfold</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="n">feval</span>  <span class="o">=</span> <span class="n">rmsle_lgbm</span><span class="p">,</span> <span class="n">stratified</span> <span class="o">=</span> <span class="bp">False</span><span class="p">,</span> <span class="n">early_stopping_rounds</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>
    
    
    <span class="c1"># Save full set of parameters
</span>    <span class="n">trial</span><span class="p">.</span><span class="nf">set_user_attr</span><span class="p">(</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
    
    <span class="c1"># Save the number of boosting iterations selected by early stopping
</span>    <span class="n">trial</span><span class="p">.</span><span class="nf">set_user_attr</span><span class="p">(</span><span class="sh">'</span><span class="s">num_boost_round</span><span class="sh">'</span><span class="p">,</span> <span class="nf">len</span><span class="p">(</span><span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">rmsle-mean</span><span class="sh">'</span><span class="p">]))</span>
    
    <span class="k">return</span> <span class="n">history</span><span class="p">[</span><span class="sh">'</span><span class="s">rmsle-mean</span><span class="sh">'</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># returns CV error for the best trial
</span>
<span class="n">sampler</span> <span class="o">=</span> <span class="nc">TPESampler</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span> 
<span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="p">.</span><span class="nf">create_study</span><span class="p">(</span><span class="n">direction</span><span class="o">=</span><span class="sh">'</span><span class="s">minimize</span><span class="sh">'</span><span class="p">,</span> <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">)</span>
<span class="n">study</span><span class="p">.</span><span class="nf">optimize</span><span class="p">(</span><span class="n">objective</span><span class="p">,</span> <span class="n">n_trials</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">timeout</span> <span class="o">=</span> <span class="mi">1200</span><span class="p">)</span>  
</code></pre></div></div> </details> <p><em>actually we tried several times on finding the appropriate range for optimization</em></p> <p>Code below shows the optimized hyperparameters:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">params</span> <span class="o">=</span> <span class="n">study</span><span class="p">.</span><span class="n">best_trial</span><span class="p">.</span><span class="n">user_attrs</span><span class="p">[</span><span class="sh">'</span><span class="s">params</span><span class="sh">'</span><span class="p">]</span>
<span class="n">num_trees</span> <span class="o">=</span> <span class="n">study</span><span class="p">.</span><span class="n">best_trial</span><span class="p">.</span><span class="n">user_attrs</span><span class="p">[</span><span class="sh">'</span><span class="s">num_boost_round</span><span class="sh">'</span><span class="p">]</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Number of boosting iterations: </span><span class="si">{</span><span class="n">num_trees</span><span class="si">}</span><span class="s"> </span><span class="se">\n</span><span class="sh">'</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">Best parameters:</span><span class="sh">'</span><span class="p">)</span>
<span class="n">params</span> 
</code></pre></div></div> <p>Checking the validation result</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lgbm1</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_boost_round</span> <span class="o">=</span> <span class="n">num_trees</span><span class="p">)</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">lgbm1</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_valid</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="nf">rmsle</span><span class="p">(</span><span class="n">y_valid</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span> 
<span class="c1"># 0.374258 --- the best performance so far
</span></code></pre></div></div> <p>prediction on the test set:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predictors</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">.</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">sub</span><span class="p">(</span><span class="sh">'</span><span class="s">[^A-Za-z0-9_]+</span><span class="sh">'</span><span class="p">,</span> <span class="sh">''</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nc">Dataset</span><span class="p">(</span><span class="n">predictors</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>
<span class="n">final_lgb</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nf">train</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">train_data</span><span class="p">,</span> <span class="n">num_boost_round</span> <span class="o">=</span> <span class="n">num_trees</span><span class="p">)</span>

<span class="c1"># consider the back transformation bias
</span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">final_lgb</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">predictors</span><span class="p">)</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">y_hat</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
<span class="n">final_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">final_lgb</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj</span>

<span class="c1"># prediction output
</span><span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">final_predict</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])</span>
<span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)</span>

<span class="n">submission</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">LightGBM model prediction.csv</span><span class="sh">'</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>
</code></pre></div></div> <p><code class="language-plaintext highlighter-rouge">lightbgm</code> has its own feature importance plot, which is convenient.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lgb</span><span class="p">.</span><span class="nf">plot_importance</span><span class="p">(</span><span class="n">lgbm1</span><span class="p">,</span><span class="n">max_num_features</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
</code></pre></div></div> <p>For the later model stacking, noted that original <code class="language-plaintext highlighter-rouge">lightgbm</code> machine does not support to be included in model stacking, therefore, the code below provides an alternative version of the model optimized with <code class="language-plaintext highlighter-rouge">sklearn</code> compatibility.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># StackingCVRegressor does not support original lgb machine,
# a alternative regressor which compatible with StackingCVRegressor is built
# with all the tuned parameters set.
</span><span class="n">LGBMSTACKmodel</span> <span class="o">=</span> <span class="n">lgb</span><span class="p">.</span><span class="nc">LGBMRegressor</span><span class="p">(</span>
    <span class="n">boosting_type</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">boosting_type</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">learning_rate</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">learning_rate</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">num_leaves</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">num_leaves</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">max_depth</span><span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">max_depth</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">reg_alpha</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">lambda_l1</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">reg_lambda</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">lambda_l2</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">bagging_fraction</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">bagging_fraction</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">bagging_freq</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">bagging_freq</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">feature_fraction</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">feature_fraction</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">min_data_in_leaf</span><span class="o">=</span><span class="n">params</span><span class="p">[</span><span class="sh">'</span><span class="s">min_data_in_leaf</span><span class="sh">'</span><span class="p">],</span>
    <span class="n">n_estimators</span> <span class="o">=</span> <span class="n">num_trees</span>
<span class="p">)</span>
</code></pre></div></div> </details> <h2 id="model-stacking">Model Stacking</h2> <p>Model stacking can be regarded as a model of the models - a nested one which uses the result of the first layer of models. - This technique can improve the performance to some extent but also increase the risk of overfitting and largely reduce the interpretability.</p> <p><code class="language-plaintext highlighter-rouge">StackingCVRegressor</code> from <code class="language-plaintext highlighter-rouge">mlxtend.regressor</code> is used for stacking models.</p> <details><summary>Click here for codes</summary> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">stack</span> <span class="o">=</span> <span class="nc">StackingCVRegressor</span><span class="p">(</span><span class="n">regressors</span><span class="o">=</span><span class="p">[</span><span class="n">LS</span><span class="p">,</span> <span class="n">RF</span><span class="p">,</span> <span class="n">XGB</span><span class="p">,</span> <span class="n">LGBMSTACKmodel</span><span class="p">],</span> <span class="c1"># the models being used
</span>                            <span class="n">meta_regressor</span><span class="o">=</span><span class="n">LGBMSTACKmodel</span><span class="p">,</span> <span class="c1"># the meta model
</span>                            <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="c1"># cross validation
</span>                            <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
                            <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
                            <span class="n">use_features_in_secondary</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="c1"># original dataset included
</span>                            <span class="n">store_train_meta_features</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
                            <span class="n">n_jobs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span>
                           <span class="p">)</span>
<span class="c1"># get rid of the feature names, otherwise there will be errors(only take numpy arrays)
</span><span class="n">predictors_stack</span> <span class="o">=</span> <span class="n">predictors</span><span class="p">.</span><span class="n">values</span>
<span class="n">X_test_stack</span> <span class="o">=</span> <span class="n">X_test</span><span class="p">.</span><span class="n">values</span>

<span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">RMSLE of Cross-Validation data with model stack:</span><span class="sh">'</span><span class="p">,</span>
      <span class="o">-</span><span class="nf">cross_val_score</span><span class="p">(</span><span class="n">stack</span><span class="p">,</span>
                       <span class="n">X</span> <span class="o">=</span> <span class="n">predictors_stack</span><span class="p">,</span>
                       <span class="n">y</span> <span class="o">=</span> <span class="n">target</span><span class="p">,</span>
                       <span class="n">scoring</span><span class="o">=</span><span class="n">rmsle_scorer</span><span class="p">,</span>
                       <span class="n">cv</span><span class="o">=</span><span class="n">kfold</span><span class="p">,).</span><span class="nf">mean</span><span class="p">()</span> <span class="p">)</span>
<span class="c1"># 0.37202 - better than lightgbm
</span>
<span class="n">stack</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">predictors_stack</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

<span class="c1"># back transformation bias modification
</span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">stack</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">predictors_stack</span><span class="p">)</span>
<span class="n">residuals</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">y_hat</span>
<span class="n">adj</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">residuals</span><span class="p">))</span>
<span class="n">final_predict</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">exp</span><span class="p">(</span><span class="n">stack</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X_test_stack</span><span class="p">))</span> <span class="o">*</span> <span class="n">adj</span>

<span class="c1"># prediction of the test set
</span><span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">test</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="n">final_predict</span><span class="p">],</span> <span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">price</span><span class="sh">'</span><span class="p">])</span>
<span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="n">submission</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">].</span><span class="nf">astype</span><span class="p">(</span><span class="sh">'</span><span class="s">int</span><span class="sh">'</span><span class="p">)</span>
<span class="n">submission</span><span class="p">.</span><span class="nf">to_csv</span><span class="p">(</span><span class="sh">'</span><span class="s">{} model prediction.csv</span><span class="sh">'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="sh">'</span><span class="s">Stacking</span><span class="sh">'</span><span class="p">),</span> <span class="n">index</span> <span class="o">=</span> <span class="bp">False</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">submission</span><span class="p">)</span>

</code></pre></div></div> </details> <p>As a result, the model stacking did not improve the performance significantly, and later proved in the test set, it was overfiting.</p> <h2 id="result">Result</h2> <p>The test set, which is the criterion for evaluating the generalization on the unseen data, shows that <code class="language-plaintext highlighter-rouge">lightgbm</code> has the best performance - model stacking is slightly overfitting. (see results in Kaggle competition)</p> <h2 id="reflection">Reflection</h2> <p>The project was done in 2022, and I was lacking the experience in deeper analysis, as well as more complicated techniques in coding and modelling. There are still a lot of possibilities to try or optimise. Here are some of the possibilities:</p> <ul> <li> <p>We did not include the neural networks although we have tried but cannot make the result reproducible, it seems that the neural network requires more fixed random seed settings. And based on the result, the <strong>neural network performs relatively bad, it takes hours of training to achieve a slightly better performance than linear regression</strong>. It is a good idea to <strong>consider neural networks in the model stacking</strong> as this is neither linear nor tree-based (similar algorithms improve the stacking result little). Moreover, designing the structure and hyperparameter tuning is more complicated compared to the models mentioned above.</p> </li> <li> <p>The natural language processing techniques are relatively simple, it is considered to use <strong>word2Vec</strong> (<a href="https://www.tensorflow.org/tutorials/text/word2vec">Word2Vec TensorFlow Core</a>) so that the sentences(some variables we dropped) can be vectorized to extract useful information.</p> </li> <li> <p>As for linear regression models, only simple linear and regularised ones are tested. There are <strong>elastic net (combining the ridge and lasso), SVM, splines, and generalised additive models</strong> that are not tested. Although I do not hold a positive expectation about their performance as the relationship is clearly non-linear with so many features. Tree-based models perform better in this kind of dataset by my experience. However, they can always be included in the model stacking.</p> </li> <li> <p>Coding habits and structure is an issue as I went through the jupyter notebook. 1) Naming the variables - <code class="language-plaintext highlighter-rouge">anExampleVariableName</code> such naming pattern is considered a good habit. 2) splitting the notebook into several separate files and commnicating using .csv(for datasets) .py(for scripts) would be better to read, manage, and maintain if the project is an ongoing service.</p> </li> </ul>]]></content><author><name></name></author><category term="ML"/><summary type="html"><![CDATA[Airbnb Price Prediction]]></summary></entry></feed>